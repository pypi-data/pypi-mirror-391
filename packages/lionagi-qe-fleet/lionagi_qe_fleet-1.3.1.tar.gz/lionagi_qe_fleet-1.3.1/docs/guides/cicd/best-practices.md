# CI/CD Integration Best Practices

**Recommended patterns and practices for optimal QE Fleet integration**

---

## Core Principles

### 1. Start Small, Scale Gradually

‚úÖ **DO**:
```yaml
# Week 1: Basic test generation only
- run: aqe generate src/core/ --ci-mode

# Week 2: Add test execution
- run: aqe execute tests/ --parallel

# Week 3: Add quality gates (non-blocking)
- run: aqe quality-gate --threshold 70 || true

# Week 4: Enable blocking quality gates
- run: aqe quality-gate --threshold 80 --fail-on-error
```

‚ùå **DON'T**: Enable all features at once with strict thresholds.

---

### 2. Version Pin Dependencies

‚úÖ **DO**:
```bash
pip install lionagi-qe-fleet==1.2.1
```

‚ùå **DON'T**:
```bash
pip install lionagi-qe-fleet  # May break on updates
```

---

### 3. Use CI Mode

‚úÖ **DO**:
```bash
aqe generate src/ --ci-mode --json --quiet
```

‚ùå **DON'T**:
```bash
aqe generate src/  # Interactive mode, verbose output
```

---

## Configuration Management

### API Keys

‚úÖ **DO**:
```yaml
# Store in CI secrets
env:
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

# Rotate regularly (every 90 days)
# Monitor usage
```

‚ùå **DON'T**:
- Hardcode API keys in code
- Commit keys to git
- Share keys across environments
- Use same key for dev/prod

---

### Configuration Files

‚úÖ **DO**:
```bash
# Store config in repo
config/
  qe-fleet.json
  quality-gates.json
  storage.json

# Load in CI
aqe generate --config config/qe-fleet.json
```

‚ùå **DON'T**:
- Hardcode configuration in CI files
- Duplicate config across environments

---

## Performance Optimization

### 1. Enable Parallel Execution

‚úÖ **DO**:
```bash
aqe generate src/ --parallel
aqe execute tests/ --parallel
```

**Benefit**: 2-4x faster execution

---

### 2. Use Multi-Model Routing

‚úÖ **DO**:
```bash
export QE_ROUTING_ENABLED=true
aqe generate src/  # Automatically uses cheapest suitable model
```

**Benefit**: 70-80% cost savings

---

### 3. Generate Incrementally

‚úÖ **DO**:
```bash
# Only generate for changed files
CHANGED_FILES=$(git diff --name-only HEAD^ | grep '\.py$')
if [ -n "$CHANGED_FILES" ]; then
  echo "$CHANGED_FILES" | xargs aqe generate
fi
```

‚ùå **DON'T**: Regenerate all tests on every commit.

---

### 4. Cache Dependencies

**GitHub Actions**:
```yaml
- uses: actions/cache@v4
  with:
    path: |
      ~/.cache/pip
      ~/.cache/qe-fleet
    key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
```

**GitLab CI**:
```yaml
cache:
  paths:
    - .pip-cache/
    - .qe-cache/
```

---

## Quality Gates

### 1. Progressive Thresholds

‚úÖ **DO**:
```yaml
# Week 1-2: Non-blocking, low threshold
- run: aqe quality-gate --threshold 60 || true

# Week 3-4: Non-blocking, medium threshold
- run: aqe quality-gate --threshold 75 || true

# Week 5+: Blocking, target threshold
- run: aqe quality-gate --threshold 80 --fail-on-error
```

‚ùå **DON'T**: Start with 90% threshold on day 1.

---

### 2. Different Thresholds by Context

‚úÖ **DO**:
```yaml
# Main branch: Strict
- if: github.ref == 'refs/heads/main'
  run: aqe quality-gate --threshold 85 --fail-on-error

# PRs: Lenient (non-blocking)
- if: github.event_name == 'pull_request'
  run: aqe quality-gate --threshold 75 || echo "‚ö†Ô∏è Quality below target"

# Feature branches: No gate
- if: startsWith(github.ref, 'refs/heads/feature/')
  run: echo "Skipping quality gate on feature branch"
```

---

### 3. Component-Specific Thresholds

‚úÖ **DO**:
```bash
# Critical code: Strict
aqe quality-gate --scope src/auth/ --threshold 95

# Utility code: Normal
aqe quality-gate --scope src/utils/ --threshold 80

# Experimental: Lenient
aqe quality-gate --scope src/experimental/ --threshold 60
```

---

## Test Generation

### 1. Review Generated Tests

‚úÖ **DO**:
```yaml
# Generate to separate directory
- run: aqe generate src/ --output tests/generated/

# Create PR for review
- uses: peter-evans/create-pull-request@v5
  with:
    title: "ü§ñ Generated tests for src/"
    body: "Auto-generated by QE Fleet. Please review."
    branch: qe-fleet/generated-tests
```

‚ùå **DON'T**: Automatically commit generated tests without review.

---

### 2. Separate Generated from Manual Tests

‚úÖ **DO**:
```
tests/
  manual/           # Hand-written tests
  generated/        # QE Fleet generated
  integration/      # Integration tests
```

**Benefits**:
- Easy to identify AI-generated tests
- Can regenerate without losing manual tests
- Clear separation of concerns

---

### 3. Version Control Generated Tests

‚úÖ **DO**: Commit generated tests to git

**Benefits**:
- Tests available offline
- Code review process
- Test history tracking
- No regeneration in CI (faster)

‚ùå **DON'T**: Regenerate tests on every CI run.

---

## Artifact Storage

### 1. Use S3 for Production

‚úÖ **DO**:
```python
{
  "backend": "s3",
  "s3": {
    "bucket": "my-qe-artifacts-prod",
    "region": "us-east-1"
  },
  "retention": {
    "default_days": 90
  }
}
```

**Benefits**:
- Unlimited storage
- Automatic retention
- Historical querying
- Team access

---

### 2. Tag Artifacts Appropriately

‚úÖ **DO**:
```bash
aqe execute tests/ --store-artifacts \
  --artifact-key "build-$CI_COMMIT_SHA" \
  --metadata '{
    "branch": "$CI_BRANCH",
    "pr": "$CI_PR_NUMBER",
    "author": "$CI_COMMIT_AUTHOR",
    "timestamp": "'$(date -Iseconds)'"
  }'
```

**Benefits**:
- Easy querying
- Better organization
- Audit trail

---

### 3. Set Retention Policies

‚úÖ **DO**:
```python
{
  "retention": {
    "feature_branches": 7,      # Keep 1 week
    "main_branch": 90,          # Keep 3 months
    "release_tags": 365,        # Keep 1 year
    "security_findings": 730    # Keep 2 years
  }
}
```

**Benefits**:
- Control storage costs
- Compliance requirements
- Performance (less data to query)

---

## Security

### 1. Scan Generated Tests for Secrets

‚úÖ **DO**:
```yaml
- name: Generate Tests
  run: aqe generate src/ --output tests/generated/

- name: Scan for Secrets
  run: |
    pip install detect-secrets
    detect-secrets scan tests/generated/ --baseline .secrets.baseline
```

---

### 2. Run Security Scans Regularly

‚úÖ **DO**:
```yaml
# On every PR
on: [pull_request]
jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - run: aqe security-scan src/ --comprehensive

# Scheduled (weekly)
on:
  schedule:
    - cron: '0 0 * * 0'  # Sunday midnight
jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - run: aqe security-scan . --comprehensive --severity medium
```

---

### 3. Limit API Key Scope

‚úÖ **DO**:
- Separate keys per environment (dev, staging, prod)
- Separate keys per project
- Rotate keys every 90 days
- Monitor usage and set alerts

‚ùå **DON'T**: Use same API key everywhere.

---

## Cost Management

### 1. Monitor AI API Costs

‚úÖ **DO**:
```bash
# Weekly cost report
aqe usage report --since 7d --output costs.json

# Set cost alerts
aqe usage alert --daily-limit 10 --monthly-limit 200
```

---

### 2. Optimize Model Selection

‚úÖ **DO**:
```bash
# Enable multi-model routing (automatic)
export QE_ROUTING_ENABLED=true

# Or manual selection
aqe generate src/simple/ --model gpt-3.5-turbo  # Cheap
aqe generate src/critical/ --model gpt-4        # Expensive
```

---

### 3. Cache Aggressively

‚úÖ **DO**:
```bash
# Cache generated tests (avoid regeneration)
# Cache dependencies (faster installs)
# Cache AI responses (for identical code)
```

---

## Monitoring & Observability

### 1. Track Key Metrics

‚úÖ **DO**:
```yaml
- name: Generate Tests & Track Metrics
  run: |
    aqe generate src/ --json > generation-results.json

    # Extract metrics
    TESTS_GENERATED=$(jq '.data.tests_generated' generation-results.json)
    COVERAGE_EST=$(jq '.data.coverage_estimate' generation-results.json)

    # Send to monitoring
    echo "tests_generated=$TESTS_GENERATED" >> $GITHUB_STEP_SUMMARY
    echo "coverage_estimate=$COVERAGE_EST" >> $GITHUB_STEP_SUMMARY
```

**Metrics to Track**:
- Tests generated per run
- Test execution time
- Coverage trends
- Quality gate pass rate
- AI API costs
- CI run duration

---

### 2. Set Up Alerts

‚úÖ **DO**:
```yaml
- name: Quality Gate with Alert
  run: |
    if ! aqe quality-gate --threshold 80; then
      curl -X POST $SLACK_WEBHOOK \
        -d '{"text": "‚ö†Ô∏è Quality gate failed on main branch!"}'
      exit 1
    fi
```

---

### 3. Generate Reports

‚úÖ **DO**:
```yaml
- name: Generate Quality Report
  run: aqe report generate --format html --output quality-report.html

- name: Upload Report
  uses: actions/upload-artifact@v4
  with:
    name: quality-report
    path: quality-report.html
```

---

## Team Collaboration

### 1. Document QE Fleet Usage

‚úÖ **DO**: Add to README.md:
```markdown
## Testing

Tests are automated using [LionAGI QE Fleet](https://github.com/lionagi/lionagi-qe-fleet).

### Generate Tests
\```bash
aqe generate src/ --output tests/generated/
\```

### Run Tests
\```bash
aqe execute tests/ --parallel --coverage
\```

### Quality Gate
\```bash
aqe quality-gate --threshold 80
\```

See [CI/CD docs](docs/guides/cicd/) for more details.
```

---

### 2. Share Configuration

‚úÖ **DO**:
```bash
# Commit config to repo
config/
  qe-fleet.json       # Main config
  quality-gates.json  # Quality thresholds
  storage.json        # Artifact storage

# Document in CONTRIBUTING.md
```

---

### 3. Review Generated Tests Together

‚úÖ **DO**:
```yaml
# Create PRs for generated tests
- uses: peter-evans/create-pull-request@v5
  with:
    title: "ü§ñ AI-generated tests for ${{ github.event.pull_request.title }}"
    reviewers: team-lead,qa-engineer
```

---

## Troubleshooting

### 1. Enable Debug Mode When Needed

‚úÖ **DO**:
```bash
# Only when troubleshooting
export QE_LOG_LEVEL=DEBUG
export QE_LOG_FILE=/tmp/qe-fleet-debug.log
aqe generate src/ --verbose
```

‚ùå **DON'T**: Always run in debug mode (slower, more logs).

---

### 2. Implement Retry Logic

‚úÖ **DO**:
```bash
# Retry on API errors
for i in {1..3}; do
  aqe generate src/ --ci-mode && break
  [ $? -eq 4 ] && { echo "Retrying..."; sleep 30; } || exit $?
done
```

---

### 3. Fail Fast

‚úÖ **DO**:
```bash
# Stop on first failure
aqe execute tests/ --fail-fast
```

---

## Summary Checklist

**Before Going to Production**:

- [ ] API keys stored in CI secrets
- [ ] Version pinned (`lionagi-qe-fleet==1.2.1`)
- [ ] CI mode enabled (`--ci-mode`)
- [ ] Parallel execution enabled (`--parallel`)
- [ ] Multi-model routing enabled (`QE_ROUTING_ENABLED=true`)
- [ ] Quality gates configured with reasonable thresholds
- [ ] Artifact storage configured (S3 recommended)
- [ ] Retention policies set
- [ ] Generated tests reviewed and committed
- [ ] Security scanning enabled
- [ ] Cost monitoring set up
- [ ] Team documentation updated
- [ ] Badges added to README
- [ ] Tested on feature branch first

---

## Next Steps

- [Troubleshooting Guide](./troubleshooting.md)
- [FAQ](./faq.md)
- [Example Workflows](./examples/)

---

**Last Updated**: 2025-11-12
