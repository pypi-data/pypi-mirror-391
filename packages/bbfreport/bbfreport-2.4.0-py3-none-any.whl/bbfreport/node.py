# noinspection GrazieInspection
"""Node classes.

Every XML element becomes a node in a tree whose structure more-or-less
matches the XML file structure.

The class hierarchy is designed to avoid unnecessary duplication. It
includes private types such as `_Node`, `_Base`, and `_HasDescription`,
and public types such as `Root`, `Dm_document`, `Model`, `Object` and
`Parameter`.

A node tree always has a single `Root` node. The root node has an `Xml_file`
node for each file specified on the command line, and each XML file node has
`Comment` nodes for any comments, and a single `Dm_document` node. Each DM
document node can have a `Description` node, `Import` nodes, `DataType` nodes,
`Component` nodes, `Model` nodes and so on.

Nodes expose both a generic interface and a specific interface.

* The generic interface is very simple: each node has a `_Base.attrs`
  (attributes) dictionary and a `_Base.elems` (child elements) tuple.

* The specific interface is pretty much what you'd expect, e.g., a `Parameter`
  object has `_ModelItem.name` and `Parameter.syntax`
  attributes.

Nodes are either "keyed" or "unkeyed". All keyed node types must implement
the `_Node.calckey()` class method, which is called before creating a new
instance.

* Examples of keyed nodes include  `Reference` nodes (bibrefs), which are
  keyed by ``id``, and `Parameter` nodes, which are keyed by
  ``(modelName:majorVersion, objectPath, parameterName)``.

* Examples of unkeyed nodes include `Description` and `Syntax` nodes.

Two factors influence whether the node hierarchy matches the XML file
structure.

* If a node is keyed, then if another node with the same key is encountered,
  the second node's data will be (hierarchically) merged into the first node's
  data. For example, a `Model`'s key is ``(modelName, majorVersion)``, so
  ``MyModel:1.1`` is merged into ``MyModel:1.0``.

* `Component` definitions are saved internally rather than being expanded.
  They are expanded when referenced, and their nodes end up in the
  appropriate places in the node tree.

Note:
    If the ``--thisonly`` command-line is specified, imports are ignored,
    component definitions are expanded at the point of definition, and
    component references aren't expanded. This is so the report can as far as
    possible replicate the exact structure of the input file.

Glossary
========

.. glossary::

    Deprecated property
        A property that is deprecated, typically because it's been
        replaced by another property.

    Internal property
        A property that holds internal state and which is therefore not
        included in the node's `attrs` or `elems`.

    Mandatory property
        A property that must be supplied.

    Plural property
        A property whose value is a list of nodes and whose name usually
        ends with an ``s``.

    Singular property
        A property that was automatically generated by removing the trailing
        ``s`` from the name of a *plural property*. A singular property
        references the *plural property*'s first item, or is `Null` if the
        *plural property* has no items.
"""

# Copyright (c) 2019-2021, Broadband Forum
#
# Redistribution and use in source and binary forms, with or
# without modification, are permitted provided that the following
# conditions are met:
#
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above
#    copyright notice, this list of conditions and the following
#    disclaimer in the documentation and/or other materials
#    provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its
#    contributors may be used to endorse or promote products
#    derived from this software without specific prior written
#    permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
# CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
# INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
# NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# The above license is used as a license under copyright only.
# Please reference the Forum IPR Policy for patent licensing terms
# <https://www.broadband-forum.org/ipr-policy>.
#
# Any moral rights which are necessary to exercise under the above
# license grant are also deemed granted under this license.

import argparse
import builtins
import keyword
import os
import re

from functools import cache
from typing import Any, Callable, cast, Optional, Union

from .content import Content
from .exception import NodeException
from .file import File
from .logging import Logging
from .parser import Data
from .path import Path, follow_reference
from .property import Attr, Attrs, BoolAttr, ContentAttr, DecimalAttr, \
    DescriptionSingleElem, Elem, Elems, EnumObjAttr, FileNameStrAttr, \
    IntAttr, IntOrUnboundedAttr, NamespaceStrAttr, NamespaceStrDictAttr, \
    PropDescr, ListElem, Null, NullType, Property, Report, \
    RedefineCheckStrAttr, SingleElem, SpecStrAttr, StrAttr, StrListAttr, \
    VersionStrAttr, SyntaxSingleElem, ValueListElem
from .utility import ActionEnum, ActiveNotifyEnum, Dt_activeNotifyEnum, \
    DefaultTypeEnum, FacetAccessEnum, FileName, MountTypeEnum, \
    NestedBracketsEnum, ObjectAccessEnum, Dt_objectAccessEnum, \
    ObjectRequirementEnum, ParameterAccessEnum, ParameterRequirementEnum, \
    ReferenceTypeEnum, ScopeEnum, Spec, StatusEnum, TargetDataTypeEnum, \
    TargetTypeEnum, Utility, Version

# common type aliases
# XXX note that Node is an alias for _Node or _Base; this is convenient
# XXX can these now be simplified, e.g., using _Mergeable?
Key = Union[None, str, tuple[str, ...]]
Node = Union['_Node', '_Base']
NodeOrMixin = Union[Node, '_Mixin']
NodeType = Union[type['_Node'], type['_Base']]
NodeOrMixinType = Union[NodeType, type['_Mixin']]
Stack = tuple[Node, ...]
NodeTypes = Union[NodeType, tuple[NodeType, ...]]
NodeTypeNames = Union[str, tuple[str, ...]]

logger = Logging.get_logger(__name__)

class_hierarchy = Utility.class_hierarchy
lower_first = Utility.lower_first
nice_dict = Utility.nice_dict
nice_list = Utility.nice_list
nicer_list = Utility.nicer_list
nice_none = Utility.nice_none
nice_string = Utility.nice_string
pluralize = Utility.pluralize


# XXX once stable, should break out some classes to separate modules

# XXX with a bit of re-factoring, some classes could be auto-generated from the
#     schema; currently some info, e.g. enumerations, has been added manually;
#     is it worth it? quite likely not

# XXX need some programming guidelines, e.g. method ordering (do what
#     PyCharm does); also python version (see report.py check), use of
#     f-strings (don't?) etc.

# XXX really should use __slots__ to prevent inadvertent attribute creation

# XXX @cache can cache partially-constructed results; need a custom caching
#     mechanism that doesn't have this problem

# XXX should have a better way of controlling this; perhaps control it via
#     a debug flag? what would be its relationship with debug logging?
PATH_QUIET = True


def typename(cls: NodeOrMixinType, *, lower: bool = False) -> str:
    name = cls.__name__
    if name.startswith('_'):
        name = '_' + lower_first(name[1:])
    else:
        name = lower_first(name)
    if lower:
        name = name.lower()
    return name


def varname(cls: NodeOrMixinType, *, safe: bool = False) -> str:
    name = re.sub(r'(?<=[a-z])(?=[A-Z])', '_', cls.__name__).lower()
    if safe and (name in keyword.kwlist or name in vars(builtins)):
        name += '_'
    return name


# XXX this should have a better name
class _Mergeable:
    """Class from which all nodes and mixins are derived. It has to define
    all methods that delegate to ``super()``.
    """

    def _mergeprep(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        """Merge preparation hook.

        This is called just before the `_merge()` method. It's a useful
        place for logic that needs to run before a node is updated in any
        way. This method should be overridden by derived classes
        (the default implementation does nothing).

        Args:
            stack: As for `_Node._merge()`.
            report: Whether to report.
        """
        pass

    # XXX could we automate (some) _mergedone() via PropDescr mandatory etc.
    def _mergedone(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        """Indicate that this node's data has been merged.

        This is called on completion of the `_merge()` method. It's a useful
        place for logic that needs to run whenever a node has been updated
        in any way. This method should be overridden by derived classes
        (the default implementation does nothing).

        Args:
            stack: As for `_Node._merge()`.
            report: Whether to report.
        """
        pass

    def format(self, human: bool = False, brief: bool = False,
               only: bool = False, **kwargs) -> str:
        """A formatted string representation of this object.

        The default implementation returns an empty string.
        """

        assert not kwargs, '%s: unsupported format() arguments %s' % \
                           (type(self).__name__, kwargs)
        return ''


class _Node(_Mergeable):
    """Class from which all node classes are derived.

    Nothing prevents creation of `_Node` instances, but all "real" nodes
    should be of types derived from `_Base` (which is derived from `_Node`).

    * `_Node` contains the machinery for creating and managing nodes,
      but knows hardly anything about the DM schema.
    * `_Base` has some knowledge of the DM schema, and defines some common
      attributes and methods.
    """

    # XXX parent is declared as being a _Base rather than a _Node; this is
    #     because all actual instances should be derived from _Base, and some
    #     of the _Base methods access parent assuming that it's a _Base

    # XXX need some documentation on this (it doesn't need to be ordered)
    # XXX it's keyed by class then (tuple) key; should the key be split into
    #     its components? there may be little or no benefit to doing this
    __nodes = {}

    # XXX rather than passing args, should use a Context structure that
    #     contains only the needed args (and is initialized to sensible
    #     defaults); store on Root and access via node.root.ctxt?
    args: argparse.Namespace = None
    """The script's command-line arguments.

    This is a class attribute, and so (for any ``node`` object) can be
    accessed as ``node.args``. For example, ``node.args.output`` is the
    value of the ``--output`` argument.
    """

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """Calculate the key for an existing or new node.

        Keys are tuples (typically of strings) but as a convenience they can
        also contain tuples, which makes it easy to form a key that includes a
        parent node's key (which will be a tuple). The key is "flattened"
        before use.

        The default implementation returns ``None``, which means that
        instances of this type of node aren't stored (so a new instance is
        always created).

        It can be quite tricky to decide which node types should be keyed or
        unkeyed, and to decide exactly what the key should be. This decision
        has far-reaching implications! For example:

        * The `Model` key omits the minor version, so all minor versions of
          a model share a single `Model` instance. This instance will be
          associated with the file that defined the first version of the
          model, and then the data from all the subsequent minor versions
          will be merged into this instance.

        * The `DataType` and `Component` keys include the containing
          `Dm_document`'s full path, which reflects the fact that data
          type and component definitions are local.

        Args:
            parent: Parent node.
            dct: The data that will be supplied to the new or existing node
                with the returned key. It's expected that only top-level items
                such as ``name`` or ``ref`` will be accessed.
            **kwargs: Additional keyword arguments (specific to the node type).

        Returns:
            A tuple (typically of strings), or ``None`` if this type of node is
            unkeyed.

        Note:
            It should be possible to define the key via `PropDescr` options,
            in which case this method wouldn't be necessary. This would be
            quite a major simplification.
        """
        return None

    # XXX should treat empty tuple key the same as None; should prefer it?
    @classmethod
    def _find(cls, key: Optional[tuple]) -> Optional[Node]:
        assert key is None or isinstance(key, tuple)
        return cls.__nodes.get(cls, {}).get(key)

    def __init__(self, *, key: Key = None, parent: Optional[Node] = None,
                 data: Optional[Data] = None,
                 defermerge: Optional[bool] = None,
                 stack: Optional[Stack] = None, **kwargs):
        """Node constructor.

        Most derived classes rely on this constructor and don't need to do any
        extra work. Only `Root`, `Component`, `Dm_document` and `Model` (at
        the time of writing) have their own constructors (all of which of
        course call this base class constructor).

        Outline:
            1. If key is specified, check there's no existing node of this
               type with this key, and store the node for future reference.
            2. If not deferring the merge, call `_merge()` to merge the
               supplied data. This may result in creation of many other
               nodes and on completion will call `_Node._mergedone()`.

        Note:
            1. If a derived class needs to do something before its data is
               merged, it needs to implement its own constructor.
            2. If a derived class needs to do something after its data has
               been merged, it needs to implement `_Node._mergedone()`.

        Args:
            key: Node key. ``None`` for unkeyed nodes, or a tuple for keyed
                nodes.
            parent: Parent node.  Should normally only be ``None`` for the
                `Root` node.
            data: Tuple of two-element ``(name, value)`` tuples, where
                ``value`` can itself be a tuple, thereby defining a
                hierarchical structure.
            defermerge: Whether to store ``data`` in the object rather than
                immediately calling `_merge()` to merge it into the node
                tree. Some derived class constructors set this to ``True``.
            stack: Node stack. Contains an entry for every node that's
                currently being constructed or merged.
            **kwargs: Additional keyword arguments that are passed to
                `_merge()` and other methods.
        """

        cls = type(self)
        assert key is None or isinstance(key, tuple)
        assert cls not in cls.__nodes or key not in cls.__nodes[cls]
        self._key = key
        self._parent = parent
        # XXX _defermerge can be a class attribute; _data and _stack should
        #     only be created when _defermerge
        self._data = data if defermerge else None
        self._stack = stack if defermerge and stack else None
        self._defermerge = defermerge
        # attributes (non-Node children) and elements (Node children)
        self._attrs = Attrs()
        self._elems = Elems()

        # this is needed for mixins, and must happen before merge
        super().__init__()

        # it's important to store before merge, because component,
        # model etc. references need to be able to find the
        # partially-constructed node
        if key is not None:
            cls.__nodes.setdefault(cls, {})
            cls.__nodes[cls][self._key] = self

        # XXX this logic should maybe be outside the constructor?
        if data is not None and not defermerge:
            self._merge(data=data, stack=stack, **kwargs)

    # XXX would like to allow data to be a dictionary? use merge() for this?
    def _merge(self, *, data: Optional[Data] = None,
               stack: Optional[Stack] = None, **kwargs) -> Any:
        """Merge the supplied data into the object's attributes.

        This method is called for every node at every level of the
        hierarchy. The supplied data can be nested quite deep, which will
        result in many recursive invocations of this method and of node
        constructors.

        Outline:
            1. If this node's data wasn't merged on creation, merge it now
               (this is currently only used for `Model` instances: when a
               model is first defined, its data is stored, and is only
               merged when it's needed).

            2. Add this node to the stack.

            3. For each ``(name, value)`` pair in ``data``

               * Get this field's `Property` object (creating it if necessary).

               * If it's an `Elem` (so we need a node)

                 * If keyed, and a node with this key already exists

                   * Merge the ``value`` data into the existing node.

                 * If not keyed, or if no node with this key already exists

                   * Create a new node and merge the ``value`` data into it.

               * Call `Property.merge()` to merge the attribute value or node
                 into the `Property` object.

            4. Call `_mergedone()`.

        Args:
            data: Data to be merged.
            stack: Node stack. Contains an entry for every node that's
                currently being constructed or merged.
            **kwargs: Additional keyword arguments that are passed to
                constructors, `_merge()` and other methods.

        Returns:
            The final `Property` value.
        """

        # if deferred merging data on creation, merge it now so there's
        # something to merge the new data into
        # XXX is this necessary when using --thisonly?
        if self._defermerge:
            self._defermerge = False
            extra = ' (in %s)' % xml_file.relpath if (
                xml_file := self.instance_in_path(Xml_file)) else ''
            logger.info('%s:merging deferred %s data%s' % (
                self.nicepath, self.varname, extra))
            self._merge(data=self._data, stack=self._stack, **kwargs)
            self._data = None
            # XXX this can indicate an error, e.g., tr-181-2-stomp.xml defined
            #     the LocalAgent rather than the STOMP model, but it's a bit
            #     hard to distinguish the expected and error cases
            # XXX we're now reporting the full path of the containing file;
            #     should replace this with the basename? (want a method)
            logger.info('%s:merged  deferred %s data%s' % (
                self.nicepath, self.varname, extra))
        # returned value is the final property value
        value = None

        # push self to stack (it's a tuple to guarantee no manipulation)
        stack = (stack or ()) + (self,)

        report = Report(self)
        if report:
            logger.info('%s: merge %r' % (report, self))

        for field_name, field_value in data or ():
            # check whether the attribute exists
            attr_name = '_' + field_name
            prop = cast(Optional[Property], getattr(self, attr_name, None))

            # if not, get it; this creates the attribute as a side effect
            if prop is None:
                prop = self.getprop(field_name)

            # if the property is still undefined, most likely there's no
            # descriptor with this name (programming error?)
            if prop is None:
                nicepath = ('%s.%s' % (self.nicepath, field_name)).replace(
                        '..', '.')
                logger.error('%s: invalid or not supported' % nicepath)
                self.getprop(field_name)
                continue

            # Attr values are used literally
            if isinstance(prop, Attr):
                value = field_value
                if report and field_name not in {'atom'}:
                    logger.info('%s: merge %s(%s)' % (
                        report, field_name, nice_string(value)))

            # Elem values populate Node objects
            else:
                prop = cast(Elem, prop)

                # if the value isn't a tuple, create a special 'atom' tuple
                if not isinstance(field_value, tuple):
                    field_value = (('atom', field_value),)

                # get the node class from the property (it can be a class or
                # a class name)
                attr_class = prop.node_cls
                if isinstance(attr_class, str):
                    attr_class = _Node.typenamed(attr_class)
                if attr_class is None:
                    nicepath = ('%s.%s' % (self.nicepath, field_name)).replace(
                            '..', '.')
                    logger.error('%s: invalid or not supported' % nicepath)
                    continue

                # XXX attr_class should always be a 'most-derived' child
                #     class; will add logic that supports vendor extension
                #     by following down the class hierarchy
                # XXX have added this logic below, but there are unintended
                #     consequences, e.g. elemname etc. now come from the
                #     most-derived class name; this needs more thought!
                # noinspection PyArgumentList
                if False and attr_class.__subclasses__():
                    temp = attr_class.__most_derived()
                    # noinspection PyUnreachableCode
                    if False:
                        logger.warning('%s -> most-derived %s' % (
                            attr_class.__name__, temp.__name__))
                    attr_class = temp

                # calculate the key and ensure it's None or a flat tuple
                # XXX should create only a mini-dict? this is rather heavy?
                # XXX I think this would be better done inside _find(); this
                #     might allow calckey() to become private (again)
                dct = dict(field_value)
                key = attr_class.calckey(self, dct, stack=stack, **kwargs)
                key = Utility.flatten_tuple(key)

                # find or create the node
                value = attr_class._find(key)
                if value is None:
                    # the constructor merges the data unless deferred (only
                    # components and models defer merging)
                    value = attr_class(key=key, parent=self, data=field_value,
                                       stack=stack, **kwargs)
                else:
                    # if the node already exists, the data is always merged
                    # (this should never happen for components, because their
                    # keys mean that they're only ever created, never updated)
                    value._mergeprep(stack=stack, report=report)
                    value._merge(data=field_value, stack=stack, **kwargs)

            # merge the property value
            prop.merge(value, report=report)

        self._mergedone(stack=stack, report=report)

        if report:
            logger.info('%s: merge %r done' % (report, self))

        # XXX should this in fact be the last merged property value?
        return value

    # XXX merge is currently an alias for _merge but might be more
    #     user-friendly, e.g. support a dictionary rather than a tuple
    merge = _merge
    """Currently an alias of `_merge()`.

    Note:
        This might become a more user-friendly version, e.g. it might
        support a dictionary rather than a tuple.
    """

    # see _Mergeable for _mergedone()

    # XXX could autogenerate default based on PropDescr() config?
    def format(self, **kwargs) -> str:
        """A formatted string representation of this node.

        The default implementation returns `keylast` or an empty string.
        """
        text = super().format(**kwargs)
        return self.keylast or text

    def __str__(self) -> str:
        """A string representation of this node.

        The default implementation returns `self.format()`, which will be
        `keylast` (if defined) or an empty string.
        """
        return self.format()

    def __repr__(self) -> str:
        return '%s(%s)' % (type(self).__name__, nice_string(str(self)))

    # if you know the property name a priori, you can do something like
    # type(obj).<name>.getprop(obj), but it's probably much the same
    def getprop(self, name: str) -> Optional[Property]:
        # get the descriptor; 's' is for plurals, and '_' is for where the
        # attribute name is a reserved word (in which case an underscore is
        # appended, e.g. 'async_'
        # XXX note that 's' is searched first so as to find 'comments' (etc.)
        #     before 'comment'; 's' attributes are not very common, so this is
        #     only mildly inefficient
        for suffix in ('s', '', '_'):
            descr = cast(Optional[PropDescr],
                         getattr(type(self), name + suffix, None))
            if descr is not None:
                break

        # get the property; if it doesn't yet exist, this will create and
        # save it (in the attribute)
        return descr.getprop(self) if isinstance(descr, PropDescr) else None

    # XXX support include and exclude arguments to control types considered
    # XXX could use mixins to control the different behaviors?
    # XXX other pieces of logic are too dependent on the exact output
    # XXX there can be multiple dots in paths, e.g. command/event parameters
    # XXX level is silly; should instead count down maxlevel
    # XXX could do more statically
    # XXX this has got out of hand!
    @cache
    def fullpath(self, *, style: str = '', level: int = 0,
                 maxlevel: Optional[int] = None) -> str:
        """
        Return this node's full path in the specified style.

        This works by concatenating the parent path (which is of course
        itself generated recursively) to this node's path component.

        Args:
            style: The type of path to generate.

                * ``<Empty>`` (default) is a verbose path including all levels
                  back to the `Root` node.
                * ``nice`` is an easy-to-read path that omits some levels.
                * ``object`` is the "conventional" object + (parameter,
                  command, event) + value path (also includes profile if
                  within a profile).

                ``object`` supports some ``+keyword`` modifiers (they're
                ignored for other styles):

                * ``+file`` includes the file name
                * ``+item`` includes abbreviation etc. item names
                * ``+component`` includes the component name at the start of
                  the path
                * ``+model`` includes the model name at the start of the path
                * ``+value`` includes enumeration and pattern values at the
                  end of the path
                * ``+notprofile`` omit the profile name

            level: The current recursion depth. This is only used for
                comparing with ``maxlevel`` and shouldn't be set by the caller.
            maxlevel: The maximum number of path components to include,
                starting with the current node. By default, all path components
                are included.

        Returns:
            The requested path.

        Note:
            1. You can use the `nicepath` property as an alternative to
               `fullpath` with ``style='nice'``.
            2. You can use the `objpath` property as an alternative to
               `fullpath` with ``style='object'``.

        Examples:
            A top-level ``Aardvark`` parameter might have this full path::

                /root=[simple.xml]/xml:file=simple.xml/dm:document=simple.xml/
                    model=Simple:1/parameter=Aardvark

            ``style='nice'`` returns ``Simple:1.Aardvark``.

            ``style='object'`` returns ``Aardvark`` (quite similar to the
            above but doesn't include the model name).

        """

        # parse style
        style_, *modifiers = style.split('+')
        assert style_ in {'', 'nice', 'object'}
        assert all(mod in {'file', 'item', 'component', 'model', 'value',
                           'notprofile'} for mod in modifiers)

        # default 'done' criterion
        done = self._parent is None or (
                maxlevel is not None and level + 1 == maxlevel)

        # default path component values
        compsep = '/'
        name = self.elemname
        typesep = '='
        value = str(self)
        term = ''

        # overrides
        if style_ == 'nice':
            if not value or not isinstance(self, (
                    AbbreviationsItem, _Command, CommandRef, Component,
                    ComponentRef, DataType, _Document, Enumeration, _Event,
                    EventRef, GlossaryItem, Import, _Input, InputRef, _Model,
                    _Object, ObjectRef, _Output, OutputRef, _Parameter,
                    ParameterRef, Pattern, Profile, Reference, Template,
                    Xml_file)):
                value = name
            if isinstance(self, (Xml_file, _Document, _Model, Profile)):
                done = True
            if isinstance(self, (_Object, ObjectRef)) and not isinstance(
                    self.parent,
                    (_Input, InputRef, _Output, OutputRef, _Event, EventRef)):
                done = True
            name = ''
            compsep = ''
            typesep = ''
            if level > 0 and value and not value.endswith('.'):
                term = '.'

        elif style_ == 'object':
            include_types = {_Command, CommandRef, _Event, EventRef, _Input,
                             InputRef, _Object, ObjectRef, _Output, OutputRef,
                             _Parameter, ParameterRef}
            include_types_more = set()
            if 'file' in modifiers:
                include_types_more |= {_Document}
            if 'item' in modifiers:
                include_types_more |= {AbbreviationsItem, DataType,
                                       GlossaryItem, Reference, Template}
            if 'component' in modifiers:
                include_types_more |= {Component}
            if 'model' in modifiers:
                include_types_more |= {_Model}
            if 'value' in modifiers:
                include_types_more |= {Enumeration, Pattern}
            if 'notprofile' not in modifiers:
                include_types_more |= {Profile}
            compsep = ''
            if value or not isinstance(self, tuple(include_types)):
                name = ''
            # XXX this isn't great; really need to have more context (could
            #     make it conditional on value but for now it's quite nice
            #     to see anonymous types (update: now ignoring anon types)
            if 'file' in modifiers and isinstance(self, Dm_document):
                done = True
            if 'item' in modifiers and isinstance(self, DataType) and value:
                typesep, term = '{', '}'
            elif 'value' in modifiers and isinstance(
                    self, (Enumeration, Pattern)):
                typesep = '.'
            else:
                typesep = ''
            if not isinstance(self, tuple(include_types | include_types_more)):
                value = ''
            if level == 0 and isinstance(self, (
                    _Command, CommandRef, _Event, EventRef, _Model)) and \
                    value.endswith('.'):
                value = value[:-1]
            if 'component' in modifiers and isinstance(self, Component):
                # XXX should review how to show component names; file?
                term = ''
            elif 'model' in modifiers and isinstance(self, _Model) \
                    and level > 0:
                term = '.'
            elif 'notprofile' not in modifiers and level > 0 and isinstance(
                    self, Profile):
                term = '.'

        # if not done, recurse to parent
        # XXX level is only incremented if value is not empty
        level1 = level + 1 if value else level
        parent_path = '' if done else self._parent.fullpath(style=style,
                                                            level=level1,
                                                            maxlevel=maxlevel)
        return parent_path + compsep + name + typesep + value + term

    @property
    def nicepath(self) -> str:
        """The node's "nice" path. Same as `fullpath()` with
        ``style='nice'``."""

        # XXX experimental; if this works well, we'll use it instead
        path = self.fullpath(style='object+item+component+value')
        # XXX for example, models
        if path == '':
            path = self.fullpath(style='object+model')
        # XXX for example, top-level imports
        if path == '':
            path = self.fullpath(style='object+file')
        return path

    # this is used with re.search(args.debugpath, node.debugpath)
    debugpath = nicepath

    @property
    def objpath(self) -> str:
        """The node's object path. Same as `fullpath()` with
        ``style='object'``."""
        return self.fullpath(style='object')

    @property
    def anchor(self) -> str:
        # XXX should distinguish anchor and target?
        notprofile = '' if isinstance(self, Profile) else '+notprofile'

        # Device:2.Device.ATM.Link.{i}.
        path = (self.fullpath(style='object+model+value%s' % notprofile) or
                str(self))

        # ignore '.{i}', '()' and '!' (name conflicts are unlikely
        path = re.sub(r'\.{i}|\(\)|!', '', path)

        # Device:2.Device.ATM.Link.
        # roughly https://pandoc.org/MANUAL.html#extension-auto_identifiers
        # (but no conversion to lower-case)
        path = re.sub(r'[^\w:.-]', '', path)

        # D.Device:2.Device.ATM.Link.
        # XXX need to extend the prefixes; get them from the class hierarchy?
        prefix_map = {AbbreviationsItem: 'A', DataType: 'T', GlossaryItem: 'G',
                      Profile: 'P', Reference: 'R'}
        prefix = prefix_map.get(type(self), 'D')
        return '%s.%s' % (prefix, path)

    @property
    def key(self) -> Key:
        """The node's key."""
        return self._key

    @property
    def keylast(self) -> Optional[str]:
        """The last component of the node's key, or ``None`` if it's
        unkeyed."""
        return self._key[-1] if self._key else None

    # XXX should be Null rather than None
    # XXX needs a type declaration
    @property
    def parent(self):
        """The node's parent node, or ``None`` if it has no parent."""
        return self._parent

    # XXX needs a type declaration
    @property
    def data(self):
        """The node's stored data, if any."""
        return self._data

    @property
    def props(self) -> tuple[Property, ...]:
        """The node's properties.

        Returns:
            A tuple of `Attr` objects followed by `Elem` objects (both
            attributes and elements are in the order in which they were
            defined).

        Note:
            This is for more advanced applications.
        """
        return self._attrs.props + self._elems.props

    # this is populated lazily as an optimization
    __typedict: dict[str, NodeOrMixinType] = {}

    @classmethod
    def __init_typedict(cls) -> None:
        if len(cls.__typedict) == 0:
            for obj in globals().values():
                if isinstance(obj, type) and \
                        issubclass(obj, (_Node, _Mixin)):
                    obj = cast(NodeOrMixinType, obj)
                    cls.__typedict[obj.__name__] = obj
                    cls.__typedict[typename(obj, lower=False)] = obj
                    cls.__typedict[typename(obj, lower=True)] = obj
                    cls.__typedict[varname(obj, safe=False)] = obj
                    cls.__typedict[varname(obj, safe=True)] = obj

    @classmethod
    def typedict(cls) -> dict[str, NodeOrMixinType]:
        cls.__init_typedict()
        return cls.__typedict

    # XXX note that only works for types in globals()
    # XXX the name is too similar to typename()
    @classmethod
    def typenamed(cls, name: str) -> Optional[NodeOrMixinType]:
        """Node or mixin type of the given name.

        Args:
            name: Name of the type. , e.g., ``dm_document``, ``object_``, or
            ``parameter``.

        Returns:
            The corresponding class object, or ``None`` if no such type exists.
        """
        cls.__init_typedict()
        return cls.__typedict.get(name, None)

    @classmethod
    def typestuple(cls, types: Optional[NodeTypes] = None, *,
                   return_scalar: bool = False) -> Optional[NodeTypes]:
        """Create an isinstance() 'types' argument, supporting a default (the
        current class) and type names such as 'model'."""
        types = types if isinstance(types, tuple) else (types,) if types else (
            cls,)
        # XXX this will contain None items for invalid type strings
        types_ = tuple(
                cls.typenamed(t) if isinstance(t, str) else t for t in types)
        return (types_[0] if types_ else None) if return_scalar else types_

    # XXX can we get rid of this in favor of varname or varname_?
    @property
    def typename(self) -> str:
        """This node's type name.

        Returns:
            The node class name with the first character converted to lower
            case.

        Note:
            The `Utility.upper_first()` function will convert a node's type
            name to its class name.
        """
        return typename(type(self))

    # XXX need to update documentation for varname and varname_
    @property
    def varname(self) -> str:
        """This node's type as a valid Python identifier.

        Returns:
            The node class name with lower-to-upper transitions replaced with
            an underscore, then converted to lower-case, and with an
            underscore appended if the result is a Python keyword.

        Examples:
            1. ``Object`` becomes ``object`` and then ``object_`` because
               it's a keyword.

            2. ``ParameterRef`` becomes ``parameter_ref``.
        """
        return varname(type(self))

    @property
    def varname_(self) -> str:
        return varname(type(self), safe=True)

    # XXX would very much like to avoid this; Property objects should handle it
    @property
    def elemname(self) -> str:
        """This node's XML element name.

        Returns:
            The XML element name.

        Note:
            This is currently done rather heuristically.
        """
        name = re.sub(r'(component|dataType|object|parameter|command|'
                      r'input|output|event)Ref$', r'\1', self.typename)
        name = lower_first(re.sub(r'(abbreviations|glossary|import|'
                                  r'reference|syntax)(.+)$', r'\2', name))
        if name.startswith('dt_') and name != 'dt_document':
            name = name[3:]
        if name == 'decimalRange' and self.parent.typename == 'decimal':
            name = 'range'
        name = name.replace('_', ':')
        return name

    # XXX would like to be able to write things like Reference.findall(); see
    #     find() below
    @classmethod
    def findall(cls, typ: Optional[Union[str, NodeType]] = None,
                predicate: Optional[Callable] = None) -> tuple[Node, ...]:
        """Find all nodes of the specified type.

        This only returns keyed nodes. It can't return unkeyed nodes because
        they aren't stored.

        Args:
            typ: Node type name or node class.
            predicate: Predicate.

        Returns:
            A possibly-empty tuple containing the nodes of the specified type.
        """
        typ_ = cls.typestuple(typ, return_scalar=True)
        return tuple(node for node in cls.__nodes.get(typ_, {}).values()
                     if predicate is None or predicate(node))

    # XXX would like to be able to write things like Reference.find(id); this
    #     would require treating a non-string initial argument specially
    #     (could require the key to be passed as a tuple?)
    # XXX this should return Null on failure, not Null; sigh...
    @classmethod
    def find(cls, typ: Union[str, NodeType], *key: Any) -> Optional[Node]:
        """Find the node of the specified type with the specified key.

        Args:
            typ: Node type name or node class.
            *key: Key components (each component is a separate argument).

        Returns:
            The referenced node, or ``None`` if not found.

        Note:
            There are very few checks, e.g. there's no check that the number
            of key components is correct for this type. Also, you have to know
            what to pass for the key.
        """
        typ_ = cls.typestuple(typ, return_scalar=True)
        # XXX could/should check that len(key_) matches instance keys?
        return typ_._find(key) if typ_ else None

    # XXX signature should allow node type names; define an alias?
    # XXX this should return Null rather than None on failure
    # XXX this should be defined on _Base0
    @classmethod
    @cache
    def instance_in_stack(cls, stack: Stack,
                          types: Optional[NodeTypes] = None,
                          predicate: Optional[Callable] = None) -> \
            Optional[Node]:
        """Search from the top (the latest entry) to the bottom (the oldest
        entry) of the stack for an instance of the specified type or types.

        Args:
            stack: Node stack. Contains an entry for every node that's
                currently being constructed or merged.
            types: Node type names or node classes. Can be a scalar or a tuple.
            predicate: Predicate.

        Returns:
            The first matching node, or ``None`` if not found.

        Note:
            The search starts with the top of the stack. Possibly there
            should be a way of ignoring the top stack entry.
        """
        assert not stack or isinstance(stack, tuple)
        types_ = cls.typestuple(types)
        # noinspection PyTypeChecker
        return None if not stack else stack[-1] \
            if isinstance(stack[-1], types_) and \
            (predicate is None or predicate(stack[-1])) else \
            cls.instance_in_stack(stack[:-1], types_, predicate)

    # XXX when it is right to return Null? if this returns Null on failure
    #     then shouldn't Null rather than None be used for parent? (maybe the
    #     moral is always to use boolean checks rather than explicit checks
    #     for None or Null?; no, because the caller needs to know whether
    #     it's safe to do self.instance_in_path(Foo).bar)
    # XXX this should be defined on _Base0
    @cache
    def instance_in_path(self, types: Optional[Union[NodeTypeNames,
                                                     NodeTypes]] = None,
                         predicate: Optional[Callable] = None, *,
                         hierarchical: bool = False) -> \
            Union[Node, NullType]:
        """Search from the current node (``self``) to its parent and so on
        up to the `Root` node for an instance of the specified type or types.

        Args:
            types: Node type names or node classes. Can be a scalar or a tuple.
            predicate: Predicate.
            hierarchical: Whether to navigate up the object hierarchy.

        Returns:
            The first matching node, or ``Null`` if not found.
        """
        cls = type(self)
        types_ = cls.typestuple(types)
        parent = lambda: self.h_parent if hierarchical else self._parent
        # noinspection PyTypeChecker
        return self if isinstance(self, types_) and (
                predicate is None or predicate(self)) else Null if \
            parent() is None else \
            parent().instance_in_path(types_, predicate,
                                      hierarchical=hierarchical)

    # XXX this is experimental
    @classmethod
    def __most_derived(cls) -> type:
        most = None
        subs = cls.__subclasses__()
        if not subs:
            # the last encountered class that has no subclasses
            most = cls
        else:
            for sub in subs:
                most = sub.__most_derived()
        return most


class _Mixin(_Mergeable):
    """Class from which all mixins are derived."""


class _Base0(_Node):
    """Class from which all node classes (other than `_Node`) are derived.

    This class defines some common attributes that can occur on all nodes,
    and also a few common methods.
    """

    xmlns_dmr = PropDescr(NamespaceStrAttr, doc='DMR namespace.')

    dmr_version = PropDescr(VersionStrAttr, doc='DMR version.',
                            deprecated='replaced by `version`')

    # XXX should move this down the hierarchy so can sometimes set as mandatory
    id = PropDescr(StrAttr, doc='Node ``id`` (mandatory for some node types).')

    # this is a simple string value
    # XXX is it correct to default it to ''
    # XXX can this move down the hierarchy?
    # XXX I think there was a reason not just to call this text?
    # XXX it was internal but this meant it wasn't in props and wasn't
    #     considered when merging; this will cause downstream problems
    #     (should consider 'internal' at a later stage)
    atom = PropDescr(StrAttr, default='', internal=False,
                     doc='Text associated with this node.')

    # XXX this is potentially confused with _HasContent.text
    text = atom
    """Alias of `atom`."""

    comments = PropDescr(ListElem, plural=True, doc="Comments.")
    cdatas = PropDescr(ListElem, plural=True, doc="Character data.")
    others = PropDescr(ListElem, plural=True, doc="Other text.")

    # this indicates whether the node is hidden; nodes can only be hidden
    # explicitly
    is_hidden = PropDescr(BoolAttr, internal=True, default=False,
                          doc="Whether this node is hidden. See `hide()` "
                              "and unhide()`.")

    # this indicates whether the node is used (referenced); it can be
    # used by transforms and output formats (None means 'unknown')
    # XXX should transforms be given an opportunity to add fields?
    is_used = PropDescr(BoolAttr, internal=True,
                        doc="Whether this node is used. See `mark_unused()` "
                            "and `mark_used()`.")

    def hide(self) -> None:
        self.is_hidden = True
        for elem in self.elems:
            elem.hide()

    def unhide(self, *, description: bool = False,
               upwards: bool = False) -> None:
        self.is_hidden = False
        if description and hasattr(self, 'description'):
            self.description.unhide()

        if not upwards:
            for elem in self.elems:
                elem.unhide()
        elif self.parent:
            self.parent.unhide(description=True, upwards=True)

    def h_hide(self) -> None:
        self.is_hidden = True
        for elem in self.h_elems:
            elem.h_hide()

    def h_unhide(self, *, description: bool = False,
                 upwards: bool = False) -> None:
        self.is_hidden = False
        if description and hasattr(self, 'description'):
            self.description.unhide()

        if not upwards:
            for elem in self.h_elems:
                elem.h_unhide()
        elif self.h_parent:
            self.h_parent.h_unhide(
                    description=description, upwards=True)

    # XXX all 'global' types should call this in _mergedone(); should use the
    #     class hierarchy for this rather than adding explicit calls
    def mark_unused(self) -> None:
        """Mark this node as being unused.

        This also (recursively) marks its `elems` as being unused.

        See the `usedTransform` for more details and for examples.
        """
        self.is_used = False
        for elem in self.elems:
            elem.mark_unused()

    def mark_used(self, *, upwards: bool = False) -> None:
        """Mark this node as being used.

        This also (recursively) marks its `elems` as being used.

        See the `usedTransform` for more details and for examples.
        """
        self.is_used = True
        if not upwards:
            for elem in self.elems:
                elem.mark_used()
        elif self.parent:
            self.parent.mark_used(upwards=True)

    def h_mark_unused(self) -> None:
        self.is_used = False
        for elem in self.h_elems:
            elem.h_mark_unused()

    def h_mark_used(self, *, upwards: bool = False) -> None:
        self.is_used = True
        if not upwards:
            for elem in self.h_elems:
                elem.h_mark_used()
        elif self.h_parent:
            self.h_parent.h_mark_used(upwards=True)

    # this searches the node's ancestors for the attribute
    @property
    def xmlns_dmr_inherited(self) -> Optional[str]:
        """The `xmlns_dmr` attribute that applies to this node.

        The value is taken from this node or the nearest ancestor that
        defines the attribute.

        Returns:
            `xmlns_dmr` value, or ``None`` if neither this node nor any
            ancestors define it.
        """
        return self.xmlns_dmr if self.xmlns_dmr is not None else \
            self._parent.xmlns_dmr_inherited if self._parent else None

    # XXX this should return Null rather than None (general point)
    @property
    @cache
    def h_parent(self) -> Optional['_Base']:
        return self._parent

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return self.elems

    # the next four properties (attrs, attrs_props, elems and elems_props)
    # could be defined on _Node, but are defined here so elems can be
    # declared to return _Base instances, which means that mark_unused() and
    # mark_used() (and any future _Base methods) are type-safe

    @property
    def attrs(self) -> dict[str, str]:
        """The node's attributes (in the XML sense).

        This only contains attributes that were explicitly defined in the
        input file or have been subsequently created.

        Returns:
            A dictionary mapping attribute names to their string values (in
            the order in which they were defined).

        Note:
            1. This is a snapshot, and modifying it won't modify the node.
            2. If you need more control, you can use `attrs_props` to get the
               underlying `Attr` objects.
        """
        return self._attrs.value

    # XXX would this be more useful as a dictionary?
    @property
    def attrs_props(self) -> tuple[Attr, ...]:
        """The node's attribute properties.

        Returns:
            A tuple of `Attr` objects (in the order in which they were
            defined).

        Note:
            This is for more advanced applications.
        """
        return self._attrs.props

    @property
    def elems(self) -> tuple[Node, ...]:
        """The node's child elements (in the XML sense). Each element is a
        node.

        This only contains elements that were explicitly defined in the
        input file or have been subsequently created.

        Returns:
            A tuple of nodes (in the order in which they were defined).

        Note:
            1. This is a snapshot, and modifying it won't modify the node.
            2. If you need more control, you can use `elems_props` to get the
               underlying `Elem` objects.
        """
        return self._elems.value

    @property
    def elems_props(self) -> tuple[Elem, ...]:
        """The node's element properties.

        Returns:
            A tuple of `Elem` objects (in the order in which they were
            defined).

        Note:
            This is for more advanced applications.
        """
        return self._elems.props

    auto_macro_criteria = {}


# this is the base for DM documents and models, whereas DT documents and
# models (like all other node classes) are derived from _Base0
class _Base(_Base0):
    status = PropDescr(EnumObjAttr, enum_cls=StatusEnum, doc='Node status.')

    version = PropDescr(VersionStrAttr, doc='Node version (added in DM v1.7).')

    # this searches the node's ancestors for the attribute
    @property
    def version_inherited(self) -> Optional[Version]:
        """The `version` attribute that applies to this node.

        The value is taken from this node or the nearest ancestor that
        defines the attribute.

        Returns:
            `version` value, or ``None`` if neither this node nor any
            ancestors define it.
        """
        return self.version if self.version is not None else \
            self.dmr_version if self.dmr_version is not None else \
            self._parent.version_inherited if self._parent is not None \
            else None

    # this searches the node's ancestors for the attribute
    @property
    @cache
    def h_version_inherited(self) -> Optional[Version]:
        """The `version` attribute that applies to this node.

        The value is taken from this node or the nearest ancestor that
        defines the attribute.

        Returns:
            `version` value, or ``None`` if neither this node nor any
            ancestors define it.
        """
        return self.version if self.version is not None else \
            self.dmr_version if self.dmr_version is not None else \
            self.h_parent.h_version_inherited if \
                self.h_parent is not None else None

    # XXX I have a feeling that status_inherited and h_status_inherited
    #     could be simplified!
    # XXX they should definitely be reviewed, and it would be good to permit
    #     None and/or str in place of Status instances
    # can't be nested, because is referenced from h_status_inherited()
    def status_inherited_helper(self, highest: StatusEnum) -> StatusEnum:
        if self.status > highest:
            highest = self.status
        return self.parent.status_inherited_helper(highest) if self.parent \
            else highest

    # note that this is the highest status in the hierarchy, not the first
    # encountered status
    @property
    @cache
    def status_inherited(self) -> StatusEnum:
        return self.status_inherited_helper(StatusEnum())

    # can't be nested, because is referenced from h_status_inherited()
    def h_status_inherited_helper(self, highest: StatusEnum) -> StatusEnum:
        if self.status > highest:
            highest = self.status
        h_parent = self.h_parent
        if h_parent is None:
            return highest
        elif isinstance(h_parent, Object):
            return h_parent.h_status_inherited_helper(highest)
        else:
            return h_parent.status_inherited_helper(highest)

    @property
    @cache
    def h_status_inherited(self) -> StatusEnum:
        return self.h_status_inherited_helper(StatusEnum())

    # properties for the containing model etc.
    # XXX could add more? should add fewer?
    # XXX would like these not all to be top-level properties; how best to
    #     achieve this?
    @property
    @cache
    def model_in_path(self) -> Union['Model', NullType]:
        return self.instance_in_path(Model)

    # XXX do we also need h_object_in_path?
    @property
    @cache
    def object_in_path(self) -> Union['Object', NullType]:
        return self.instance_in_path(Object)

    @property
    @cache
    def parameter_in_path(self) -> Union['Parameter', NullType]:
        return self.instance_in_path(Parameter)

    @property
    @cache
    def command_in_path(self) -> Union['Command', NullType]:
        return self.instance_in_path(Command)

    @property
    @cache
    def event_in_path(self) -> Union['Event', NullType]:
        return self.instance_in_path(Event)

    @property
    @cache
    def profile_in_path(self) -> Union['Profile', NullType]:
        return self.instance_in_path(Profile)


class _Text(_Base):
    """A simple text element with no whitespace processing.

    This doesn't add any new attributes, because its text is stored in the
    `atom` attribute, which is defined on `_Base`.
    """

    def format(self, **kwargs) -> str:
        """The value of the `_Base.text` attribute."""
        return self.text or ''


# noinspection PyPep8Naming
class Xml_decl(_Text):
    """An XML declaration line."""


class Comment(_Text):
    """An XML comment."""


class Other(_Text):
    """XML "other" text. This only occurs outside the XML root element,
    i.e. at the top and the bottom of the file. Most "other" text is just
    whitespace, but it's also used for XML entity declarations."""


class Cdata(_Text):
    """XML "cdata" (character data) text. This only occurs within XML
    elements."""


# XXX processing should potentially be deferred until the text is accessed,
#     in which case we wouldn't need the content property
class _HasContent(_Base):
    """A complex text element with whitespace processing, e.g., `Description`.
    """

    content = PropDescr(ContentAttr, internal=True, default=Content,
                        doc="Content associated with this node (the content "
                            "is taken from child (XML) elements).")

    def _mergedone(self, *, stack=None, report=None):
        """Collect text from child elements.

        Note:
            This is rather tricky because, having collected the text, it's
            necessary to remove (or otherwise disable) the child elements,
            since otherwise the text would be output twice: once via the
            `content` attribute and once when reporting on the children.
        """

        # collect child elem text into this node's content; this calls
        # property.ContentAttr._merge(), which calls Utility.whitespace()
        self.content = self._elems.value

        # we've collected the content, so we don't want to iterate over elems
        # XXX should be clear that we expect only Cdata etc. children here
        # XXX should instead have a way of marking them as "ignore"
        for prop in self._elems.props:
            self._elems.remove(prop, report=report)

        super()._mergedone(stack=stack, report=report)

    # XXX this is potentially confused with _Base.text
    @property
    def text(self) -> str:
        """The `_HasContent.content` attribute's raw text."""
        return cast(Content, self.content).text or ''

    # XXX this is the only property setter! is this appropriate?
    # XXX should this only change the content if the text has changed?
    # XXX it's not at all obvious that self.content should be set to text
    #     rather than to a Content instance! should allow this too?
    @text.setter
    def text(self, value: str):
        self.content = value

    def format(self, **kwargs) -> str:
        """The `_HasContent.content` attribute's raw text."""
        return self.text


class Root(_Base):
    """The root of an application's node tree.

    XML files specified on the command line will become children of the
    application's `Root` node, whereas imported XML files will become
    children of the appropriate `Import` node.
    """

    xml_files = PropDescr(ListElem, plural=True,
                          doc='XML files specified on the command line.')

    def __init__(self, *, key: Key = None, stack: Optional[Stack] = None,
                 args: argparse.Namespace = None, **kwargs):
        """Root node constructor.

        Stores `args` as a `_Node` class attribute (so it's available to
        all nodes) and then calls the base class constructor.

        Only additional arguments (specific to this class) are listed.

        Args:
            args: The script's command-line arguments.
        """

        # command line arguments must be passed to the Root constructor, and
        # must include certain mandatory ones
        mandatory = {'debugpath', 'dirs', 'output', 'parser', 'recursive',
                     'thisonly'}
        assert args and all({hasattr(args, a) for a in mandatory})
        _Node.args = args

        super().__init__(key=key, stack=stack, **kwargs)

        # create primitive data type instances
        _Primitive.init(parent=self)

    # XXX the method name should imply both search and parse
    # XXX will need to provide basic XSD support; where? how?
    @classmethod
    def parse(cls, file: str, *, spec: Optional[Spec] = None,
              ignore_spec: bool = False,
              parent: Optional[Union['Root', 'Import']] = None,
              stack: Optional[Stack] = None) -> Optional['Xml_file']:
        """Find, parse and merge an XML file. All files are parsed via this
        method.

        The file's data is merged into the supplied parent node. This will
        (as a side effect) add a new `Xml_file` instance to the parent's
        `xml_files` attribute.

        Args:
            file: The file to parse.
            spec: The expected value of the `Dm_document.spec` attribute. If
                specified, only files with matching specs will be considered.
            ignore_spec: If ``True``, the spec is ignored (this allows other
                problems to be detected, e.g., when a local file spec has
                been changed but the referencing file spec hasn't been changed)
            parent: The parent node. This will always be either a `Root` or
                an `Import` node, and must be specified.
            stack: Node stack. Contains an entry for every node that's
                currently being constructed or merged.

        Returns:
            The newly-created `Xml_file` instance, or ``None`` on failure.
        """

        # parent must have an xml_files attribute, e.g. Root or Import
        # XXX should check this here
        assert parent is not None

        # command-line arguments
        args = cls.args

        # find the file
        realpath = File.find(file, spec=spec, ignore_spec=ignore_spec,
                             dirs=args.dirs, nocurdir=args.nocurdir,
                             recursive=args.recursive)
        # if can't find it, try again with an all lower-case filename
        # XXX this is a hack to work around the misnamed TR-140-1-0-2.xml
        if realpath is None and file.lower() != file:
            realpath = File.find(file.lower(), spec=spec, dirs=args.dirs,
                                 nocurdir=args.nocurdir,
                                 recursive=args.recursive)
        if realpath is None:
            places = []
            if not args.nocurdir:
                places += [os.curdir]
            if args.dirs:
                places += args.dirs
            extra1 = f' with spec {spec}' if spec else ''
            extra2 = f' in {Utility.nicer_list(places, last="or")}' if places \
                else ''
            logger.error(f"{parent.nicepath}: can't find file {file!r}"
                         f"{extra1}{extra2}")
            return None

        # see whether we've already parsed it
        key = Xml_file.calckey(parent, {}, realpath=realpath)
        key = Utility.flatten_tuple(key)
        xml_file = Xml_file._find(key)
        relpath = os.path.relpath(realpath)
        if xml_file:
            logger.debug(f'already parsed {relpath!r}')
            parent.xml_files += [xml_file]
            return xml_file

        # parse it if not
        logger.info(f'parsing {relpath!r}')
        data = args.parser.parse(realpath, args=args)
        logger.info(f'parsed  {relpath!r}')

        # wrap it in 'xml_file'
        data_ = (('xml_file', data),)

        # filter it
        data_ = Root._filter(data_, spec=args.filter)

        # merge into the parent; this creates and returns a Xml_file instance
        logger.debug(f'merging {relpath!r}')
        xml_file = parent.merge(data=data_, stack=stack, realpath=realpath)
        logger.debug(f'merged  {relpath!r}')

        # force merge of any top-level models
        if isinstance(parent, Root):
            for model in xml_file.document.models:
                model.merge(stack=stack)

        # return the Xml_file instance
        return xml_file

    @staticmethod
    def _filter(data: Data, *, spec: Optional[list[str]] = None) -> Data:
        # return the input if there's no spec or the data isn't a tuple
        if not spec or not isinstance(data, tuple):
            return data

        # helper to check whether a given (name, value) should be included
        # XXX this is currently very limited
        def predicate(nam: str, val: Data) -> bool:
            # assume that a multi-item spec is a list of items to include; all
            # items of interest from 'xml_file' downwards must be provided
            # (this is intended for dependency generation)
            if len(spec) > 1:
                return nam in spec

            # otherwise assume a string of the form 'elemname=elemval' and
            # return True for all items except those with a matching elemname
            # and a non-matching elemval
            else:
                elemname, elemval = spec[0].split('=')
                return nam != elemname or not isinstance(val, tuple) or \
                    val[0][1].startswith(elemval)

        # return the filtered tuple
        return tuple(
                (name, Root._filter(value, spec=spec)) for name, value in data
                if predicate(name, value))

    # XXX use just the filename? or dir/filename if ambiguous?
    def format(self, **kwargs) -> str:
        """The value of the `xml_files` attribute, formatted as a compact
        string."""
        return nice_list(cast(list, self.xml_files),
                         style='compact') if self.xml_files else ''


# noinspection PyPep8Naming
class Xml_file(_Base):
    """An XML file."""

    # XXX should provide an attribute that's just the simple filename; can
    #     use str() but it might include a partial path
    xml_decl = PropDescr(SingleElem, doc="File's XML declaration line.")

    # XXX can't express that allow only one of dm_document and dt_document
    dm_document = PropDescr(SingleElem, doc="File's DM document element.")
    dt_document = PropDescr(SingleElem, doc="File's DT document element.")

    # key is always the full path (realpath)
    @classmethod
    def calckey(cls, parent: Node, dct: dict, *,
                realpath: Optional[str] = None, **kwargs) -> Key:
        """The full file path ("real path")."""
        # realpath must be supplied
        assert realpath is not None
        return realpath

    # XXX should return this via format(relpath=True)?
    @property
    def relpath(self) -> str:
        return os.path.relpath(self.keylast)

    @property
    def document(self) -> Union['Dm_document', 'Dt_document', NullType]:
        return self.dm_document or self.dt_document

    # XXX could/should disambiguate (like Emacs) when multiple files have
    #     the same name
    def format(self, **kwargs) -> str:
        """The filename part of the full path name.

        The file extension (always ``.xml``) is omitted.
        """

        *_, file = Utility.path_split_drive(self.keylast)
        file, _ = os.path.splitext(file)
        return file


# XXX descriptions are so widely supported that perhaps should just add this
#     to _Base (as we've done with status)
class _HasDescription(_Base):
    """Base class for nodes that can have a `Description`.
    """

    description = PropDescr(DescriptionSingleElem, doc="Description.")

    @property
    def description_inherited(self) -> Union['Description', NullType]:
        return self.description


class _Document(_Mixin):
    XMLNS_DMR_ORIGINAL_URN = 'urn:broadband-forum-org:cwmp:datamodel-report' \
                             '-0-1'
    XMLNS_DMR_LATEST_URN = 'urn:broadband-forum-org:cwmp:datamodel-report-1-0'
    XMLNS_DMR_LATEST_LOCATION = 'https://www.broadband-forum.org/cwmp/cwmp' \
                                '-datamodel-report-1-0.xsd'

    xmlns_dm = PropDescr(NamespaceStrAttr, doc='DM namespace.')

    xmlns_xsi = PropDescr(NamespaceStrAttr, doc='XML XSI namespace.')
    xsi_schemaLocation = PropDescr(NamespaceStrDictAttr,
                                   doc='XSI schema location.')

    @property
    def file_safe(self) -> FileName:
        raise NotImplementedError

    # optional additional info
    # XXX this needs review, and perhaps extension
    @property
    def file_info(self) -> dict[str, Optional[str]]:
        return {}


# noinspection PyPep8Naming
class Dm_document(_HasDescription, _Document):
    """A DM document.
    """

    file = PropDescr(FileNameStrAttr, mandatory=True,
                     doc='File name (added in DM v1.4)')
    spec = PropDescr(SpecStrAttr, mandatory=True, doc='Spec URN.')

    imports = PropDescr(ListElem, plural=True, doc="Imports.")
    dataTypes = PropDescr(ListElem, plural=True, doc="Data types.")
    glossary = PropDescr(SingleElem, doc="Glossary.")
    abbreviations = PropDescr(SingleElem, doc="Abbreviations.")
    bibliography = PropDescr(SingleElem, doc="Bibliography.")
    templates = PropDescr(ListElem, plural=True, doc="Templates.")
    components = PropDescr(ListElem, plural=True, doc="Components.")
    models = PropDescr(ListElem, plural=True, doc="Models.")

    # XXX for testing, allow various other top-level elements that aren't
    #     permitted by the schema (this is hardly worth it?)
    objects = PropDescr(ListElem, plural=True)
    parameters = PropDescr(ListElem, plural=True)
    commands = PropDescr(ListElem, plural=True)
    events = PropDescr(ListElem, plural=True)

    # key is always the full path (realpath)
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Xml_file`'s key (the full file path)."""
        xml_file = parent.instance_in_path(Xml_file)
        assert xml_file is not None and xml_file.key is not None
        return xml_file.key

    def __init__(self, *, key=None, parent=None, data=None, stack=None,
                 **kwargs):
        """DM document node constructor.

        If this document is being imported, check that its `file` and `spec`
        match the `Import`. Then call the base call constructor.

        Arguments are the same as for the base class constructor.

        Note:
            The `file` and `spec` aren't yet checked against the `Import`.
        """

        # if importing, check the dm_document's file and spec match the import
        # file and spec (the top of the stack will be (..., Import, Xml_file)
        # (do this before calling the super-class constructor, because it may
        # handle recursive imports, so checks would be reversed)
        if len(stack) > 1 and isinstance(stack[-2], Import):
            imp = cast(Import, stack[-2])
            dct = dict(data)
            file = dct.get('file')
            spec = dct.get('spec')
            # XXX not yet implemented; will make file and spec attributes be
            #     objects with appropriate methods for accessing fields,
            #     comparing etc.; can base on file.File.__parsename().Result
            # XXX it seems that _mergedone() now checks this; is this routine
            #     no longer needed?
            logger.debug(f'import  {imp.file!r} {imp.spec!r} -> {file!r} '
                         f'{spec!r}')

        super().__init__(key=key, parent=parent, data=data, stack=stack,
                         **kwargs)

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `spec` attribute was specified, and that (if it was
        specified), the `file` and `spec` attributes match."""
        if self.spec is None:
            logger.error('%s.spec: missing attribute' % self.nicepath)

        if self.file is not None and self.spec is not None and not \
                cast(Spec, self.spec).matches(cast(FileName, self.file)):
            logger.warning(f"{self.nicepath}: spec is {self.spec} (doesn't "
                           f"match {self.file})")

        super()._mergedone(stack=stack, report=report)

    # document's local and imported entities (dataTypes, components, models),
    # as a dictionary mapping name to entity or its import
    # XXX need to rewrite this to use public attributes
    # XXX could use an _ImportEntity method to avoid need for getattr()?
    def entity_dict(self, attr):
        assert attr in {'dataTypes', 'components', 'models'}
        return {e.name: e for e in (
                getattr(self, attr) + [e for i in self.imports for e in
                                       getattr(i, attr)])}

    # the file attribute, taken from the XML file name if not defined
    @property
    def file_safe(self) -> FileName:
        assert isinstance(self.parent, Xml_file)
        return self.file or FileName(os.path.basename(self.parent.keylast))

    def format(self, **kwargs) -> str:
        """The value of the `file` attribute, or the parent `Xml_file`'s
        filename if it isn't set.

        The file extension (always ``.xml``) is omitted.
        """

        file = str(self.file_safe)
        file, _ = os.path.splitext(file)
        return file


class Description(_HasContent):
    """A description element.
    """

    action = PropDescr(EnumObjAttr, enum_cls=ActionEnum,
                       doc='How to combine new content with existing content.')


class Import(_Base):
    """An import element.
    """

    file = PropDescr(FileNameStrAttr, mandatory=True, doc='File to import.')
    spec = PropDescr(SpecStrAttr, doc='Spec expected in the imported file.')
    dataTypes = PropDescr(ListElem, plural=True, node_cls='ImportDataType',
                          doc='Data types to import.')
    components = PropDescr(ListElem, plural=True, node_cls='ImportComponent',
                           doc='Components to import.')
    models = PropDescr(ListElem, plural=True, node_cls='ImportModel',
                       doc='Models to import.')

    # this is set in _mergedone()
    xml_files = PropDescr(ListElem, plural=True, internal=True,
                          doc='Imported `Xml_file` (a list with zero or one '
                              'entry).')

    # XXX should avoid duplicate stack Import entries
    # XXX need to rewrite this to use Attr and Elem properly
    def _mergedone(self, *, stack=None, report=None):
        """Parse the imported file and find the imported entities.

        If the `file` attribute wasn't specified or the ``--thisonly``
        command-line option was specified, there's nothing to do.

        Otherwise, call `Root.parse()` to parse the file, get the
        newly-created `Dm_document` instance, and find the imported entities.

        Note:
            The code for finding the imported entities is rather complex and
            really needs to be re-written.
        """

        # if no file attribute was specified, can't proceed
        if self.file is None:
            logger.error('%s.file: missing attribute' % self.nicepath)
            return

        # if processing this file only, don't parse the imported file, but do
        # create empty proxy entities
        if self.args.thisonly:
            for import_entity in self.dataTypes + self.components + \
                                 self.models:
                attr_name = import_entity.elemname
                attr_class = _Node.typenamed(attr_name)
                name = import_entity.name
                proxy = attr_class(data=(('name', name),),
                                   stack=stack, report=report)
                setattr(import_entity, attr_name, proxy)
            return

        # if xml_files is set, this is the second (recursive) invocation
        # when the file (parsed below) contents have been merged into this obj
        if len(self.xml_files) > 0:
            return

        # a spec attribute should always be specified
        if self.spec is None:
            logger.error('%s: import %s has missing spec attribute' %
                         (self.nicepath, self.file))

        # parse the imported file (ignore the spec when there are fewer than
        # two files on the command line, so we can detect when a local file
        # spec has been changed but the referencing file spec hasn't been
        # changed)
        ignore_spec = len(self.args.file) < 2
        xml_file = Root.parse(str(self.file), spec=self.spec,
                              ignore_spec=ignore_spec, parent=self,
                              stack=stack)
        if xml_file is None or len(self.xml_files) != 1:
            # assume that the problem has already been reported
            # XXX should we return on error? we won't call the super() method
            return

        # get its dm_document; if it's Null it means that this XML file is
        # already being imported (it's been parsed but is still being merged)
        # XXX should we return on error? we won't call the super() method
        dm_document = xml_file.dm_document
        if dm_document is Null:
            logger.error(f"{self.nicepath}: can't import {xml_file.keylast!r} "
                         f"because it's already being processed")
            return

        # check that document file and spec match the import
        if self.spec and not dm_document.spec.matches(self.spec):
            logger.warning(f"{self.nicepath}: import {self.file}: spec is "
                           f"{dm_document.spec} (doesn't match {self.spec})")

        # find the imported entities
        # XXX this needs to be re-written properly for accessors / properties
        for import_entity in self.dataTypes + self.components + self.models:
            attr = import_entity.elemname
            name = import_entity.name
            ref = import_entity.ref
            entity = import_entity.find_entity(dm_document)
            if not entity:
                logger.error("%s: can't find %s %s (in %s)" % (
                    self.nicepath, attr, ref or name, xml_file.relpath))
            else:
                extra = ' as %s' % name if name and ref and name != ref else ''
                logger.debug('%s: imported %s %s%s (from %s)' % (
                    self.nicepath, attr, ref or name, extra, xml_file.relpath))
                # set the corresponding attribute
                setattr(import_entity, attr, entity)
                # XXX temporarily also set the '_entity' attribute
                import_entity._entity = entity
                # XXX this should be handled (much) better
                if attr == 'dataType':
                    depth = len([n for n in stack if isinstance(n, Xml_file)])
                    always = (depth == 1)
                    import_entity.update_entities(name, always=always)

        super()._mergedone(stack=stack, report=report)

    # imported entities (dataTypes, components, models), as a dictionary
    # mapping name to entity or its import; c.f. Dm_document.entity_dict()
    # XXX could use an _ImportEntity method to avoid need for getattr()? or
    #     see below re using fixed '_entity' attribute name
    def entity_dict(self, attr):
        assert attr in {'dataType', 'component', 'model'}
        return {e.name: e for e in getattr(self, attr)}

    def format(self, **kwargs) -> str:
        """The name of the imported file.

        The file extension (always ``.xml``) is omitted.
        """

        file = str(self.file)
        file, _ = os.path.splitext(file)
        return file


# accessor for an imported or locally-defined entity
# XXX Details of exactly what this means and how it's used are TBD
class _Accessor(_Mixin):
    def __init__(self):
        # XXX alarm bell: attributes aren't affected by merge()
        self._entity = None
        super().__init__()

    # all encountered entity imports and definitions; entries are (name,
    # entity) tuples, where name is the local name (it can be different from
    # the entity name for an import)
    # XXX the rules for which entity definitions apply in a given context
    #     are rather complicated (and possibly not really well-defined);
    #     effectively the first encountered definition should be used, e.g.
    #     the USP Alias data type definition should be used, even though
    #     Alias in the context of common definitions is the common one
    # XXX would call it _entities or __entities, but that would require a
    #     class property, and that requires metaclasses; it's not worth it!
    entities = {}

    # XXX should accessors have names? if so, we'd default to using
    #     the accessor name here
    # XXX actually the code assumes that entities DO have names; need to fix
    def update_entities(self, name, *, always=False):
        if always or name not in self.entities:
            entity = self.entity  # note that this uses the property accessor
            # XXX have disabled this deletion; it (for example) deleted the
            #     _AliasUSP entry when it was imported as Alias (surely it
            #     does no harm to retain the original; it's needed!)
            # if entity.name in self.entities:
            #     del self.entities[entity.name]
            self.entities[name] = (name, entity)

    # XXX perhaps None shouldn't mean self? it's too dangerous a default?
    @property
    def entity(self):
        return self._entity or self


# XXX each derived class has its own entities; this isn't a nice solution
class DataTypeAccessor(_Accessor):
    """`DataType` accessor."""
    entities = {}

    # maps data type names to the public names by which they were imported
    # (primarily intended for _AliasCWMP / _AliasUSP imported as Alias)
    @classmethod
    def public_map(cls) -> dict[str, str]:
        return {data_type.name: name for name, data_type in
                cls.entities.values() if
                not name.startswith('_') and name != data_type.name}


class ComponentAccessor(_Accessor):
    """`Component` accessor."""
    entities = {}


class ModelAccessor(_Accessor):
    """`Model` accessor."""
    entities = {}


# XXX should use '_entity' here rather than '_dataType' etc. in derived classes
# XXX now we have _Entity we should extract common entity code, e.g. lookup
class _ImportEntity(_Base):
    """Import a `DataType`, `Component` or `Model` from another file."""

    name = PropDescr(StrAttr, mandatory=True, doc='Entity name in this file.')
    ref = PropDescr(StrAttr, doc='Entity name in the other file. If not '
                                 'specified, the name in the other file is '
                                 'the same as the name in this file.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Dm_document` key and the `_ImportEntity.name`
        attribute."""
        assert parent.instance_in_path(Dm_document) is not None
        return parent.instance_in_path(Dm_document).key, dct.get('name')

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `name` attribute was specified."""
        if self.name is None:
            logger.error('%s.name: missing attribute' % self.nicepath)

        super()._mergedone(stack=stack, report=report)

    # find and return the referenced entity
    # XXX would like to avoid use of getattr()
    def find_entity(self, document):
        attr = self.elemname
        entity_dict = document.entity_dict(attr + 's')
        entity_or_import = entity_dict.get(self.ref or self.name)
        if entity_or_import is None:
            entity = None
        elif not isinstance(entity_or_import, _ImportEntity):
            entity = entity_or_import
        else:
            entity = getattr(entity_or_import, attr)
        return entity

    def format(self, **kwargs) -> str:
        """A string of the form ``{thisfile}name={otherfile}ref``,
        where ``ref`` is ``name`` if not specified."""
        name = self.name or ''
        ref = self.ref or name
        # XXX should add a utility for this? remove the file extension?
        doc = cast(Dm_document, self.instance_in_path(Dm_document))
        imp = cast(Import, self.instance_in_path(Import))
        assert doc is not None and imp is not None
        *_, docfile = Utility.path_split_drive(doc.file_safe.name)
        *_, impfile = Utility.path_split_drive(imp.file.name)
        return f'{{{docfile}}}{name}={{{impfile}}}{ref}'


class ImportDataType(_ImportEntity, DataTypeAccessor):
    """Import a `DataType`.
    """

    dataType = PropDescr(SingleElem, node_cls='ImportDataType', internal=True,
                         doc='Imported data type.')


class ImportComponent(_ImportEntity, ComponentAccessor):
    """Import a `Component`.
    """

    component = PropDescr(SingleElem, node_cls='ImportComponent',
                          internal=True, doc='Imported component.')


class ImportModel(_ImportEntity, ModelAccessor):
    """Import a `Model`.
    """

    model = PropDescr(SingleElem, node_cls='ImportModel', internal=True,
                      doc='Imported model.')


class _HasValueMixin(_Mixin):
    # this is called for all facets, and so needs to be tolerant of unexpected
    # value types
    def is_valid_value(self, value: Any, *,
                       length: Optional[int] = None,
                       nopatterncheck: bool = False,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        assert not kwargs, '%s: unsupported is_valid_value() arguments %s' % \
                           (type(self).__name__, kwargs)
        return True


class _DataTypeBase(_HasDescription, _HasValueMixin):
    """Base class for `DataType`, `_HasPrimitives` (and their derived
    classes)."""

    @property
    def primitive(self) -> Union['_Primitive', NullType]:
        raise NotImplementedError

    @property
    def primitive_inherited(self) -> Union['_Primitive', NullType]:
        return self.primitive

    # XXX experimental mechanism for giving nodes a chance to review (and
    #     modify?) proposed updates; should be generalized
    def proposed_update(self, other: '_DataTypeBase') -> Any:
        logger.debug('%s: proposed update %s -> %s' % (
            self.nicepath, self, other))


# XXX I don't like this name; _HasXXX is ambiguous: mainline or mixin?
class _HasPrimitives(_DataTypeBase):
    """TBD.

    Note:
        Zero or one of the primitive type elements can be present, but this is
        not checked at this level.
    """

    base64 = PropDescr(SingleElem, doc='BASE64.')
    boolean = PropDescr(SingleElem, doc='Boolean.')
    dateTime = PropDescr(SingleElem, doc='Date and time.')
    decimal = PropDescr(SingleElem, doc='Decimal.')
    hexBinary = PropDescr(SingleElem, doc='Hex binary.')
    int = PropDescr(SingleElem, doc='Int.')
    long = PropDescr(SingleElem, doc='Long.')
    string = PropDescr(SingleElem, doc='String.')
    unsignedInt = PropDescr(SingleElem, doc='Unsigned int.')
    unsignedLong = PropDescr(SingleElem, doc='Unsigned long.')

    # collect all the primitive type names
    primitive_types = tuple(n for n, v in vars().items()
                            if isinstance(v, PropDescr))

    # XXX this was defined statically as self._primitives in _mergedone() but
    #     this creates problems on update, because only props are merged
    @property
    def primitives(self) -> list['_Primitive']:
        return [elem for elem in self.elems if isinstance(elem, _Primitive)]

    @property
    def primitive(self) -> Union['_Primitive', NullType]:
        prims = self.primitives
        return prims[-1] if prims else Null

    # XXX there are two levels of human? (1) the title text, and (2) what
    #     can be included in the description (make this be human+verbose?)
    def format(self, *, prim: bool = False, human: bool = False,
               **kwargs) -> str:
        """TBD."""

        super().format(**kwargs)

        # there should be 0 or 1, but we don't care at this level
        text = ', '.join(primitive.format(prim=prim, human=human, **kwargs)
                         for primitive in self.primitives)
        return text


class _FacetMixin(_HasValueMixin):

    # XXX need to implement this for the remaining derived classes
    @classmethod
    def is_valid_update(cls, old: 'DataType', new: 'DataType',
                        expand: bool = False,
                        errors: Optional[list[str]] = None,
                        **kwargs) -> bool:
        assert not kwargs, '%s: unsupported is_valid_update() arguments %s' \
                           % (cls.__name__, kwargs)
        return True


# XXX there should be a more obvious connection between mixins (derived from
#     _FacetMixin) and their facets (derived from _Facet), e.g., between
#     _HasList and List
class _HasList(_FacetMixin):
    """Mixin indicating support for the `List` facet."""

    list = PropDescr(SingleElem, doc='List facet.')

    # the list facet isn't inherited, so don't need list_inherited()


class _HasSizes(_FacetMixin):
    """Mixin indicating support for the `Size` facet."""

    sizes = PropDescr(ListElem, plural=True, doc='Size facet.')

    @property
    def sizes_inherited(self) -> list['Size']:
        return self.sizes or []

    @classmethod
    def is_valid_update(cls, old: 'DataType', new: 'DataType', *,
                        expand: bool = False,
                        errors: Optional[list[str]] = None,
                        **kwargs) -> bool:
        if not super().is_valid_update(old, new, expand=expand,
                                       errors=errors, **kwargs):
            return False

        old_sizes = old.sizes_inherited
        new_sizes = new.sizes_inherited
        if not old_sizes or not new_sizes or new_sizes is old_sizes:
            return True

        sizes_errors = []
        old_pranges = _PrangeFacet.prange_clean(old_sizes, errors=sizes_errors)
        new_pranges = _PrangeFacet.prange_clean(new_sizes, errors=sizes_errors)

        haystack_sizes = new_pranges if expand else old_pranges
        needle_sizes = old_pranges if expand else new_pranges

        valid = _PrangeFacet.prange_check(haystack_sizes, needle_sizes,
                                          expand=expand, errors=sizes_errors)
        if sizes_errors and errors is not None:
            errors.append('sizes: %s' % '; '.join(sizes_errors))
        return valid

    def is_valid_value(self, value: Any, *,
                       length: Optional[int] = None,
                       errors: Optional[list[str]] = None,
                       nosizecheck: bool = False, **kwargs) -> bool:
        if not super().is_valid_value(value, length=length, errors=errors,
                                      **kwargs):
            return False

        if not isinstance(value, str):
            return True

        # can suppress size checks when the value is a pattern
        # XXX pattern size checks would be possible, but would require
        #     parsing the pattern to determine the length of matching strings
        if nosizecheck:
            return True

        sizes = self.sizes_inherited
        if not sizes:
            return True

        sizes_errors = []
        sizes_pranges = _PrangeFacet.prange_clean(sizes, errors=sizes_errors)

        prange = range(length, length + 1) if length is not None \
            else range(len(value), len(value) + 1)
        valid = _PrangeFacet.prange_check(sizes_pranges, [prange],
                                          errors=sizes_errors)
        if sizes_errors and errors is not None:
            errors.append('sizes: %s' % '; '.join(sizes_errors))
        return valid

    def format(self, *, human: bool = False, is_list: bool = False,
               **kwargs) -> str:
        text = super().format(**kwargs)
        sizes = cast(list[Size], self.sizes_inherited)
        if sizes:
            size_strs = [siz.format(human=human) for siz in sizes]
            if not human:
                text += '(%s)' % ','.join(size_strs)
            # special case where there's only one size, with only a maximum
            elif len(sizes) == 1 and 'minLength' not in sizes[0].attrs and \
                    'maxLength' in sizes[0].attrs:
                extra = '' if is_list else ' per item'
                text += ' (maximum number of characters%s %s)' % (
                    extra, sizes[0].maxLength)
            else:
                text += ' (length '
                text += Utility.nicer_list(size_strs, last=', or')
                text += ')'
        return text


class _HasInstanceRef(_FacetMixin):
    """Mixin indicating support for the `InstanceRef` facet."""

    instanceRef = PropDescr(SingleElem, doc='Instance ref facet.')


class _HasPathRef(_FacetMixin):
    """Mixin indicating support for the `PathRef` facet."""

    pathRef = PropDescr(SingleElem, doc='Path ref facet.')


class _HasRanges(_FacetMixin):
    """Mixin indicating support for the `Range` facet."""

    ranges = PropDescr(ListElem, plural=True, doc='Integer range facet.')

    @property
    def ranges_inherited(self) -> list['Range']:
        return self.ranges or []

    @classmethod
    def is_valid_update(cls, old: 'DataType', new: 'DataType', *,
                        expand: bool = False,
                        errors: Optional[list[str]] = None,
                        **kwargs) -> bool:
        if not super().is_valid_update(old, new, expand=expand,
                                       errors=errors, **kwargs):
            return False

        old_ranges = old.ranges_inherited
        new_ranges = new.ranges_inherited
        if not old_ranges or not new_ranges or new_ranges is old_ranges:
            return True

        ranges_errors = []
        old_pranges = _PrangeFacet.prange_clean(old_ranges,
                                                errors=ranges_errors)
        new_pranges = _PrangeFacet.prange_clean(new_ranges,
                                                errors=ranges_errors)

        haystack_ranges = new_pranges if expand else old_pranges
        needle_ranges = old_pranges if expand else new_pranges

        valid = _PrangeFacet.prange_check(haystack_ranges, needle_ranges,
                                          expand=expand, errors=ranges_errors)
        if ranges_errors and errors is not None:
            errors.append('ranges: %s' % '; '.join(ranges_errors))
        return valid

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, int):
            return True

        ranges = self.ranges_inherited
        if not ranges:
            return True

        ranges_errors = []
        ranges_pranges = _PrangeFacet.prange_clean(ranges,
                                                   errors=ranges_errors)

        prange = range(value, value + 1)
        valid = _PrangeFacet.prange_check(ranges_pranges, [prange],
                                          errors=ranges_errors)
        if ranges_errors and errors is not None:
            errors.append('ranges: %s' % '; '.join(ranges_errors))
        return valid

    def format(self, *, human: bool = False, **kwargs) -> str:
        text = super().format(human=human, **kwargs)
        ranges = cast(list[Range], self.ranges_inherited)
        if ranges:
            range_strs = [rng.format(human=human) for rng in ranges]
            if not human:
                text += '(%s)' % ','.join(range_strs)
            else:
                text += ' ('
                text += Utility.nicer_list(range_strs, last=', or')
                text += ')'
        return text


class _HasDecimalRanges(_FacetMixin):
    """Mixin indicating support for the `DecimalRange` facet
    (``decimalRanges`` attribute, for use in data type definitions)."""

    decimalRanges = PropDescr(ListElem, plural=True,
                              doc='Decimal range facet.')

    # noinspection PyPep8Naming
    @property
    def decimalRanges_inherited(self) -> list['DecimalRange']:
        return self.decimalRanges or []

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        # XXX is this correct?
        if not isinstance(value, str):
            return True

        ranges = self.decimalRanges_inherited
        if not ranges:
            return True

        for rng in ranges:
            if rng.is_valid_value(value, errors=errors, **kwargs):
                return True
        return False

    def format(self, *, human: bool = False, **kwargs) -> str:
        text = super().format(human=human, **kwargs)
        ranges = cast(list[DecimalRange], self.decimalRanges)
        if ranges:
            range_strs = [rng.format(human=human) for rng in ranges]
            if not human:
                text += '(%s)' % ','.join(range_strs)
            else:
                text += ' ('
                text += Utility.nicer_list(range_strs, last=', or')
                text += ')'
        return text


# XXX is there a better way of doing this?
class _HasDecimalRanges2(_FacetMixin):
    """Mixin indicating support for the `DecimalRange` facet
    (``ranges`` attribute, for use in parameter definitions)."""

    ranges = PropDescr(ListElem, plural=True, doc='Decimal range facet.',
                       node_cls='DecimalRange')

    @property
    def ranges_inherited(self) -> list['DecimalRange']:
        return self.ranges or []

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        # XXX is this correct?
        if not isinstance(value, str):
            return True

        ranges = self.ranges_inherited
        if not ranges:
            return True

        for rng in ranges:
            if rng.is_valid_value(value, errors=errors, **kwargs):
                return True
        return False

    def format(self, *, human: bool = False, **kwargs) -> str:
        text = super().format(human=human, **kwargs)
        ranges = cast(list[DecimalRange], self.ranges)
        if ranges:
            range_strs = [rng.format(human=human) for rng in ranges]
            if not human:
                text += '(%s)' % ','.join(range_strs)
            else:
                text += ' ('
                text += Utility.nicer_list(range_strs, last=', or')
                text += ')'
        return text


class _HasEnumerations(_FacetMixin):
    """Mixin indicating support for the `Enumeration` facet."""

    enumerations = PropDescr(ValueListElem, plural=True,
                             doc='Enumeration facet.')

    @property
    def enumerations_inherited(self) -> list['Enumeration']:
        return self.enumerations or []

    @classmethod
    def is_valid_update(cls, old: 'DataType', new: 'DataType', *,
                        expand: bool = False,
                        errors: Optional[list[str]] = None,
                        **kwargs) -> bool:
        if not super().is_valid_update(old, new, expand=expand,
                                       errors=errors, **kwargs):
            return False

        old_dict = old.enumerations_inherited_dict
        new_dict = new.enumerations_inherited_dict
        if not old_dict or not new_dict or new_dict is old_dict:
            return True

        old_keys = set(old_dict.keys())
        new_keys = set(new_dict.keys())
        added = new_keys - old_keys
        removed = old_keys - new_keys
        removed_not_optional = {key for key in removed
                                if not old_dict[key].optional}
        # note that we don't complain about removal of optional enumerations
        valid = (not removed_not_optional) if expand else (not added)
        if not valid and errors is not None:
            errors.append('enumerations: %s %s' % (
                'removed' if expand else 'added',
                ', '.join(sorted(removed if expand else added))))
        return valid

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, str):
            return True

        enumerations = self.enumerations_inherited
        if not enumerations:
            return True

        for enum in enumerations:
            if enum.is_valid_value(value, errors=errors, **kwargs):
                return True
        if errors is not None:
            errors.append("isn't any of the allowed values")
        return False

    def format(self, human: bool = False, **kwargs) -> str:
        return ''

        # XXX this shouldn't be the default
        # noinspection PyUnreachableCode
        enumerations = cast(list[Enumeration], self.enumerations)
        return '{%s}' % ','.join(enum.value for enum in enumerations) \
            if enumerations else ''


class _HasEnumerationRef(_FacetMixin):
    """Mixin indicating support for the `EnumerationRef` facet."""

    enumerationRef = PropDescr(SingleElem, doc='Enumeration ref facet.')

    # noinspection PyPep8Naming
    @property
    def enumerationRef_inherited(self) -> Union['EnumerationRef', NullType]:
        return self.enumerationRef

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, str):
            return True

        if not (ref := self.enumerationRef):
            return True

        if ref.nullValue is not None and value == ref.nullValue:
            return True

        # invalid targetParam will be reported elsewhere
        if not (target := ref.targetParamNode):
            return True

        valid = value in target.syntax.values
        if not valid and errors is not None:
            errors.append("isn't any of the allowed values")
        return valid


class _HasPatterns(_FacetMixin):
    """Mixin indicating support for the `Pattern` facet."""

    patterns = PropDescr(ValueListElem, plural=True, doc='Pattern facet.')

    @property
    def patterns_inherited(self) -> list['Pattern']:
        return self.patterns or []

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, str):
            return True

        patterns = self.patterns_inherited
        if not patterns:
            return True

        for patt in patterns:
            if patt.is_valid_value(value, errors=errors, **kwargs):
                return True
        if errors is not None:
            errors.append("doesn't match any of the patterns")
        return False


class _HasUnits(_FacetMixin):
    """Mixin indicating support for the `Units` facet."""

    units = PropDescr(SingleElem, doc='Units.')

    @property
    def units_inherited(self) -> Union['Units', NullType]:
        return self.units


class _HasFacets(_Base, _HasList, _HasSizes, _HasInstanceRef, _HasPathRef,
                 _HasRanges, _HasDecimalRanges, _HasEnumerations,
                 _HasEnumerationRef, _HasPatterns, _HasUnits):
    """TBD."""

    @property
    @cache
    def facets(self) -> tuple['_Facet', ...]:
        return tuple(elem for elem in self.elems if isinstance(elem, _Facet))


# XXX there's no obvious way of checking whether a data type is primitive
#     (have to compare its name with primitive_types?)
class DataType(_HasPrimitives, _HasFacets, DataTypeAccessor):
    """Data type definition.
    """

    dmr_noNameCheck = PropDescr(BoolAttr)
    dmr_noUnitsTemplate = PropDescr(BoolAttr)

    name = PropDescr(StrAttr, mandatory=True, doc='Name of this data type.')
    base = PropDescr(StrAttr,
                     doc='Name of the data type on which this one is based.')

    expand = False

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Dm_document` key and the `DataType.name` attribute."""

        # if no name is supplied this is an anonymous (unkeyed) type
        if 'name' not in dct:
            return None
        else:
            assert parent.instance_in_path(Dm_document) is not None
            return parent.instance_in_path(Dm_document).key, dct['name']

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        # could do this in _mergedone() (data type merge is never deferred),
        # but do it here for consistency with other Accessor types
        if self.name:
            self.update_entities(self.name)
            extra = ' (in %s)' % xml_file.relpath \
                if (xml_file := self.instance_in_path(Xml_file)) else ''
            logger.debug('defined dataType %s%s' % (self.name, extra))

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `name` attribute was specified and mark this data
        type as not (yet) having been used.
        """

        # anonymous types are only permitted within parameters, i.e. not in
        # top-level data types
        if self.name is None and not self.parameter_in_path:
            # XXX this dot separator isn't always needed; probably the best
            #     approach is an error_func() that takes care of such things
            logger.error('%s.name: missing attribute' % self.nicepath)

        # the remaining checks require the sub-hierarchy to be populated
        super()._mergedone(stack=stack, report=report)

        # XXX general point: which of these checks should be done by lint?
        #     probably all of them? should almost never modify the node tree?

        # XXX this doesn't detect a complete change of type, e.g., a named
        #     data type to dateTime, because the new data type has no facets
        #     to check, and base is None so there's no baseNode to examine
        #     (this needs to be checked by property.py merge logic?)

        # if base is absent, this must define everything via a primitive type
        facet_names = {facet.typename for facet in self.facets}
        if not self.base:
            if not self.primitive_inherited:
                logger.error("%s: data type %s isn't derived from anything" %
                             (self.nicepath, self))
            if self.facets:
                plural = 's' if len(facet_names) > 1 else ''
                extra = ', '.join(sorted(facet_names))
                logger.error('%s: invalid direct facet%s (only valid in '
                             'derived types) %s' % (self.nicepath, plural,
                                                    extra))

        # if base is present, this must define everything via direct facets
        else:
            if self.primitive:
                logger.error("%s: is derived from %s so can't derive it from "
                             "%s" % (self.nicepath, self.base, self.primitive))

        # check that all facets are appropriate for the primitive data type
        # XXX could push this down to a base class?
        primitive = self.primitive_inherited
        if primitive:
            allowed_facet_names = {
                Utility.lower_first(name) for name in primitive.allowed_facets}
            invalid_facet_names = facet_names - allowed_facet_names
            if invalid_facet_names:
                plural = 's' if len(invalid_facet_names) > 1 else ''
                logger.error('%s: invalid facet%s (not supported by %s) %s' % (
                    self.nicepath, plural, primitive.typename,
                    ', '.join(sorted(invalid_facet_names))))

        # check that all facets are valid relative to the base type
        errors = []
        self.is_valid_update(self.baseNode, self,
                             expand=self.expand,
                             errors=errors)
        if errors:
            logger.error('%s: invalid facet updates: %s' % (
                self.nicepath, ', '.join(errors)))

        # XXX should also be checking that all facets are valid in their own
        #     right, and all facet collections (ranges, sizes etc.) are valid

        # check that values (enumerations or patterns) are valid
        # XXX should push this down to a base class?
        for value in self.values.values():
            nocheck = isinstance(value, Pattern)
            errors = []
            if not self.is_valid_value(
                    value.value, nosizecheck=nocheck, nopatterncheck=nocheck,
                    errors=errors):
                logger.error('%s: invalid value %s: %s' % (
                    self.nicepath, value, ', '.join(errors)))

        # it's important to do this last, so the merged sub-hierarchy can be
        # marked unused (it may later be marked used by the 'used' transform)
        # XXX but we don't do this for syntax instances (should adjust the
        #     class hierarchy to avoid the need for this special case)
        if not isinstance(self, Syntax):
            self.mark_unused()

    @property
    def name_public(self) -> str:
        """Get the public name, falling back on the data type name."""
        return DataTypeAccessor.public_map().get(self.name, self.name)

    @property
    def base_public(self) -> str:
        """Get the public base, falling back on the data type base."""
        return DataTypeAccessor.public_map().get(self.base, self.base)

    @property
    def anchor(self) -> str:
        # XXX this is a bit of a hack
        return super().anchor.replace(self.name, self.name_public)

    # this allows a data type to inherit its base type's description
    @property
    def description_inherited(self) -> Union[Description, NullType]:
        return self.description or self.baseNode.description_inherited

    # noinspection PyPep8Naming
    @property
    def baseNode(self) -> Union['DataType', NullType]:
        """Get the node referenced by `base`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return DataTypeAccessor.entities.get(self.base, (None, Null))[1]

    @property
    def primitive_inherited(self) -> Union['_Primitive', NullType]:
        return super().primitive_inherited or self.baseNode.primitive_inherited

    # we don't need list_inherited() because list facets aren't inherited (a
    # data type can be a list of another data type, etc.)

    # XXX is it a bit anomalous that multi-instance xxx returns Null if
    #     undefined, whereas xxx_inherited returns []?

    @property
    def sizes_inherited(self) -> list['Size']:
        return self._facet_inherited('sizes', [])

    # noinspection PyPep8Naming
    @property
    def instanceRef_inherited(self) -> Union['InstanceRef', NullType]:
        return self._facet_inherited('instanceRef', Null)

    # noinspection PyPep8Naming
    @property
    def pathRef_inherited(self) -> Union['PathRef', NullType]:
        return self._facet_inherited('pathRef', Null)

    # XXX this can actually return both Range and DecimalRange objects
    @property
    def ranges_inherited(self) -> list['Range']:
        return self._facet_inherited('ranges', [])

    # noinspection PyPep8Naming
    @property
    def decimalRanges_inherited(self) -> list['DecimalRange']:
        return self._facet_inherited('decimalRanges', [])

    @property
    def enumerations_inherited(self) -> list['Enumeration']:
        return self._facet_inherited('enumerations', [])

    @property
    def enumerations_inherited_dict(self) -> dict[str, 'Enumeration']:
        return {value.value: value for value in self.enumerations_inherited}

    # noinspection PyPep8Naming
    @property
    def enumerationRef_inherited(self) -> Union['EnumerationRef', NullType]:
        return self._facet_inherited('enumerationRef', Null)

    @property
    def patterns_inherited(self) -> list['Pattern']:
        return self._facet_inherited('patterns', [])

    @property
    def patterns_inherited_dict(self) -> dict[str, 'Pattern']:
        return {value.value: value for value in self.patterns_inherited}

    @property
    def units_inherited(self) -> Union['Units', NullType]:
        return self._facet_inherited('units', Null)

    # helper
    def _facet_inherited(self, facet_name: str, default: Any) -> Any:
        return (getattr(self.primitive, facet_name, default) or
                getattr(self, facet_name) or
                getattr(self.baseNode, '%s_inherited' % facet_name) or
                default)

    @property
    def reference(self) -> Union['EnumerationRef', 'PathRef', 'InstanceRef',
                                 NullType]:
        """TBD."""

        return self.enumerationRef_inherited or self.pathRef_inherited or \
            self.instanceRef_inherited

    @property
    def values(self) -> Union[dict[str, 'Enumeration'], dict[str, 'Pattern']]:
        return self.enumerations_inherited_dict or \
            self.patterns_inherited_dict

    # enumeration and pattern descriptions are different, because descriptions
    # are inherited from the corresponding base class values
    def value_description(self, facet: Union['Enumeration', 'Pattern']) \
            -> Union[Description, NullType]:
        # could call self.is_valid_value(facet.value) here but this would check
        # all facets and so could fail for other reasons
        if facet.value not in self.values:
            return Null
        elif facet.description:
            return cast(Description, facet.description)
        elif base_facet := self.baseNode.values.get(facet.value, Null):
            return self.baseNode.value_description(base_facet)
        else:
            return Null

    def format(self, **kwargs) -> str:
        """A string of the form ``{file}name`` or ``{file}name:base=base``.

        The file extension (always ``.xml``) is omitted.
        """

        # XXX need to review this; for now just return the name or base
        # noinspection PyUnusedLocal
        facet_text = super().format(**kwargs)
        return self.name_public or self.base_public or 'anon'

        # if not keyed, this is an empty proxy data type
        # XXX does this happen?
        # noinspection PyUnreachableCode
        if not self.key:
            file = ''
        else:
            *_, file = Utility.path_split_drive(self.key[0])
            file, _ = os.path.splitext(file)
        # file is also empty for built-in data types
        if file:
            file = f'{{{file}}}'
        name = self.name or ''
        base = self.base or ''
        extra = f':base={file}{base}' if base else ''
        return f'{file}{name}{extra}'

    auto_macro_criteria = {
        'enum': lambda node: (node.enumerations or
                              node.string.enumerations, ''),
        'pattern': lambda node: (node.patterns or
                                 node.string.patterns, '')
    }


class _Items(_HasDescription):
    """A collection of `_Item` instances, each of which has an `id`
    attribute."""

    # XXX subclasses have to override this (to use the correct node class) so
    #     does it need to be defined?
    items = PropDescr(ListElem, plural=True, doc='Items.', node_cls='_Item')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The class name (so each derived class has a singleton instance)."""
        return cls.__name__


class _Item(_HasDescription):
    """An item with an `id` attribute."""

    # id is defined on _Base
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The `id` attribute."""
        return dct.get('id')

    # this is only called when merging into an existing instance
    def _mergeprep(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        logger.warning('%s: duplicate %s (replaces original defined in '
                       '%s.xml)' % (self.nicepath, self.typename,
                                    self.instance_in_path(Xml_file)))
        return super()._mergeprep(stack=stack, report=report)

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `id` attribute was specified, and mark this item
        as not (yet) having been used.
        """

        if self.id is None:
            logger.error('%s.id: missing attribute' % self.nicepath)

        # XXX see Template._mergedone(); does this need to be done before
        #     marking unused? and why does it have to be marked unused
        super()._mergedone(stack=stack, report=report)

        # it's important to do this last, so the merged sub-hierarchy can be
        # marked unused (it may later be marked used by the 'used' transform)
        self.mark_unused()


class Glossary(_Items):
    """The glossary."""

    items = PropDescr(ListElem, plural=True, doc='Glossary items.',
                      node_cls='GlossaryItem')


class GlossaryItem(_Item):
    """A glossary item."""


class Abbreviations(_Items):
    """The abbreviations."""

    items = PropDescr(ListElem, plural=True, doc='Abbreviations items.',
                      node_cls='AbbreviationsItem')


class AbbreviationsItem(_Item):
    """An abbreviation item."""


# XXX could this be an _Items? would need to play some games with names
class Bibliography(_HasDescription):
    """The bibliography."""

    references = PropDescr(ListElem, plural=True,
                           doc="Bibliographic references.")

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The class name (so there's a singleton instance)."""
        return cls.__name__


# XXX this is keyed by 'id', so it should be an _Item
class Template(_HasContent):
    """The description templates.
    """

    # id is defined on _Base
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The `id` attribute."""
        return dct.get('id')

    # this is only called when merging into an existing instance
    # XXX logically this would be on _Base, which defines 'comments',
    #     'cdatas' and 'others', but is appears only to be needed here, so
    #     we'll define it here for now
    def _mergeprep(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        # XXX this is a bit of a hack really; templates are keyed, so if we
        #     didn't do this, comments, cdatas and others would be extended
        #     when merging
        self.comments = None
        self.cdatas = None
        self.others = None

        # check for duplicate definition (some templates are redefined,
        # so this is reported at the info level)
        logger.info('%s: duplicate %s (replaces original defined in '
                    '%s.xml)' % (self.nicepath, self.typename,
                                 self.instance_in_path(Xml_file)))
        return super()._mergeprep(stack=stack, report=report)

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `id` attribute was specified, and mark this item
        as not (yet) having been used.
        """

        if self.id is None:
            logger.error('%s.id: missing attribute' % self.nicepath)

        # content logic
        super()._mergedone(stack=stack, report=report)

        # it's important to do this last, so the merged sub-hierarchy can be
        # marked unused (it may later be marked used by the 'used' transform)
        self.mark_unused()

    def format(self, **kwargs) -> str:
        """The value of the `id` attribute."""
        return self.id or ''


# XXX this is keyed by 'id', so it should be an _Item
class Reference(_Base):
    """A bibliographic reference.
    """

    name = PropDescr(SingleElem, node_cls='ReferenceName',
                     doc='Reference name.')
    title = PropDescr(SingleElem, node_cls='ReferenceTitle',
                      doc='Reference title.')
    organization = PropDescr(SingleElem, node_cls='ReferenceOrganization',
                             doc='Reference organization.')
    category = PropDescr(SingleElem, node_cls='ReferenceCategory',
                         doc='Reference category.')
    date = PropDescr(SingleElem, node_cls='ReferenceDate',
                     doc='Reference date.')
    hyperlinks = PropDescr(ListElem, plural=True,
                           node_cls='ReferenceHyperlink',
                           doc='Reference hyperlinks.')

    # id is defined on _Base
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The `id` attribute."""
        return dct.get('id')

    # this is only called when merging into an existing instance
    def _mergeprep(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        logger.info('%s: duplicate %s (replaces original defined in '
                    '%s.xml)' % (self.nicepath, self.typename,
                                 self.instance_in_path(Xml_file)))
        return super()._mergeprep(stack=stack, report=report)

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `id` attribute was specified, and mark this item
        as not (yet) having been used.
        """

        if self.id is None:
            logger.error('%s.id: missing attribute' % self.nicepath)

        super()._mergedone(stack=stack, report=report)

        # it's important to do this last, so the merged sub-hierarchy can be
        # marked unused (it may later be marked used by the 'used' transform)
        self.mark_unused()


class ReferenceName(_HasContent):
    """A bibliographic `Reference` name."""


class ReferenceTitle(_HasContent):
    """A bibliographic `Reference` title."""


class ReferenceOrganization(_HasContent):
    """A bibliographic `Reference` organization."""


class ReferenceCategory(_HasContent):
    """A bibliographic `Reference` category."""


class ReferenceDate(_HasContent):
    """A bibliographic `Reference` date."""


# XXX this probably shouldn't have content
class ReferenceHyperlink(_HasContent):
    """A bibliographic `Reference` hyperlink."""


# noinspection GrazieInspection
class Component(_HasDescription, ComponentAccessor):
    """A component definition.
    """

    dmr_noNameCheck = PropDescr(BoolAttr)

    name = PropDescr(StrAttr, mandatory=True, doc='Component name.')
    virtual = PropDescr(BoolAttr, doc='Virtual component?', default=False)
    objects = PropDescr(ListElem, plural=True, doc='Component objects.')
    commands = PropDescr(ListElem, plural=True, doc='Component commands.')
    events = PropDescr(ListElem, plural=True, doc='Component events.')
    parameters = PropDescr(ListElem, plural=True, doc='Component parameters.')
    components = PropDescr(ListElem, plural=True, node_cls='ComponentRef',
                           doc='Component component references.')
    profiles = PropDescr(ListElem, plural=True, doc='Component profiles.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Dm_document` key and the `Component.name` attribute."""
        assert parent.instance_in_path(Dm_document) is not None
        return parent.instance_in_path(Dm_document).key, dct.get('name')

    def __init__(self, *, key=None, data=None, stack=None, **kwargs):
        """Component node constructor.

        The behavior of the constructor depends on whether the
        ``--thisonly`` command-line option was specified.

        * If not, the component data is stored in the node, and is only
          expanded (at the point of reference) when the component is
          referenced. In this case, only the `name` attribute is ever set,
          and `objects`, `parameters` etc. will never be defined.

        * If so, the component data is expanded as usual.
        """

        # we defer merging unless --thisonly
        defermerge = not self.args.thisonly

        # if defermerge, assume that data is of the form (('name', name),
        # ('foo', foo), ...), use the first element to set name, and pass the
        # rest to the super-class for later expansion
        # XXX if defermerge, we also pick off 'virtual' etc., and should pick
        #     off further fields such as 'status' and 'description' (then we
        #     wouldn't need to worry about them in ComponentRef.__relocate())
        # XXX we shouldn't assume anything about the order of the 'name',
        #     'virtual' etc. attributes
        name, virtual, dmr_no_name_check, data_ = None, None, None, data
        if defermerge:
            assert data and data[0][0] == 'name'
            name = data[0][1]
            data_ = data[1:]
            if not data_:
                data_ = None
            elif data_[0][0] == 'virtual':
                virtual = Utility.boolean(data_[0][1])
                data_ = data_[1:]
            elif data_[0][0] == 'dmr_noNameCheck':
                dmr_no_name_check = Utility.boolean(data_[0][1])
                data_ = data_[1:]

        super().__init__(key=key, data=data_, defermerge=defermerge,
                         stack=stack, **kwargs)

        # if merge was deferred, need to set the name and virtual attributes
        # directly
        if defermerge:
            self.name = name
            self.virtual = virtual
            self.dmr_noNameCheck = dmr_no_name_check

        # do this here rather than in _mergedone() in case merge was deferred
        self.update_entities(self.name)
        logger.debug('defined component %s (in %s)' % (
            self.name, self.instance_in_path(Xml_file).relpath))

    # this is only called for --thisonly
    def _mergedone(self, *, stack=None, report=None):
        """Check that the `name` attribute was specified."""
        if self.name is None:
            logger.error('%s.name: missing attribute' % self.nicepath)

        super()._mergedone(stack=stack, report=report)

    def format(self, **kwargs) -> str:
        """TBD.
        """
        return super().format(**kwargs) or self.name


class ComponentRef(_Base):
    """A `Component` reference.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)
    dmr_previousObject = PropDescr(StrAttr)
    dmr_previousProfile = PropDescr(StrAttr)

    ref = PropDescr(StrAttr, mandatory=True,
                    doc='Name of referenced component.')

    path = PropDescr(StrAttr, doc="""Component path.

    If specified, this is the relative path between the point of reference
    (inclusion) and the component's items. If not specified, behavior is as
    if an empty relative path was specified.
    """)

    def __init__(self, **kwargs):
        self._component = None
        super().__init__(**kwargs)

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `ref` attribute was specified, then locate and
        expand the component (unless the ``--thisonly`` command-line option
        was specified).

        The logic is quite complicated (and possibly not 100% correct,
        although it works on all current and past data models).

        XXX Need to update this. The logic is now simpler (and correct?).

        The component is located as follows.

        * The current `Dm_document` is located and searched for the
          component.
        * If not found, the calling component (if any) is searched
        * If not found, the `ComponentAccessor` is searched (this should
          always find the component, but is it guaranteed to find the correct
          instance? bear in mind that component names are only unique within
          the file in which they were defined)

        Having located the component, it's expanded as follows.

        * Temporarily relocate the component body to account for `path`.
        * Merge the component data into the point of reference (adjusted to
          account for `path`).
        """

        # if no ref attribute was specified, can't proceed
        if self.ref is None:
            logger.error('%s.ref: missing attribute' % self.nicepath)
            return

        # if processing this file only, don't expand the component
        if self.args.thisonly:
            return

        # find current document
        # XXX use of instance_in_stack() is suspect; it won't work if creating
        #     new nodes in transforms; for now, check stack first and fall back
        #     (but read on...)
        dm_document = self.instance_in_stack(stack, Dm_document)
        if dm_document is None:
            logger.warning('falling back on %s.instance_in_path()' % type(
                self).__name__)
            dm_document = self.instance_in_path(Dm_document)
        assert dm_document is not None
        dm_document = cast(Dm_document, dm_document)

        # XXX component search is wrong; need to start the search in the file
        #     where the calling component was found (only use the current
        #     file if there's no calling component)
        calling_component = self.instance_in_stack(stack[:-1], ComponentRef)
        if calling_component and calling_component.component:
            dm_document = \
                calling_component.component.instance_in_path(Dm_document)

        # look for the desired component in the current document
        document_component_dict = dm_document.entity_dict('components')
        component = document_component_dict.get(cast(str, self.ref))

        # this is either a Component or an ImportComponent
        if isinstance(component, ImportComponent):
            component = component.component

        # if not found, give up
        if not component:
            logger.error(
                    "%s: can't find component %r" % (self.nicepath, self.ref))
            return

        # save the component on this object
        if self._component and self._component is not component:
            logger.error('%s: has already saved %s; now being replaced' % (
                self.nicepath, component.name))
        self._component = component

        # if the component is virtual, search up the stack for a non-virtual
        # component (also treat empty components as virtual)
        if component.virtual or not component.data:
            dm_documents_in_stack = [node for node in reversed(stack)
                                     if isinstance(node, Dm_document)]
            for document in dm_documents_in_stack:
                components = document.entity_dict('components')
                if self.ref in components:
                    comp = components[self.ref]
                    if isinstance(comp, ImportComponent):
                        comp = comp.component
                    if comp:
                        component = comp
                        if not component.virtual and component.data:
                            break

        # report if didn't find a non-virtual (or non-empty) component
        # (can't report this as a warning because it can legitimately happen
        # with old models)
        if component.virtual or not component.data:
            logger.info("%s: expanding virtual %s component" % (
                self.nicepath, component.name))

        # if there's data (even if it's virtual), expand the component
        if component.data:
            # XXX need a really good explanation here
            assert self._parent is not None
            assert isinstance(component, Component)
            data = component._data
            container, relpath = self.__proccomppath(stack=stack)
            xml_file = cast(Xml_file, dm_document.parent)
            logger.debug('%s: expanding component %s (from %s) with container '
                         '%s and relpath %r' % (
                             self.nicepath, component.name, xml_file.relpath,
                             container, relpath))
            # XXX shouldn't have to know the possible attribute names
            previous = {attr: getattr(self, attr) for attr in
                        {'dmr_previousCommand',
                         'dmr_previousEvent',
                         'dmr_previousParameter',
                         'dmr_previousObject',
                         'dmr_previousProfile'} if getattr(self, attr, None)}
            data_ = self.__relocate(data, relpath, previous=previous)
            # the version might be set in a parent component reference
            # noinspection PyTypeChecker
            compref_with_version = self.instance_in_stack(
                    stack, ComponentRef, lambda n: n.version is not None)
            parent_version = self.parent.h_version_inherited
            if self.version is not None and self.version == parent_version:
                logger.info('%s: %s version %s is unnecessary' % (
                    self.nicepath, component.name, self.version))
            # the clamp version defaults to the (inherited) parent version
            clamp_version = compref_with_version.version if \
                compref_with_version else parent_version
            data_ = self.__clampversion(data_, clamp_version)
            # XXX could mark expanded items with their provenance?
            container.merge(data=data_, stack=stack)
            logger.debug('%s: expanded  component %s (from %s)' % (
                self.nicepath, component.name, xml_file.relpath))

        super()._mergedone(stack=stack, report=report)

    def __proccomppath(self, *, stack=None):
        # this ComponentRef's path attribute, which is defined as follows: "If
        # specified, is relative path between point of reference (inclusion)
        # and the component's items. If not specified, behavior is as if an
        # empty relative path was specified"

        # this componentRef's path attribute
        comppath = self.path or ''

        # absolute path that's the "starting point" for the component's items
        abspath = self.objpath + comppath

        # relpath is the relative path from the container to the component's
        # items (it can be empty)
        relpath = comppath

        # if elemname is 'object' then (because objects are always relative to
        # their containing model, input, output or event) the component
        # definition has to be adjusted to be relative to this containing item
        container = self._parent
        if container.elemname == 'object':
            container = self.instance_in_path((Model, Input, Output, Event))
            assert container is not None
            contpath = container.objpath
            assert abspath.startswith(contpath), \
                "absolute path %s doesn't start with %s" % (abspath, contpath)
            relpath = abspath[len(contpath):]
            # command/event objpaths don't end with dots, so (within a
            # command/event) this will start with a dot; get rid of it
            if relpath.startswith('.'):
                relpath = relpath[1:]

        return container, relpath

    # relocate component data to account for comppath
    def __relocate(self, indata: Data, relpath: str, *, isprofile=False,
                   previous: Optional[dict[str, str]] = None) -> Data:
        # items are removed as they are used
        if previous is None:
            previous = {}

        # build the data as a list
        outdata = []
        for field, value in indata:
            # component (i.e. non-profile) status and description are ignored
            # XXX should have removed them in the Component constructor?
            if field in {'status', 'description'} and not isprofile:
                if field == 'status' and value != StatusEnum.default:
                    # XXX this is currently reported at the info level
                    logger.info('%s: expanded %s %s component' % (
                        self.nicepath, value, self.ref))
                continue

            # if relative path is empty, no change is needed
            elif relpath == '':
                outdata += [(field, value)]

            # components, parameters, commands and events are defined within
            # their containing object (might be a command/event argument
            # object)
            elif field in {'component', 'parameter', 'command', 'event'}:
                if not isprofile:
                    prelude = (('base', relpath),)
                else:
                    prelude = (('ref', relpath), ('requirement', 'present'))

                # propagate dmr_previousXxx attributes; each is used only once
                if previous:
                    attr = 'dmr_previous%s' % Utility.upper_first(field)
                    if attr in previous:
                        value = value + ((attr, previous[attr]),)
                        del previous[attr]

                outdata += [('object', prelude + ((field, value),))]

            # objects need their names adjusting
            elif field in {'object'}:
                # XXX what if there's more than one of name, base or ref?
                assert value and value[0][0] in {'name', 'base', 'ref'}
                outdata += [(field,
                             ((value[0][0], relpath + value[0][1]),) + value[
                                                                       1:])]

            # profile _contents_ need the above two treatments
            elif field in {'profile'}:
                outdata += [
                    (field, self.__relocate(value, relpath, isprofile=True,
                                            previous=previous))]

            # otherwise no change is needed
            else:
                outdata += [(field, value)]

        # XXX could warn of unused 'previous' items?
        # return as a tuple
        return cast(Data, tuple(outdata))

    # clamp the version in relocated component data
    # (this is only called if a clamp version was specified)
    def __clampversion(self, indata: Data, version: Version) -> Data:
        outdata = []
        for field, value in indata:
            if isinstance(value, tuple):
                outdata += [(field, self.__clampversion(value, version))]
            else:
                if field == 'version' and Version(value) < version:
                    value = version
                outdata += [(field, value)]

        # return as a tuple
        return cast(Data, tuple(outdata))

    @property
    def component(self) -> Optional[Component]:
        return self._component

    def format(self, **kwargs) -> str:
        """A string of the form ``ref`` or ``ref:path=path``."""
        ref = self.ref or ''
        extra = f':path={self.path}' if self.path else ''
        return f'{ref}{extra}'


# TBD common (_Dm_modelItem, _Dt_modelItem) items
class _ModelItem(_Mixin):
    pass


# name or base must be specified; also see _mergedone() logic
class _Dm_modelItem(_HasDescription, _ModelItem):
    """Base class for models and their parameters, objects, commands,
    events and profiles. All these nodes have `Description`, `name` (for
    new nodes) and `base` (for nodes based on another node) attributes.
    """

    dmr_noNameCheck = PropDescr(BoolAttr)

    name = PropDescr(RedefineCheckStrAttr, doc='Name of new node.')
    base = PropDescr(StrAttr, doc='Name of node on which this node is based.')

    # some subclasses override this
    access = None

    # this is the name of the previous instance of this class
    __previous_lexical = None

    def _mergedone(self, *, stack=None, report=None):
        """Check that the ``name`` attribute was specified and (if defined)
        clear the ``base`` attribute (but don't do anything if the
        ``--thisonly`` command-line option was specified).

        Note:
            One of ``name`` or ``base`` has to be specified (a given instance
            should never have both), but after merging, a ``base`` node into a
            ``name`` node, the node *will* have both, which is why this method
            clears ``base``.
        """

        # XXX experimental (see property.Elems._set_node_to_prop()) but it
        #     doesn't work (need a more sophisticated notion of 'previous'),
        #     so it's been disabled
        if False and not self.args.thisonly and \
                self.name is not None and self.base is None:
            self._previous_lexical = _Dm_modelItem.__previous_lexical
            logger.warning('%s: set previous_lexical to %s' % (
                self.objpath, _Dm_modelItem.__previous_lexical))
            _Dm_modelItem.__previous_lexical = self.name

        # if --thisonly, don't complain or change anything
        if self.args.thisonly:
            pass

        # name must be defined
        elif self.name is None:
            # XXX this dot separator isn't always needed; probably the best
            #     approach is an error_func() that takes care of such things
            # XXX perhaps better to rely on lint rather than reporting an
            #     error here
            # XXX this can (semi-)legitimately occur when expanding a component
            #     that uses base= to reference a non-existent item; for this
            #     reason, report it at the info level, and rely on the
            #     output format to omit it if appropriate
            dot = '' if self.nicepath.endswith('.') else '.'
            logger.info('%s%sname: missing attribute' % (self.nicepath, dot))

        # can clear base because it's been merged (but not for profiles with
        # different base and name attributes)
        elif self.base is None:
            pass
        elif isinstance(self, Profile) and self.base != self.name:
            pass
        else:
            self.base = None

        # check that the version doesn't exceed the DM document's spec version
        # (this is a bit tricky, because we have to account for the case where
        # the model item was defined in a component, which might have been
        # defined in a different file)
        if self.version is not None:
            dm_document = self.instance_in_stack(stack, Dm_document)
            if dm_document and dm_document.spec.version is not None:
                # XXX this logic only looks for the most recent component
                #     reference; it should really search up the stack for
                #     all component references
                if component_ref := \
                        self.instance_in_stack(stack, ComponentRef):
                    component = component_ref.component
                    dm_document = component.instance_in_path(Dm_document)
                if dm_document and (spec_version :=
                                    dm_document.spec.version) is not None:
                    if self.version > spec_version:
                        logger.error("%s: version %s > spec version %s" % (
                            self.nicepath, self.version, spec_version))

        super()._mergedone(stack=stack, report=report)

    # noinspection PyPep8Naming
    @property
    def nameOrBase(self) -> Optional[str]:
        return self.name or self.base


# TBD common (Model, _Dt_model) items
class _Model(_Mixin):
    pass


# XXX should models be model items?
class Model(_Dm_modelItem, _Model, ModelAccessor):
    """A model definition.
    """

    # these are the first model versions that supported USP (the dict is
    # indexed by 'Device:2' etc.)
    FIRST_USP_VERSIONS = {version.prefix + str(version.comps[0]):
                              version for version in (
        Version('Device:2.12'),
        Version('FAPService:2.1.1'),
        Version('StorageService:1.3.1'),
        Version('STBService:1.4.1'),
        Version('VoiceService:2.0.1')
    )}

    isService = PropDescr(BoolAttr, default=False,
                          doc='Whether this is a ``Service`` model.')
    components = PropDescr(ListElem, plural=True, node_cls='ComponentRef',
                           doc='Model components.')
    objects = PropDescr(ListElem, plural=True, doc='Model objects.')
    parameters = PropDescr(ListElem, plural=True, doc='Model parameters.')
    profiles = PropDescr(ListElem, plural=True, doc='Model profiles.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, *, stack: Optional[Stack] = None,
                **kwargs) -> Key:
        """The `Xml_file` name and the `_ModelItem.base` or (as a fallback)
        `_ModelItem.name` attribute with the minor version removed."""

        base, name = (dct.get(a) for a in ('base', 'name'))
        version = Version(base or name or '')
        base_or_name_major = '%s%d' % (version.prefix, version.comps[0])

        # XXX this might have been defined under a different name in a
        #     separate file (the common case is importing XXX as _XXX),
        #     so should consult the imports; however, for now, just discard
        #     a leading underscore
        if base_or_name_major.startswith('_'):
            base_or_name_major = base_or_name_major[1:]

        # noinspection PyTypeChecker
        xml_file = cls.instance_in_stack(
                stack, Xml_file,
                predicate=lambda f: f.parent.elemname == 'root')

        # XXX this was str(xml_file), which is just the filename and is
        #     usually OK, but prevents comparing two files with the same
        #     name in different directories
        return xml_file.keylast, base_or_name_major

    # XXX components and models could share some 'defermerge' logic?
    # XXX could extend 'defermerge' to objects etc.
    def __init__(self, *, key=None, data=None, stack=None, **kwargs):
        """Always defer merging (to avoid wasting resources merging models that
        aren't part of the report).
        """

        # we currently unconditionally defer merging
        defermerge = True

        super().__init__(key=key, data=data, defermerge=defermerge,
                         stack=stack, **kwargs)

        # assume that data is of the form (('name', name), ('foo', foo), ...),
        # so can set the model name
        # XXX shouldn't assume that 'name' is first
        # XXX also allow 'ref', to accommodate Dt_model
        if defermerge:
            assert data and data[0][0] in {'name', 'ref'}
            self.name = data[0][1]

        # do this here (as well as in _mergedone()) in case merge was deferred
        self.update_entities(self.name)
        logger.debug('defined model %s (in %s)' % (
            self.name, self.instance_in_path(Xml_file).relpath))

    def _mergedone(self, *, stack=None, report=None):
        # this is needed to add the new model name, where a model is derived
        # from an existing one
        self.update_entities(self.name)
        super()._mergedone(stack=stack, report=report)

    # the current (latest) model version; taken from the version attribute
    # if present, otherwise derived from the model name
    @property
    @cache
    def model_version(self) -> Version:
        return self.version or Version(self.name)

    # the version at which the model was first created
    @property
    @cache
    def version_inherited(self) -> Version:
        if self.version is not None:
            return cast(Version, self.version)
        else:
            model_version = self.model_version
            first_version = model_version.reset(1)
            if self.usp:
                first_usp_version = \
                    self.FIRST_USP_VERSIONS.get(self.keylast, first_version)
                if first_version < first_usp_version:
                    first_version = first_usp_version
            return first_version

    # this is needed in order to get Model's version_inherited behavior
    @property
    @cache
    def h_version_inherited(self) -> Optional[Version]:
        return self.version_inherited

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.nameOrBase)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not
                     isinstance(elem, Object) or elem in self.h_objects)

    # XXX should also provide a --usp command-line option and/or should
    #     provide a set of flags such as 'ignore enable parameter'
    @property
    def usp(self) -> bool:
        # first check the path for an XML file name ending '-usp.xml'
        node = self
        while node := node.parent:
            if isinstance(node, Xml_file) and str(node).endswith('-usp'):
                return True

        # next check for commands or events
        if self.findall(Command) or self.findall(Event):
            return True

        return False

    def format(self, *, brief: bool = False, only: bool = False, **kwargs) \
            -> str:
        """TBD.
        """
        if kwargs:
            return super().format(**kwargs) or self.name or self.typename
        elif self.name is None:
            return self.typename
        else:
            return re.sub(r'\.\d+$', '', self.name)


# TBD common (Object, _Dt_object) items
class _Object(_Mixin):
    # XXX this should be moved to Path
    @staticmethod
    @cache
    def _path_split(value: str) -> tuple[str, str]:
        path = Path(value)
        head = '.'.join(path.comps[:-2] + [''])
        tail = '.'.join(path.comps[-2:])
        return head, tail


class Object(_Dm_modelItem, _Object):
    """An object definition.

    Note:
        This class is currently used for both model and argument objects,
        which is not ideal.
    """

    dmr_previousObject = PropDescr(StrAttr)
    dmr_noUniqueKeys = PropDescr(BoolAttr)
    dmr_fixedObject = PropDescr(BoolAttr)
    dmr_noDiscriminatorParameter = PropDescr(BoolAttr)

    access = PropDescr(EnumObjAttr, enum_cls=ObjectAccessEnum,
                       doc='Object access.')
    minEntries = PropDescr(IntAttr, default=1,
                           doc='Minimum number of object entries.')
    maxEntries = PropDescr(IntOrUnboundedAttr, default=1,
                           doc='Maximum number of object entries, '
                               'or ``unbounded``.')
    numEntriesParameter = PropDescr(StrAttr, doc="Name of the object's "
                                                 "#entries parameter.")
    enableParameter = PropDescr(StrAttr,
                                doc="Name of the object's enable parameter.")
    discriminatorParameter = PropDescr(StrAttr, doc="Name of the object's "
                                                    "discriminator parameter.")
    mountType = PropDescr(EnumObjAttr, enum_cls=MountTypeEnum,
                          doc='Object mount type (``none`` and ``mountable`` '
                              'are deprecated).')
    uniqueKeys = PropDescr(ListElem, plural=True, doc='Object unique keys.')
    components = PropDescr(ListElem, plural=True, node_cls='ComponentRef')
    commands = PropDescr(ListElem, plural=True, doc='Object commands.')
    events = PropDescr(ListElem, plural=True, doc='Object events.')
    parameters = PropDescr(ListElem, plural=True, doc='Object parameters.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Model` (or `Component`) key, parent object path,
        and the `_ModelItem.name` attribute.

        Note:
            This key logic is used in several other places. It should be
            shared via a suitable class hierarchy.
        """

        model_or_component = parent.instance_in_path((Model, Component))
        assert model_or_component is not None
        name, base = (dct.get(a) for a in ('name', 'base'))
        return model_or_component.key, parent.objpath, (name or base or '')

    def _mergedone(self, *, stack=None, report=None):
        """If within a `Command` or `Event`, this will have been created via
        `Component` expansion: clear not-permitted attributes.
        """

        if self.instance_in_path((Command, Event)):
            if self.access is not None:
                self.access = None
            if self.numEntriesParameter is not None:
                self.numEntriesParameter = None

        # XXX temporarily report created and modified objects
        logger.debug('%s %s' % (
            'DEF' if self.name and not self.base else 'ref', self))

        # XXX this should never happen
        if not self.args.thisonly and not self.h_parent:
            logger.warning("%s: parent hasn't yet been defined" %
                           self.nicepath)

        # name/base logic
        super()._mergedone(stack=stack, report=report)

    # XXX is_xxx properties are useful, especially things like is_writable
    #     where access values vary across classes, but where to stop?
    #     is_deprecated? is_deprecated_or_obsoleted? is_deleted?

    @property
    def is_writable(self) -> bool:
        return self.access.value in {'readWrite'}

    @property
    def is_multi(self) -> bool:
        return self.maxEntries == 'unbounded' or self.maxEntries > 1

    @property
    def is_fixed(self) -> bool:
        return self.is_multi and self.maxEntries == self.minEntries

    @property
    def is_union(self) -> bool:
        return not self.is_multi and self.minEntries == 0

    # XXX all these object_xxx properties will become h_xxx properties

    # XXX some or all of these should be defined on _Node so they can be
    #     called on nodes of all types

    # XXX maybe, rather than h_xxx properties, they should be methods with
    #     a bool argument that controls default or hierarchical behavior?
    #     not sure... definitely want an h_elems property... perhaps put them
    #     all on a sub-object?

    # XXX this also needs to be implemented for ObjectRef and Dt_object
    @property
    @cache
    def h_parent(self) -> Optional[Union[Model, 'Object']]:
        name_or_base = self.nameOrBase
        assert name_or_base is not None
        head, _ = self._path_split(name_or_base)
        if head == '':
            parent = self.parent
        else:
            parent_key = self.key[:-1] + (head,)
            parent = self.find(Object, *parent_key)
            if not parent:
                # this should only happen when there's something wrong, but
                # it's safer and more consistent to return the model in this
                # case (self.parent will be the model)
                parent = self.parent
        return parent

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        container = self.instance_in_path((Model, _Arguments, Event))
        assert container is not None
        objs = ListElem.ListWrapper()
        for obj in container.objects:
            head, _ = self._path_split(obj.objpath)
            if head == self.objpath:
                objs += [obj]
        return objs

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        # XXX ideally the objects would be inserted in a more logical place
        return tuple(self.elems + tuple(self.h_objects))

    # XXX should all these be defined on _Base? this would save isinstance()
    #     checks but would rather pollute the namespace; maybe defined on
    #     _ModelItem as a compromise?
    @property
    @cache
    def h_name(self) -> Optional[str]:
        if self.name is None:
            return None
        else:
            _, tail = self._path_split(cast(str, self.name))
            return tail

    @property
    @cache
    def h_base(self) -> Optional[str]:
        if self.base is None:
            return None
        else:
            _, tail = self._path_split(self.base)
            return tail

    @property
    def h_nameonly(self) -> Optional[str]:
        return re.sub(r'(\.{i})?\.$', '', self.h_name) if \
            self.h_name else None

    @property
    def h_baseonly(self) -> Optional[str]:
        return re.sub(r'(\.{i})?\.$', '', self.h_base) if \
            self.h_base else None

    # noinspection PyPep8Naming
    @property
    @cache
    def enableParameterNode(self) -> Union['Parameter', NullType]:
        """Get the node referenced by `enableParameter`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return follow_reference(self, self.enableParameter,
                                scope=ScopeEnum('object'), quiet=PATH_QUIET)

    # noinspection PyPep8Naming
    @property
    @cache
    def numEntriesParameterNode(self) -> Union['Parameter', NullType]:
        """Get the node referenced by `numEntriesParameter`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        if not self.numEntriesParameter:
            node = Null
        else:
            target = '#.%s' % self.numEntriesParameter
            node = follow_reference(self, target, scope=ScopeEnum('object'),
                                    quiet=PATH_QUIET)
        return node

    # noinspection PyPep8Naming
    @property
    @cache
    def discriminatorParameterNode(self) -> Union['Parameter', NullType]:
        """Get the node referenced by `discriminatorParameter`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        if not self.discriminatorParameter:
            node = Null
        else:
            target = '#.%s' % self.discriminatorParameter
            node = follow_reference(self, target, scope=ScopeEnum('object'),
                                    quiet=PATH_QUIET)
        return node

    auto_macro_criteria = {
        'showid': lambda node: node.id,
        'union': lambda node: node.discriminatorParameter,
        'mount': lambda node: node.mountType == 'mountPoint',
        'entries':
            lambda node: node.is_multi or node.is_fixed or node.is_union,
        'keys': lambda node: node.uniqueKeys
    }

    def format(self, *, typ: bool = False, human: bool = False,
               brief: bool = False, only: bool = False, **kwargs) -> str:
        text = super().format(**kwargs)
        if typ:
            text = self.typename
            # XXX need to update this; they have defaults so are never None
            if (self.minEntries is not None or self.maxEntries is not None) \
                    and not (self.minEntries == self.maxEntries == 1):
                text += '('
                if self.minEntries is not None:
                    text += str(self.minEntries)
                text += ':'
                if self.maxEntries is not None:
                    text += str(self.maxEntries)
                text += ')'
        if brief:
            _, text = self._path_split(text)
        if only:
            text = re.sub(r'(\.{i})?\.$', '', text)
        # there's no special human-readable version
        return text


# TBD common (Command, _Dt_command) items
class _Command(_Mixin):
    pass


class Command(_Dm_modelItem, _Command):
    """A command definition.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)

    async_ = PropDescr(BoolAttr, name='async', default=False,
                       doc='Asynchronous?')
    input = PropDescr(SingleElem, doc='Input arguments.')
    output = PropDescr(SingleElem, doc='Output arguments.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Model` (or `Component`) key, parent `Object` path,
        and the `_ModelItem.name` attribute (plus a ``.``)."""
        model_or_component = parent.instance_in_path((Model, Component))
        assert model_or_component is not None
        name, base = (dct.get(a) for a in ('name', 'base'))
        return model_or_component.key, parent.objpath, (
                name or base or '') + '.'

    auto_macro_criteria = {
        'showid': lambda node: node.id,
        'async': lambda node: node.async_
    }


# XXX should this be _ModelItem, even though it has no base + name attributes?
class _Arguments(_HasDescription):
    """Base class for `Command` and `Event` arguments."""

    components = PropDescr(ListElem, plural=True, node_cls='ComponentRef',
                           doc='Arguments components.')
    objects = PropDescr(ListElem, plural=True, doc='Arguments objects.')
    parameters = PropDescr(ListElem, plural=True, doc='Arguments parameters.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Command` or `Event` key and the class name (plus a
        ``.``)."""
        return parent.key, cls.__name__ + '.'

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.nameOrBase)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not
                     isinstance(elem, Object) or elem in self.h_objects)


# TBD common (Input, _Dt_input) items
class _Input(_Mixin):
    pass


class Input(_Arguments, _Input):
    """`Command` input arguments."""


# TBD common (Output, _Dt_output) items
class _Output(_Mixin):
    pass


class Output(_Arguments, _Output):
    """`Command` output arguments."""


# TBD common (Event, _Dt_event) items
class _Event(_Mixin):
    pass


class Event(_Dm_modelItem, _Event):
    """An event definition.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)

    components = PropDescr(ListElem, plural=True, node_cls='ComponentRef',
                           doc='Event components.')
    objects = PropDescr(ListElem, plural=True, doc='Event objects.')
    parameters = PropDescr(ListElem, plural=True, doc='Event parameters.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Model` (or `Component`) key, parent `Object` path,
        and the `_ModelItem.name` attribute (plus a ``.``)."""
        model_or_component = parent.instance_in_path((Model, Component))
        assert model_or_component is not None
        name, base = (dct.get(a) for a in ('name', 'base'))
        return model_or_component.key, parent.objpath, (
                name or base or '') + '.'

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.nameOrBase)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not
                     isinstance(elem, Object) or elem in self.h_objects)


class UniqueKey(_Base):
    """An `Object` unique key definition.
    """

    functional = PropDescr(BoolAttr, default=True, doc='Functional?')
    parameters = PropDescr(ListElem, plural=True, node_cls='ParameterRef',
                           doc='Unique key parameters.')

    def format(self, **kwargs) -> str:
        return '{' + ','.join(p.ref for p in self.parameters) + '}'


# TBD common (Parameter, _Dt_parameter) items
class _Parameter(_Mixin):
    pass


class Parameter(_Dm_modelItem, _Parameter):
    """A parameter definition.

    Note:
        This class is currently used for both model and argument parameters,
        which is not ideal.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)
    dmr_customNumEntriesParameter = PropDescr(BoolAttr)
    dmr_noUnitsTemplate = PropDescr(BoolAttr)

    access = PropDescr(EnumObjAttr, enum_cls=ParameterAccessEnum,
                       doc='Parameter access.')
    activeNotify = PropDescr(EnumObjAttr, enum_cls=ActiveNotifyEnum,
                             doc='Parameter active notify.')
    forcedInform = PropDescr(BoolAttr, default=False,
                             doc='Parameter forced inform.')
    syntax = PropDescr(SyntaxSingleElem, doc='Parameter syntax.')
    # this is only used by argument parameters
    mandatory = PropDescr(BoolAttr, default=False)

    # these are populated by the 'used' transform
    tableObjectNode = PropDescr(SingleElem, internal=True,
                                doc='Object whose ``numEntriesParameter`` '
                                    'references this parameter.')

    discriminatedObjectNodes = PropDescr(ListElem, plural=True, internal=True,
                                         doc='Objects whose '
                                             '``discriminatorParameter`` '
                                             'references this parameter.')

    uniqueKeyNodes = PropDescr(ListElem, plural=True, internal=True,
                               doc='Unique keys that reference '
                                   'this parameter.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Model` (or `Component`) key, parent `Object` path,
        and the `_ModelItem.name` attribute."""
        model_or_component = parent.instance_in_path((Model, Component))
        assert model_or_component is not None
        name, base = (dct.get(a) for a in ('name', 'base'))
        return model_or_component.key, parent.objpath, (name or base or '')

    def _mergedone(self, *, stack=None, report=None):
        """If within a `Command` or `Event`, this will have been created via
        `Component` expansion: clear not-permitted attributes.
        """

        # name/base logic
        super()._mergedone(stack=stack, report=report)

        if not self.instance_in_path((Command, Component, Event)):
            if self.mandatory is not None:
                self.mandatory = None

        if self.instance_in_path((Command, Event)):
            if self.access is not None:
                self.access = None
            if self.activeNotify is not None:
                self.activeNotify = None

    @property
    def is_writable(self) -> bool:
        return self.access.value in {'readWrite', 'writeOnceReadOnly'}

    auto_macro_criteria = {
        'showid': lambda node: node.id,
        'union': lambda node: node.discriminatedObjectNodes,
        'mandatory': lambda node: node.mandatory,
        'datatype': lambda node: node.syntax.dataType,
        'list': lambda node: node.syntax.list,
        'reference': lambda node: node.syntax.reference,
        'enum': lambda node: (node.syntax.enumerations or
                              node.syntax.string.enumerations or
                              node.syntax.dataType.enumerations, ''),
        'pattern': lambda node: (node.syntax.patterns or
                                 node.syntax.string.patterns or
                                 node.syntax.dataType.patterns, ''),
        'access': lambda node: node.access == 'writeOnceReadOnly',
        'hidden': lambda node: node.syntax.hidden,
        'secured': lambda node: node.syntax.secured,
        'factory': lambda node: node.syntax.default.type == 'factory',
        'impldef': lambda node: node.syntax.default.type == 'implementation',
        'paramdef': lambda node: node.syntax.default.type == 'parameter',
        'keys': lambda node: node.uniqueKeyNodes,
        'inform': lambda node: node.forcedInform,
        'notify': lambda node: node.activeNotify != 'normal'
    }

    def format(self, *, typ: bool = False, prim: bool = False,
               human: bool = False, **kwargs) -> str:
        text = super().format(**kwargs)
        if not typ:
            # this will return the superclass value, i.e. the parameter name
            pass
        elif not self.syntax:
            # parameter didn't specify a data type
            text = 'untyped'
        elif not human:
            text = self.syntax.format(prim=prim, **kwargs)
        else:
            text = self.syntax.format(human=True, **kwargs)
        return text


# this is an anonymous data type
class Syntax(DataType):
    """A syntax definition."""

    hidden = PropDescr(BoolAttr, default=False, doc='Hidden?')
    secured = PropDescr(BoolAttr, default=False, doc='Secured?')
    command = PropDescr(BoolAttr, default=False,
                        doc='Command? (This is not the same as a `Command`!)')
    # this is a bit confusing; Syntax is a data type and can also reference
    # a data type: this reference is regarded as the (anonymous) Syntax data
    # type's (anonymous) base data type; blame the DM Schema...
    dataType = PropDescr(SingleElem, node_cls='DataTypeRef',
                         doc='Data type reference.')
    default = PropDescr(SingleElem, doc='Default.')

    expand = True

    def _mergedone(self, *, stack=None, report=None):
        """TBD."""

        # various things are permitted by the class hierarchy but not by the
        # schema
        # XXX should convert these assertions to checks and error messages
        # XXX really should adjust the class hierarchy to impose these rules...
        #     again
        assert not self.name and not self.base and not (
                self.primitive and self.dataType), \
            '%s: invalid configuration' % self.nicepath

        # the remaining checks require the sub-hierarchy to be populated
        super()._mergedone(stack=stack, report=report)

        if not self.type:
            logger.error('%s: untyped parameter' % self.nicepath)

    # XXX this name is confusing; better to make the logic explicit?
    @property
    def type(self) -> Union['_DataTypeBase', NullType]:
        return self.primitive or self.dataType

    # XXX this is only used in one place; can we avoid the need for it?
    def typeprop(self) -> Optional[Property]:
        props = [prop for prop in self.elems_props if
                 isinstance(prop.value, _DataTypeBase)]
        return props[-1] if props else None

    # XXX should this fall back on .primitive or .primitive_inherited? not
    #     straightforward, because they aren't derived from DataType
    @property
    def baseNode(self) -> Union['DataType', NullType]:
        return self.dataType or super().baseNode

    # XXX there are two levels of human? (1) the title text, and (2) what
    #     can be included in the description (make this be human+verbose?)
    # XXX this is similar to _HasPrimitives.format() but adds list support
    def format(self, *, prim: bool = False, human: bool = False,
               **kwargs) -> str:
        """TBD."""

        # XXX calling this is wasteful; it's just to check for invalid kwargs
        # noinspection PyUnusedLocal
        facet_text = super().format(**kwargs)
        typ = self.type
        lst = cast(List, self.list)
        text = ''
        if not typ:
            # this should never happen (it will have been reported elsewhere)
            pass
        elif not human:
            text += typ.format(prim=prim, human=human,
                               plural=bool(lst), **kwargs)
            if lst:
                text += lst.format(human=human, **kwargs)
        else:
            if lst:
                # XXX perhaps the caller should add the prefix and suffix
                text += 'Comma-separated list'
                text += lst.format(human=human, is_list=True, **kwargs)
                text += ' of '
            text += typ.format(prim=prim, human=human,
                               plural=bool(lst), **kwargs)
        return text


class _Primitive(_DataTypeBase):
    """Base class for all primitive types."""

    # subclasses MUST override this with the appropriate TR-106 I.4 (Data
    # Model Definition) text
    usage = ''

    # subclasses MUST override this with an appropriate regex
    # - re.fullmatch() is used, so '^' and '$' aren't needed
    # - if leading or trailing spaces are permitted, the regex needs to
    #   include them
    # XXX could add capture groups to extract the canonical value?
    regex = re.compile(r'.*')

    # subclasses MUST override this with the class names of the allowed
    # facets, e.g. {'Size', 'Units'} (this is used for error-checking)
    # XXX this could be handled automatically but it's not as
    #     straightforward as you might think
    allowed_facets = set()

    # subclasses MAY override this with a human-readable type name (otherwise
    # self.typename will be used)
    human = None

    # subclasses MUST override this with the appropriate TR-106 A.2.3.5
    # (Null Values and References) value
    null = None

    # create DataType instances for all the primitive types
    # - names all start with lower-case characters, so they can't conflict
    #   with other named data types
    # - descriptions are taken from TR-106 I.4 (Data Model Definition)
    @classmethod
    def init(cls, *, parent: _Node) -> None:
        # XXX alternatively could inspect cls's subclasses, but this would need
        #     to be done recursively, and would have to exclude non-leaf nodes
        # XXX how best to prevent these from being output to XML? for now, will
        #     hack this in visitor.py
        for elemname in _HasPrimitives.primitive_types:
            type_cls = cls.typenamed(elemname)
            DataType(key=('', elemname), parent=parent,
                     data=(('name', elemname),
                           ('description', (
                               ('cdata', type_cls.usage),)),
                           (elemname, ())))

    @property
    def primitive(self) -> '_Primitive':
        return self

    # this is a DataType instance that was created in init() above, e.g., for
    # String there's a corresponding 'string' DataType
    @property
    def data_type(self) -> Union[DataType, NullType]:
        return DataTypeAccessor.entities.get(self.elemname, (None, Null))[1]

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        valid = bool(self.regex.fullmatch(str(value)))
        if not valid and errors is not None:
            errors.append("doesn't match pattern")
        return valid

    def format(self, *, prim: bool = False, human: bool = False,
               plural: bool = False, facetsonly: bool = False,
               **kwargs) -> str:
        # get text from superclass mixins, e.g. _HasSizes might return '(:64)'
        facets_text = super().format(human=human, **kwargs)

        # get text from this class, e.g. 'string'
        if facetsonly:
            text = ''
        elif not human:
            text = self.typename
        else:
            text = self.human or self.typename
            # plural only affects the human-readable version
            if plural:
                text = pluralize(text)

        # combine the two, e.g., 'string(:64)'
        return text + facets_text


class _Number(_Primitive, _HasInstanceRef, _HasRanges, _HasUnits):
    """Base class for numeric types."""

    regex = re.compile(r'-?\d+')  # no leading/trailing whitespace
    allowed_facets = {'InstanceRef', 'Range', 'Units'}
    minval = -2**31  # signed 32-bit integer
    maxval = 2**31 - 1
    null = -1


class Base64(_Primitive, _HasSizes):
    """A BASE64 node."""

    usage = """
        Base64 encoded binary (no line-length limitation).

        A minimum and maximum allowed length can be indicated using the form
        *base64(Min:Max)*, where *Min* and *Max* are the minimum and maximum
        length in characters before Base64 encoding. If either *Min* or
        *Max* are missing, this indicates no limit, and if *Min* is missing
        the colon can also be omitted, as in *base64(Max)*. Multiple
        comma-separate ranges can be specified, in which case the length
        MUST be in one of the ranges."""
    regex = re.compile(r'[0-9A-Za-z+/=\s]*')  # this is quite lax
    allowed_facets = {'Size'}
    human = 'Base64'
    null = ''

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        import base64
        import binascii
        try:
            # length (the decoded length) is used rather than len(value)
            length = len(base64.b64decode(value, validate=True))
            return super().is_valid_value(value, length=length, errors=errors,
                                          **kwargs)
        except binascii.Error:
            if errors is not None:
                errors.append('invalid Base64 encoding')
            return False


class Boolean(_Primitive):
    """A boolean node."""

    usage = """
        Boolean, where the allowed values are *0* or *1* (or equivalently,
        {{true}} or {{false}})."""
    regex = re.compile(r'false|true')  # XML permits 0 and 1 but we don't
    null = False

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        # allow a boolean value to be supplied (_is_ a boolean value ever
        # supplied?)
        if isinstance(value, bool):
            value = 'true' if value else 'false'
        return super().is_valid_value(value, errors=errors, **kwargs)


class DateTime(_Primitive):
    """A date and time node."""

    usage = """
        The subset of the ISO 8601 date-time format defined by the SOAP
        *dateTime* type {{bibref|SOAP1.1}}."""
    regex = re.compile(r'-?\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d+)?' +
                       r'(([+-]00:00)|Z)?')  # see TR-106 3.2.1
    human = 'date/time'
    null = '0001-01-01T00:00:00Z'


class Decimal(_Primitive, _HasDecimalRanges2, _HasUnits):
    """A decimal node."""

    usage = """
        Decimal number, with optional sign and optional fractional part.

        For some *decimal* types, a value range is given using the form
        *decimal(Min:Max)* or *decimal(Min:Max step Step)* where the *Min*
        and *Max* values are inclusive. If either *Min* or *Max* are missing,
        this indicates no limit. If *Step* is missing, this indicates a
        step of *1.0*. Multiple comma-separated ranges can be specified,
        in which case the value will be in one of the ranges."""

    regex = re.compile(r'-?\d+(\.\d*)?')
    allowed_facets = {'DecimalRange', 'Units'}
    null = '-1'  # note that it's a string


class HexBinary(_Primitive, _HasSizes):
    """A Hex binary node."""

    usage = """
        Hex encoded binary.

        A minimum and maximum allowed length can be indicated using the form
        *hexBinary(Min:Max)*, where *Min* and *Max* are the minimum and
        maximum length in characters before Hex Binary encoding. If either
        *Min* or *Max* are missing, this indicates no  limit, and if *Min*
        is missing the colon can also be omitted, as in *hexBinary(Max)*.
        Multiple comma-separated ranges can be specified, in which case the
        length MUST be in one of the ranges."""
    allowed_facets = {'Size'}
    regex = re.compile('([0-9A-Fa-f]{2})*')
    human = 'Hex binary'
    null = ''

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        # length (the decoded length) is used rather than len(value)
        length = int((len(value) + 1) / 2)
        return super().is_valid_value(value, length=length, errors=errors,
                                      **kwargs)


class _SignedNumber(_Number):
    """Base class for signed numeric types."""


# XXX this isn't the reported 'step' syntax (similarly for others below)
class Int(_SignedNumber):
    """An int node."""

    usage = """
        Integer in the range *-2147483648* to *+2147483647*, inclusive.

        For some *int* types, a value range is given using the form
        *int(Min:Max)* or *int(Min:Max step Step)* where the *Min* and *Max*
        values are inclusive. If either *Min* or *Max* are missing,
        this indicates no limit. If *Step* is missing, this indicates a
        step of *1*. Multiple comma-separated ranges can be specified,
        in which case the value will be in one of the ranges."""
    human = 'integer'


class Long(_SignedNumber):
    """A long node."""

    usage = """
        Long integer in the range *-9223372036854775808* to
        *9223372036854775807*, inclusive.

        For some *long* types, a value range is given using the form
        *long(Min:Max)* or *long(Min:Max step Step)*, where the *Min* and
        *Max* values are inclusive. If either *Min* or *Max* are missing,
        this indicates no limit. If *Step* is missing, this indicates a
        step of *1*. Multiple comma-separated ranges can be specified,
        in which case the value will be in one of the ranges."""
    minval = -2**63
    maxval = +2**63 - 1


class String(_Primitive, _HasSizes, _HasPathRef, _HasEnumerations,
             _HasEnumerationRef, _HasPatterns):
    """A string node."""

    usage = """
        For strings, a minimum and maximum allowed length can be indicated
        using the form *string(Min:Max)*, where *Min* and *Max* are the minimum
        and maximum string length in characters. If either *Min* or *Max*
        are missing, this indicates no limit, and if *Min* is missing the
        colon can also be omitted, as in *string(Max)*. Multiple
        comma-separated ranges can be specified, in which case the string
        length will be in one of the ranges."""
    allowed_facets = {'Size', 'PathRef', 'Enumeration', 'EnumerationRef',
                      'Pattern'}
    null = ''


class _UnsignedNumber(_Number):
    """Base class for unsigned numeric types."""

    null = 0
    minval = 0
    maxval = 2**64 - 1
    regex = re.compile(r'\d+')


class UnsignedInt(_UnsignedNumber):
    """An unsigned int node."""

    usage = """
        Unsigned integer in the range *0* to *4294967295*, inclusive.

        For some *unsignedInt* types, a value range is given using the form
        *unsignedInt(Min:Max)* or *unsigned(Min:Max step Step)*, where the
        *Min* and *Max* values are inclusive. If either *Min* or *Max* are
        missing, this indicates no limit. If *Step* is missing,
        this indicates a step of *1*. Multiple comma-separated ranges can be
        specified, in which case the value will be in one of the ranges."""
    minval = 0
    maxval = 2**32 - 1
    human = 'unsigned integer'


class UnsignedLong(_UnsignedNumber):
    """An unsigned long node."""

    usage = """
        Unsigned long integer in the range *0* to *18446744073709551615*,
        inclusive.

        For some *unsignedLong* types, a value range is given using the form
        *unsignedLong(Min:Max)* or *unsignedLong(Min:Max step Step)*, where
        the *Min* and *Max* values are inclusive. If either *Min* or *Max*
        are missing, this indicates no limit. If *Step* is missing,
        this indicates a step of *1*. Multiple comma-separated ranges can be
        specified, in which case the value will be in one of the ranges."""
    human = 'unsigned long'
    minval = 0
    maxval = 2**64 - 1


class DataTypeRef(DataType):
    """Data type reference."""

    # XXX this is supported but should probably be deprecated
    ref = PropDescr(StrAttr, doc='Name of the referenced data type.')

    expand = True

    # XXX the only reason to define this here rather than relying on the
    #     base class is so that it can be used before _mergedone() has
    #     copied ref (if defined) to base
    # noinspection PyPep8Naming
    @property
    def baseNode(self) -> Union['DataType', NullType]:
        """Get the node referenced by `base` (or `ref`).

        Returns:
            The referenced node, or `Null` if not found.
        """

        return DataTypeAccessor.entities.get(self.base or self.ref,
                                             (None, Null))[1]

    def _mergedone(self, *, stack=None, report=None):
        """Check that one of the `ref` and `base` attributes is specified."""

        # various things are permitted by the class hierarchy but not by the
        # schema
        # XXX should convert these assertions to checks and error messages
        # XXX really should adjust the class hierarchy to impose these rules...
        #     again
        assert self.name is None and not (self.ref and self.base) and not \
            self.primitive, '%s: invalid configuration' % self.nicepath

        # (ref / base) should be used when (not extending / extending) a data
        # type, but this rule is often broken, and it would be better only
        # to support base; copy ref to base so data type inheritance code
        # works correctly, and fix this in output formats as needed
        # XXX ideally we should be able to mark such a copied base as hidden,
        #     so output formats would know to ignore it
        if self.ref:
            logger.debug('%s: copied ref to base' % self.objpath)
            assert self.base is None
            self.base = self.ref

        super()._mergedone(stack=stack, report=report)

    def format(self, *, prim: bool = False, human: bool = False,
               plural: bool = False, **kwargs) -> str:
        """By default, the value of the `ref` or `base` attribute."""

        # XXX facets text is currently ignored
        # XXX lists are on on the parent syntax node
        # noinspection PyUnusedLocal
        facet_text = super().format(**kwargs)
        # noinspection PyUnreachableCode
        if False:
            logger.warning('%s: facets text %s' % (self.base, facets_text))
        text = self.base_public or ''
        if not human:
            if prim and (primitive := self.primitive_inherited):
                text = primitive.format(**kwargs)
                # XXX should provide a .list_inherited property? in the general
                #     case there could be multiple levels of nested list
                if self.baseNode.list:
                    lst = cast(List, self.baseNode.list)
                    text += lst.format(human=human, **kwargs)
        else:
            # plural only affects the human-readable version
            if plural:
                text = pluralize(text)
        return text


class _Facet(_HasDescription, _HasValueMixin):
    """Base class for facets."""

    access = PropDescr(EnumObjAttr, enum_cls=FacetAccessEnum,
                       doc='Facet access.')
    optional = PropDescr(BoolAttr, default=False, doc='Optional?')

    @property
    def is_writable(self) -> bool:
        return self.access.value in {'readWrite'}


# XXX possibly temporarily, Default and List aren't derived from _Facet;
#     they're a bit different from the other facets...
class Default(_HasDescription):
    """A default facet node.

    Note:
        This class is currently used for both object and parameter defaults,
        which is not ideal.
    """

    type = PropDescr(EnumObjAttr, enum_cls=DefaultTypeEnum, mandatory=True,
                     doc='Default type.')
    value = PropDescr(StrAttr, mandatory=True, doc='Default value.')

    def _mergedone(self, *, stack=None, report=None):
        """If within a `Command` or `Event`, this will have been created via
        `Component` expansion: if so, change the `Default.type` to
        ``parameter``."""
        if self.instance_in_path((Command, Event)):
            if self.type:
                self.type = 'parameter'

        super()._mergedone(stack=stack, report=report)

    def format(self, **kwargs) -> str:
        """The `Default.value`."""
        return self.value or ''


class _ValueFacet(_Facet):
    """Base class for value facets (enumerations and patterns)."""

    value = PropDescr(StrAttr, mandatory=True, doc='Value.')

    def format(self, **kwargs) -> str:
        """The `_ValueFacet.value`."""
        return self.value or ''


class Enumeration(_ValueFacet):
    """Enumeration facet.
    """

    dmr_noNameCheck = PropDescr(BoolAttr)
    dmr_noUnionObject = PropDescr(BoolAttr)

    code = PropDescr(IntAttr, doc='Code.')

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, str):
            return True

        return value == self.value


class EnumerationRef(_Facet):
    """Enumeration reference facet.
    """

    targetParam = PropDescr(StrAttr, mandatory=True, doc='Target parameters.')
    targetParamScope = PropDescr(EnumObjAttr, enum_cls=ScopeEnum,
                                 doc='Target parameter scope.')
    # XXX should this have a default?
    nullValue = PropDescr(StrAttr, doc='Null value.')

    def _mergedone(self, *, stack=None, report=None):
        """Check that the `targetParam` attribute was specified."""

        if self.targetParam is None:
            logger.error('%s.targetParam: missing attribute' % self.nicepath)

        super()._mergedone(stack=stack, report=report)

    def format(self, **kwargs) -> str:
        """The `targetParam` value."""

        return self.targetParam or ''

    # XXX should return Parameter rather than Node (and should check this)?
    # noinspection PyPep8Naming
    @property
    @cache
    def targetParamNode(self) -> Union[Node, NullType]:
        """Get the node referenced by `targetParam`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return follow_reference(self, self.targetParam,
                                scope=self.targetParamScope, quiet=PATH_QUIET)


class _HasRefType(_Mixin):
    refType = PropDescr(EnumObjAttr, enum_cls=ReferenceTypeEnum,
                        mandatory=True, doc='Reference type.')


class InstanceRef(_Facet, _HasRefType):
    """Instance reference facet.
    """

    targetParent = PropDescr(StrAttr, doc='Target parent.')
    targetParentScope = PropDescr(EnumObjAttr, enum_cls=ScopeEnum,
                                  doc='Target parent scope.')

    # noinspection PyPep8Naming
    @property
    @cache
    def targetParentNode(self) -> Union[Node, NullType]:
        """Get the node referenced by `targetParent`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return follow_reference(self, self.targetParent,
                                scope=self.targetParentScope, quiet=PATH_QUIET)


# XXX possibly temporarily, Default and List aren't derived from _Facet;
#     they're a bit different from the other facets...
class List(_HasDescription, _HasSizes):
    """List facet.
    """

    minItems = PropDescr(IntAttr, default=0,
                         doc='Minimum number of list items.')
    maxItems = PropDescr(IntOrUnboundedAttr, default='unbounded',
                         doc='Maximum number of list items, or ``unbounded``.')
    nestedBrackets = PropDescr(EnumObjAttr, enum_cls=NestedBracketsEnum,
                               doc='Nested Brackets support.')

    def format(self, *, human: bool = False, **kwargs) -> str:
        text = ''

        # this gets overall list min/max entries and overall length information
        length = super().format(human=human, **kwargs)

        # XXX is this the best way to check whether an attribute has been
        #     explicitly supplied?
        min_def, min_val = 'minItems' in self.attrs, str(self.minItems)
        max_def, max_val = 'maxItems' in self.attrs, str(self.maxItems)
        if not human:
            text += '['
            if min_def:
                text += '%s' % min_val
            if min_def or max_def:
                text += ':'
            if max_def:
                text += '%s' % max_val
            text += ']'
        else:
            if min_def or max_def:
                text += ' ('
                if min_def and max_def:
                    text += '%s' % min_val
                    if min_val != max_val:
                        text += ' to %s' % max_val
                elif min_def:
                    text += 'at least %s' % min_val
                elif max_def:
                    text += 'up to %s' % max_val
                text += ' item)' if text.endswith(' 1') else ' items)'

        # the overall entries and length information always goes at the end
        text += length

        return text


class PathRef(_Facet, _HasRefType):
    """Path reference facet.
    """

    targetParents = PropDescr(StrListAttr, plural=True, doc='Target parents.')
    targetParentScope = PropDescr(EnumObjAttr, enum_cls=ScopeEnum,
                                  doc='Target parent scope.')
    targetType = PropDescr(EnumObjAttr, enum_cls=TargetTypeEnum,
                           doc='Target type.')
    targetDataType = PropDescr(EnumObjAttr, enum_cls=TargetDataTypeEnum,
                               doc='Target data type.')

    def format(self, **kwargs) -> str:
        """The `targetParents`, separated with spaces."""
        return ' '.join(self.targetParents)

    # noinspection PyPep8Naming
    @property
    @cache
    def targetParentsNodes(self) -> list[Union[Node, NullType]]:
        """Get the nodes referenced by `targetParents`.

        Returns:
            A list with an entry for each element of `targetParents`. Each
            entry is either the referenced node, or `Null` if not found.
        """

        return [
            follow_reference(self, target_parent, scope=self.targetParentScope,
                             quiet=PATH_QUIET) for target_parent in
            self.targetParents]

    # noinspection PyPep8Naming
    @property
    @cache
    def targetParentsNode(self) -> Union[Node, NullType]:
        """Get the first node referenced by `targetParents`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return follow_reference(self, self.targetParents,
                                scope=self.targetParentScope, quiet=PATH_QUIET)


class Pattern(_ValueFacet):
    """Pattern facet."""

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       nopatterncheck: bool = False,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        # can suppress pattern checks when the value is a pattern
        if nopatterncheck:
            return True

        if not isinstance(value, str):
            return True

        return bool(re.fullmatch(self.value, value))


# XXX some/all _PrangeFacet class methods might be better defined on 'sizes'
#     or 'ranges' objects, but those are just plain-old ListElem instances
# XXX the methods that support _PrangeFacet | range unions could also support
#     single values, and those that support lists could also support scalars
class _PrangeFacet(_Facet):
    """Base class for facets such as `Range` and `Size` that have associated
    python ranges (aka pranges)."""

    # helper class for storing a python range plus remembering whether
    # start, stop and step were specified
    class _Prange:
        def __init__(self, prange: range,
                     start_specified: bool = False,
                     stop_specified: bool = False,
                     step_specified: bool = False):
            self.prange = prange
            self.start_specified = start_specified
            self.stop_specified = stop_specified
            self.step_specified = step_specified

        def __str__(self) -> str:
            prange = self.prange
            text = 'prange('
            if self.start_specified:
                text += f'{prange.start}, '
            text += f'{prange.stop}'
            if self.step_specified:
                text += f', {prange.step}'
            text += ')'
            return text

    def __init__(self, **kwargs):
        # derived classes can redefine this in _mergedone()
        # XXX alarm bell: attributes aren't affected by merge()
        self._prange = _PrangeFacet._Prange(
                range(UnsignedInt.minval, UnsignedInt.maxval + 1))
        super().__init__(**kwargs)

    # XXX this needs to be done only once; errors should be reported then
    @classmethod
    def prange_clean(cls, facets: list['_PrangeFacet'], *,
                     errors: Optional[list] = None) \
            -> list['_PrangeFacet._Prange']:
        """Clean a list of python range facets, where possible combining
        overlapping and adjacent ranges, returning a list of (python)
        ranges."""

        # sort the ranges by (start, step)
        facets_sorted = sorted(facets,
                               key=lambda f: (f.prange.prange.start,
                                              f.prange.prange.step))
        if facets_sorted != facets and errors is not None:
            # XXX this should be reported once as part of a
            #     DataType._mergedone() check, not unconditionally here
            facets_text = ','.join(cls.prange_format(o) for o in facets)
            errors.append('out-of-order %s' % facets_text)

        # merge overlapping and adjacent ranges
        cursor = None
        pranges = []
        for facet in facets_sorted:
            prange = facet.prange
            first, last = prange.prange.start, prange.prange.stop - \
                                               prange.prange.step
            if len(pranges) == 0 or first > cursor:
                pranges.append(facet.prange)
            elif prange.prange.step != pranges[-1].prange.step or \
                    first - prange.prange.step not in pranges[-1].prange:
                if errors is not None:
                    errors.append("can't merge %s and %s" % (
                        pranges[-1], facet.prange))
                pranges.append(facet.prange)
            else:
                if errors is not None:
                    errors.append('overlapping %s and %s' % (
                        pranges[-1], facet.prange))

                pranges[-1] = _PrangeFacet._Prange(
                        range(pranges[-1].prange.start,
                              last + prange.prange.step,
                              prange.prange.step),
                        pranges[-1].start_specified,
                        prange.stop_specified,
                        prange.step_specified)
            cursor = last + prange.prange.step
        return pranges

    # check whether any needles aren't found in a haystack
    # XXX this might be easier to understand if it was split into two parts?
    @classmethod
    def prange_check(cls, haystacks: list['_PrangeFacet._Prange'],
                     needles: list[Union['_PrangeFacet._Prange', range]], *,
                     expand: bool = False, errors: Optional[list] = None) \
            -> bool:
        for needle in needles:
            found = False
            for haystack in haystacks:
                if cls.prange_contains(haystack, needle):
                    found = True
            if not found:
                if errors is not None:
                    # XXX the caller already swapped the arguments depending on
                    #     expand, so we have to account for this; this is very
                    #     messy; the caller should generate the message
                    haystack_text = ','.join(
                            cls.prange_format(h) for h in haystacks)
                    needle_text = cls.prange_format(needle)
                    errors.append("%s doesn't %s %s" % (
                        haystack_text if expand else needle_text,
                        'expand' if expand else 'restrict',
                        needle_text if expand else haystack_text))
                return False
        return True

    # XXX this doesn't yet support arbitrary step values
    @classmethod
    def prange_contains(cls, haystack: '_PrangeFacet._Prange',
                        needle: Union['_PrangeFacet._Prange', range]) -> bool:
        """Determine whether a python range contains another."""

        needle_prange = needle.prange \
            if isinstance(needle, _PrangeFacet._Prange) else needle
        return needle_prange[0] in haystack.prange and \
            needle_prange[-1] in haystack.prange

    @classmethod
    def prange_format(cls, facet_or_prange: Union['_PrangeFacet', range],
                      **kwargs) -> str:
        if isinstance(facet_or_prange, _PrangeFacet):
            facet = facet_or_prange
            text = facet.format(**kwargs)

        # this is a cut-down version of format(); it has to make assumptions
        # about what to show
        else:
            prange = facet_or_prange
            text = ''
            last = prange.stop - prange.step
            if prange.start != 0 or last == prange.start:
                text += '%s' % prange.start
            if last != prange.start:
                text += ':%s' % last
            if prange.step != 1:
                text += ':%s' % prange.step

        return text

    @property
    def prange(self) -> '_PrangeFacet._Prange':
        return self._prange

    @prange.setter
    def prange(self, value: '_PrangeFacet._Prange') -> None:
        self._prange = value

    # this is designed to be the format() implementation for derived classes
    def format(self, human: bool = False, **kwargs) -> str:
        """A string of the form ``min:max`` or ``min:max:step`` (if `step`
           isn't ``1``).
        """

        super().format(**kwargs)

        assert self._prange is not None
        start_specified, stop_specified, step_specified, prange = \
            self._prange.start_specified, self._prange.stop_specified, \
            self._prange.step_specified, self._prange.prange

        # this is only the last element if the range isn't empty
        def last(rng: range) -> int:
            return rng.stop - rng.step

        # alternative to len(rng) == 1 (which can fail for very large ranges)
        def is_single(rng: range) -> bool:
            return rng.start == last(rng)

        text = ''
        if not (start_specified or stop_specified or step_specified):
            pass
        elif not human:
            if start_specified and stop_specified and is_single(prange):
                text += '%d' % prange.start
            else:
                if start_specified:
                    text += '%d' % prange.start
                text += ':'
                if stop_specified:
                    text += '%d' % last(prange)
                if step_specified:
                    text += ':%s' % prange.step
        else:
            if start_specified and stop_specified:
                text += '%d' % prange.start
                if not is_single(prange):
                    text += ' to %d' % last(prange)
            elif start_specified:
                text += 'at least %d' % prange.start
            elif stop_specified:
                text += 'up to %d' % last(prange)
            if step_specified:
                text += ' stepping by %d' % prange.step
        return text


class Range(_PrangeFacet):
    """Range facet.
    """

    minInclusive = PropDescr(IntAttr, doc='Minimum value (inclusive).')
    maxInclusive = PropDescr(IntAttr, doc='Maximum value (inclusive).')
    step = PropDescr(IntAttr, default=1, doc='Step.')

    def _mergedone(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        # update the python range object (this is done here rather than in the
        # constructor, so it will be updated if the object is ever updated)

        # determine the minimum and maximum values by finding the containing
        # _Number class (not as easy as it might be, because the object isn't
        # yet fully constructed, so need a couple of different approaches)
        # XXX could avoid doing this for fully-specified ranges
        primitive = self.instance_in_stack(stack, _Number)
        if not primitive:
            # this is needed in derived data type definitions
            data_type = self.instance_in_stack(stack, DataType)
            if data_type:
                primitive = data_type.primitive_inherited
        if primitive:
            start_specified, stop_specified, step_specified = \
                'minInclusive' in self.attrs, 'maxInclusive' in self.attrs, \
                'step' in self.attrs
            minval, maxval = primitive.minval, primitive.maxval
            start = (self.minInclusive if start_specified else minval)
            stop = (self.maxInclusive if stop_specified else maxval) + 1
            step = (self.step if step_specified else 1)
            self._prange = _PrangeFacet._Prange(
                    range(start, stop, step),
                    start_specified, stop_specified, step_specified)

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, int):
            return True

        return self.prange_check(
                [self], [range(value, value + 1)], errors=errors)


# this isn't a _PrangeFacet because you can't define python ranges for decimals
# (could support them by scaling, but would need to know the precision; L8R...)
class DecimalRange(_Facet):
    """Decimal range facet.
    """

    minInclusive = PropDescr(DecimalAttr, doc='Minimum value (inclusive).')
    maxInclusive = PropDescr(DecimalAttr, doc='Maximum value (inclusive).')
    step = PropDescr(DecimalAttr, default='1.0', doc='Step.')

    # XXX this hasn't been rewritten to support 'human' etc.
    def format(self, **kwargs) -> str:
        """A string of the form ``min:max`` or ``min:max:step`` (if `step`
        isn't ``1.0``)."""
        text = '%s:%s' % (nice_none(self.minInclusive, '0.0'),
                          nice_none(self.maxInclusive, ''))
        if not re.match(r'1(\.0*)$', self.step):
            text += ':%s' % self.step
        return text


class Size(_PrangeFacet):
    """Size facet.
    """

    minLength = PropDescr(IntAttr, default=0, doc='Minimum length.')
    # maxLength doesn't support 'unbounded'; it has no default
    maxLength = PropDescr(IntAttr, doc='Maximum length.')

    def _mergedone(self, *, stack: Optional[Stack] = None,
                   report: Optional[Report] = None) -> None:
        # update the python range object (this is done here rather than in the
        # constructor, so it will be updated if the object is ever updated)
        start_specified = 'minLength' in self.attrs
        stop_specified = 'maxLength' in self.attrs
        start = (self.minLength if start_specified else UnsignedInt.minval)
        stop = (self.maxLength if stop_specified else UnsignedInt.maxval) + 1
        self._prange = _PrangeFacet._Prange(range(start, stop),
                                            start_specified, stop_specified)

    def is_valid_value(self, value: Any, *,
                       errors: Optional[list[str]] = None,
                       **kwargs) -> bool:
        if not super().is_valid_value(value, errors=errors, **kwargs):
            return False

        if not isinstance(value, (str, int)):
            return True

        # if the arg isn't a string, it's the precalculated length
        lenval = len(value) if isinstance(value, str) else value
        return self.prange_check([self], [range(lenval + 1)], errors=errors)


class Units(_Facet):
    """Units facet.
    """

    value = PropDescr(StrAttr, mandatory=True, doc='Value.')

    def format(self, **kwargs) -> str:
        """The `value`."""
        return self.value or ''


# XXX should profiles be model items?
class Profile(_Dm_modelItem):
    """A profile definition.
    """

    dmr_previousProfile = PropDescr(StrAttr)

    # XXX will need additional logic for pyxb, which will return a python list;
    #     similarly for other list-valued attributes such as targetParents
    extends = PropDescr(StrListAttr, doc='Extends.')
    # XXX have suppressed this because it's not used and will probably never be
    #     used; the DM Schema should deprecate it
    # minVersions = PropDescr(StrListAttr, plural=True,
    #                         doc='Minimum model version(s).')
    objects = PropDescr(ListElem, plural=True, node_cls='ObjectRef',
                        doc='Profile objects.')
    commands = PropDescr(ListElem, plural=True, node_cls='CommandRef',
                         doc='Profile commands.')
    events = PropDescr(ListElem, plural=True, node_cls='EventRef',
                       doc='Profile events.')
    parameters = PropDescr(ListElem, plural=True, node_cls='ParameterRef',
                           doc='Profile parameters.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Model` (or `Component`) key and the
        `_ModelItem.name` attribute."""
        model_or_component = parent.instance_in_path((Model, Component))
        assert model_or_component is not None
        name, base = (dct.get(a) for a in ('name', 'base'))
        return model_or_component.key, (name or base or '')

    # XXX this adds items in the order that they're encountered, which isn't
    #     good enough; need to place them in the hierarchy
    def profile_expand(self, *, base: bool = False, extends: bool = False,
                       internal_only: bool = False, items_only: bool =
                       False) -> list[Union[Description, '_ProfileItem']]:
        """Expand a profile, returning am ordered list of its elements and (if
        requested) of its `base` and/or `extends` profiles."""

        # XXX this doesn't need to be a dictionary
        elems = {}

        def expand_elem(elem: Node) -> None:
            if not items_only or isinstance(elem, _ProfileItem):
                path = elem.fullpath(style='object+notprofile')
                elems[path] = elem
            for child in elem.elems:
                expand_elem(child)

        def expand_profile(prof: Profile) -> None:
            for elem in prof.elems:
                expand_elem(elem)

        def expand_dependencies(prof: Profile, *,
                                active: Optional[list[Profile]] = None) \
                -> None:
            if active is None:
                active = []
            if prof in active:
                logger.error('%s: recursive profile dependency: %s' % (
                    prof.objpath,
                    ' -> '.join(p.name for p in active + [prof])))
                return
            active.append(prof)
            profs = []
            if base:
                profs.append(prof.baseNode)
            if extends:
                profs.extend(prof.extendsNodes)
            profs = [prof for prof in profs if prof]
            if internal_only:
                profs = [prof for prof in profs if prof.name.startswith('_')]
            for prof_ in profs:
                expand_dependencies(prof_, active=active)
            expand_profile(prof)
            active.remove(prof)

        expand_dependencies(self)
        return list(elems.values())

    @property
    @cache
    def profile_name(self) -> str:
        match = re.match(r'^([^:]+):\d+$', self.name.strip())
        assert match is not None, 'invalid profile name %r' % self.name
        return match.group(1)

    @property
    @cache
    def profile_version(self) -> int:
        match = re.match(r'^[^:]+:(\d+)$', self.name.strip())
        assert match is not None, 'invalid profile name %r' % self.name
        return int(match.group(1))

    # noinspection PyPep8Naming
    @property
    def baseNode(self) -> Union['Profile', NullType]:
        """Get the node referenced by `base`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        key = self.key[:-1] + (self.base,)
        return self.find(Profile, *key)

    # noinspection PyPep8Naming
    @property
    def baseNodeImplicit(self) -> Union['Profile', NullType]:
        """Get the node referenced by `base`, or the previous version if
        not indicated explicitly.

        Returns:
            The referenced node, or `Null` if not found.
        """

        base = self.base
        if base is None and self.profile_version > 1:
            base = '%s:%d' % (self.profile_name, self.profile_version - 1)

        key = self.key[:-1] + (base,)
        return self.find(Profile, *key)

    # noinspection PyPep8Naming
    @property
    @cache
    def extendsNodes(self) -> list[Union['Profile', NullType]]:
        """Get the nodes referenced by `extends`.

        Returns:
            A list with an entry for each element of `extends`. Each
            entry is either the referenced node, or `Null` if not found.
        """

        nodes = []
        for extend in self.extends:
            key = self.key[:-1] + (extend,)
            nodes.append(self.find(Profile, *key))
        return nodes

    auto_macro_criteria = {
        'showid': lambda node: node.id,
        'profdesc': lambda node: True
    }


class _ProfileItem(_HasDescription):
    """Base class for profiles and their parameter, object, command and
    event references. All these nodes have `Description` and `ref` attributes.
    """

    ref = PropDescr(StrAttr, mandatory=True, doc='Ref.')

    # some subclasses override this
    requirement = None

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Profile` key, `ObjectRef` path and the
        `_ProfileItem.ref` attribute."""

        assert (profile := parent.profile_in_path) is not None
        return profile.key, parent.fullpath(
                style='object+notprofile'), dct.get('ref')

    def _mergedone(self, *, stack=None, report=None):
        """Check that the ``ref`` attribute was specified."""

        if self.ref is None:
            logger.error('%s.ref: missing attribute' % self.nicepath)

        super()._mergedone(stack=stack, report=report)

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union['_Dm_modelItem', NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        raise NotImplementedError


class ObjectRef(_ProfileItem):
    """An object reference.
    """

    dmr_previousObject = PropDescr(StrAttr)

    requirement = PropDescr(EnumObjAttr, enum_cls=ObjectRequirementEnum,
                            mandatory=True, doc='Object requirement.')
    commands = PropDescr(ListElem, plural=True, node_cls='CommandRef',
                         doc='Object commands.')
    events = PropDescr(ListElem, plural=True, node_cls='EventRef',
                       doc='Object events.')
    parameters = PropDescr(ListElem, plural=True, node_cls='ParameterRef',
                           doc='Object parameters.')

    # ObjectRef overrides this because its key doesn't include the parent path,
    # which is always empty
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Profile` key and the `_ProfileItem.ref` attribute."""

        assert (profile := parent.profile_in_path) is not None
        return profile.key, dct.get('ref')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Object, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing command or event reference's
        # refNode, or the model
        node = (self.instance_in_path((CommandRef, EventRef)).refNode or
                self.model_in_path)
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)


# XXX this is currently used for both uniqueKey and profile parameter refs
class ParameterRef(_ProfileItem):
    """A parameter reference.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)

    requirement = PropDescr(EnumObjAttr, enum_cls=ParameterRequirementEnum,
                            mandatory=True, doc='Parameter requirement.')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """``None`` if within a `UniqueKey`, or else the parent `Profile` key,
        `ObjectRef` path and the `_ProfileItem.ref` attribute."""

        return None if isinstance(parent, UniqueKey) else super().calckey(
                parent, dct, **kwargs)

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Parameter, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing command, event or object
        # reference's refNode, or the model
        types = (CommandRef, EventRef, ObjectRef)
        node = (self.object_in_path or
                self.instance_in_path(types).refNode or self.model_in_path)
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)

    # XXX can't rely on self.keylast because of the above UniqueKey logic
    def format(self, **kwargs) -> str:
        return self.ref or ''


class CommandRef(_ProfileItem):
    """A command reference.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)

    input = PropDescr(SingleElem, node_cls='InputRef',
                      doc='Command input arguments.')
    output = PropDescr(SingleElem, node_cls='OutputRef',
                       doc='Command output arguments.')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Command, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing object reference's refNode,
        # or the model
        node = self.instance_in_path(ObjectRef).refNode or self.model_in_path
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)


# XXX should this be a _ProfileItem, even though it has no ref attribute?
class _ArgumentsRef(_HasDescription):
    """Base class for arguments references."""

    objects = PropDescr(ListElem, plural=True, node_cls='ObjectRef')
    parameters = PropDescr(ListElem, plural=True, node_cls='ParameterRef')

    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `CommandRef` or `EventRef` key and the class name
        (plus a ``.``)."""
        return parent.key, cls.__name__ + '.'

    def format(self, **kwargs) -> str:
        return super().format(**kwargs).replace('Ref', '')


class InputRef(_ArgumentsRef):
    """Input arguments reference."""


class OutputRef(_ArgumentsRef):
    """Output arguments reference."""


class EventRef(_ProfileItem):
    """An event reference.
    """

    dmr_previousCommand = PropDescr(StrAttr)
    dmr_previousEvent = PropDescr(StrAttr)
    dmr_previousParameter = PropDescr(StrAttr)

    objects = PropDescr(ListElem, plural=True, node_cls='ObjectRef',
                        doc='Event objects.')
    parameters = PropDescr(ListElem, plural=True, node_cls='ParameterRef',
                           doc='Event parameters.')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Event, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing object reference's refNode,
        # or the model
        node = self.instance_in_path(ObjectRef).refNode or self.model_in_path
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)

############
# DT support


# XXX _HasContent is problematic, because it's on the main DM inheritance
#     line so using it pollutes things; it should be a _Mixin
# noinspection PyPep8Naming
class Dt_annotation(_HasContent):
    """A DT annotation element.
    """


# noinspection PyPep8Naming
class Dt_document(_Base, _Document):
    """A DT document."""

    xmlns_dt = PropDescr(NamespaceStrAttr, doc='DT namespace.')

    deviceType = PropDescr(StrAttr, doc='Device type.')
    uuid = PropDescr(StrAttr, doc='UUID.')

    annotation = PropDescr(DescriptionSingleElem, node_cls='Dt_annotation',
                           doc="Annotation.")

    imports = PropDescr(ListElem, plural=True, doc="Imports.")
    models = PropDescr(ListElem, plural=True, node_cls='Dt_model',
                       doc="Models.")

    # XXX does DT have a file attribute?
    @property
    def file_safe(self) -> FileName:
        assert isinstance(self.parent, Xml_file)
        return FileName(os.path.basename(self.parent.keylast))

    @property
    def file_info(self) -> dict[str, Optional[str]]:
        return {'Device type': self.deviceType, 'UUID': self.uuid}


# noinspection PyPep8Naming
class _Dt_item(_Base0):
    ref = PropDescr(StrAttr)

    annotation = PropDescr(DescriptionSingleElem, node_cls='Dt_annotation',
                           doc="Annotation.")

    # XXX I think we can have a mostly-shared implementation for this
    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Model, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        raise NotImplementedError

    # need explicit implementation because otherwise would get _Node.format()
    def format(self, typ: bool = False, brief: bool = False, **kwargs) -> str:
        if not typ and not brief:
            return self.ref or super().format(**kwargs)
        elif typ:
            return self.refNode.format(typ=typ, **kwargs)
        elif brief:
            return self.refNode.format(brief=brief, **kwargs)

    # this gets public attributes from the referenced object
    def __getattr__(self, attr) -> Any:
        if attr.startswith('_'):
            # this is expected
            raise AttributeError

        if (ref_node := self.refNode) is Null:
            # this is unexpected
            text = '%s.%s (%s not found)' % (type(self).__name__, attr,
                                             self.ref)
            raise NodeException(text, self.ref)

        return getattr(ref_node, attr)


# noinspection PyPep8Naming
class _Dt_modelItem(_Dt_item, _ModelItem):
    annotation = PropDescr(DescriptionSingleElem, node_cls='Dt_annotation',
                           doc="Annotation.")

    # this has to be defined on the _Dt_modelItem so its parent is in the DT
    # tree (if it was accessed via refNode, its parent would be in the DM tree)
    # XXX this was added by DMR-473 PR, which changed DT items to be
    #     _ModelItems, but it means that DT descriptions are always Null; it's
    #     been disabled but this might expose the reason why it was added in
    #     the first place
    # description = PropDescr(DescriptionSingleElem, doc="Referenced node's "
    #                                                    "description.")


# noinspection PyPep8Naming
# XXX would like this to be a Model, but this doesn't currently work
class Dt_model(_Dt_modelItem, _Model):
    parameters = PropDescr(ListElem, plural=True, node_cls='Dt_parameter')
    objects = PropDescr(ListElem, plural=True, node_cls='Dt_object')

    def merge(self, *, stack: Optional[Stack] = None, **kwargs) -> Any:
        self.refNode.merge(stack=stack)

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Model, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return ModelAccessor.entities[self.ref][1] if \
            self.ref in ModelAccessor.entities else Null

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Dt_object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.ref)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not isinstance(
                elem, Dt_object) or elem in self.h_objects)

    # this is needed to prevent getting profiles from the referenced model
    @property
    def profiles(self) -> list[Profile]:
        return []


# noinspection PyPep8Naming
class Dt_object(_Dt_modelItem, _Object):
    # XXX the DT schema doesn't permit this; this is an error?
    access = PropDescr(EnumObjAttr, enum_cls=Dt_objectAccessEnum,
                       doc='Object access.')
    minEntries = PropDescr(IntAttr, default=1,
                           doc='Minimum number of object entries.')
    maxEntries = PropDescr(IntOrUnboundedAttr, default=1,
                           doc='Maximum number of object entries, '
                               'or ``unbounded``.')

    parameters = PropDescr(ListElem, plural=True, node_cls='Dt_parameter')
    commands = PropDescr(ListElem, plural=True, node_cls='Dt_command')
    events = PropDescr(ListElem, plural=True, node_cls='Dt_event')

    # XXX Dt_object instances are keyed for the benefit of .h_parent
    @classmethod
    def calckey(cls, parent: Node, dct: dict, **kwargs) -> Key:
        """The parent `Dt_model.ref` attribute, parent object path, and the
        `_Dt_item.ref` attribute.
        """

        model = parent.instance_in_path(Dt_model)
        assert model is not None
        return model.ref, parent.objpath, dct.get('ref', '')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Object, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing object, command, event or
        # model's refNode
        # noinspection PyTypeChecker
        node = self.instance_in_path(
                (Dt_object, Dt_command, Dt_event, Dt_model),
                predicate=lambda n: n is not self).refNode
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)

    @property
    @cache
    def h_parent(self) -> Optional[Union[Dt_model, 'Dt_object']]:
        ref = self.ref
        assert ref is not None
        head, _ = self._path_split(ref)
        if head == '':
            parent = self.parent
        else:
            parent_key = self.key[:-1] + (head,)
            parent = self.find(Dt_object, *parent_key)
            if not parent:
                # this should only happen when there's something wrong, but
                # it's safer and more consistent to return the model in this
                # case (self.parent will be the model)
                parent = self.parent
        return parent

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Dt_object']:
        container = self.instance_in_path((Dt_model, _Dt_arguments, Dt_event))
        assert container is not None
        objs = ListElem.ListWrapper()
        for obj in container.objects:
            head, _ = self._path_split(obj.objpath)
            if head == self.objpath:
                objs += [obj]
        return objs

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        # XXX ideally the objects would be inserted in a more logical place
        return tuple(self.elems + tuple(self.h_objects))


# noinspection PyPep8Naming
class Dt_parameter(_Dt_modelItem, _Parameter):
    access = PropDescr(EnumObjAttr, enum_cls=ParameterAccessEnum,
                       doc='Parameter access.')
    activeNotify = PropDescr(EnumObjAttr, enum_cls=Dt_activeNotifyEnum,
                             doc='Parameter active notify.')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Parameter, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing command, event, object or
        # model's refNode
        node = self.instance_in_path((Dt_command, Dt_event, Dt_object,
                                      Dt_model)).refNode
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)


# noinspection PyPep8Naming
class Dt_command(_Dt_modelItem, _Command):
    # XXX invalid node_cls isn't detected, e.g. 'Dt_Input' typo
    input = PropDescr(SingleElem, node_cls='Dt_input',
                      doc='Command input arguments.')
    output = PropDescr(SingleElem, node_cls='Dt_output',
                       doc='Command input arguments.')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Command, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing object's or model's refNode
        node = self.instance_in_path((Dt_object, Dt_model)).refNode
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)

    def format(self, **kwargs) -> str:
        text = super().format(**kwargs)
        if not text.endswith('.'):
            text += '.'
        return text


# noinspection PyPep8Naming
class _Dt_arguments(_Dt_modelItem):
    parameters = PropDescr(ListElem, plural=True, node_cls='Dt_parameter')
    objects = PropDescr(ListElem, plural=True, node_cls='Dt_object')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Model, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        return self.instance_in_path(Dt_command).refNode

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.nameOrBase)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not
                     isinstance(elem, Dt_object) or elem in self.h_objects)

    # the refNode is the command, so can't use its .format()
    def format(self, **kwargs) -> str:
        return type(self).__name__.replace('Dt_', '').capitalize() + '.'


# noinspection PyPep8Naming
class Dt_input(_Dt_arguments, _Input):
    pass


# noinspection PyPep8Naming
class Dt_output(_Dt_arguments, _Output):
    pass


# noinspection PyPep8Naming
class Dt_event(_Dt_modelItem, _Event):
    parameters = PropDescr(ListElem, plural=True, node_cls='Dt_parameter')
    objects = PropDescr(ListElem, plural=True, node_cls='Dt_object')

    # noinspection PyPep8Naming
    @property
    @cache
    def refNode(self) -> Union[Event, NullType]:
        """Get the node referenced by `ref`.

        Returns:
            The referenced node, or `Null` if not found.
        """

        # the ref is relative to the containing object's or model's refNode
        node = self.instance_in_path((Dt_object, Dt_model)).refNode
        return follow_reference(node, self.ref, scope=ScopeEnum('normal'),
                                quiet=PATH_QUIET)

    # XXX should try to optimize this
    @property
    @cache
    def h_objects(self) -> ListElem.ListWrapper['Object']:
        objs = {}
        for obj in self.objects:
            path = Path(obj.nameOrBase)
            name, *rest = path.comps
            if len(rest) == 1 and name not in objs:
                objs[name] = obj
        return ListElem.ListWrapper(objs.values())

    @property
    @cache
    def h_elems(self) -> tuple[Node, ...]:
        return tuple(elem for elem in self.elems if not
                     isinstance(elem, Dt_object) or elem in self.h_objects)

    def format(self, **kwargs) -> str:
        text = super().format(**kwargs)
        if not text.endswith('.'):
            text += '.'
        return text


# add class hierarchy
__doc__ += class_hierarchy(_Mergeable)
