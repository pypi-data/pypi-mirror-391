# smart_split/core.py

import os
import pandas as pd
import numpy as np
from .utils.io import load_datasets, save_csv
from .utils.stats import print_ratio_report

class SmartSplitter:
    """
    Multi-domain, multi-class dataset splitter
    Offers 3 balancing strategies: 'label', 'domain', 'intersection'
    """

    def __init__(self, data_path, class_list, label_map=None, balance_mode="label", label_col="label", ratio=(8,1,1), seed=42, output="./output"):
        self.data_path = data_path
        self.class_list = class_list
        self.label_map = label_map
        self.balance_mode = balance_mode
        self.label_col = label_col
        self.ratio = np.array(ratio)
        self.seed = seed
        self.output = output
        self.rng = np.random.RandomState(seed)
        self.load_map = self.label_map if self.label_map else {c: c for c in self.class_list}

    # --- ìƒ˜í”Œë§ í—¬í¼ ---
    def _sample_uniformly(self, df, group_by_col, target_count):
        """
        DataFrame(df)ì—ì„œ target_countë§Œí¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
        ìƒ˜í”Œë§ ì‹œ, group_by_col(ì˜ˆ: 'label' ë˜ëŠ” 'domain')ì˜ ë¹„ìœ¨ì„ ìµœëŒ€í•œ ë§ì¶¥ë‹ˆë‹¤.
        """
        groups = df[group_by_col].unique()
        n_groups = len(groups)
        
        if n_groups == 0:
            return df.sample(n=min(target_count, len(df)), random_state=self.seed)

        samples_per_group = target_count // n_groups
        remainder = target_count % n_groups

        balanced_dfs = []
        shuffled_groups = self.rng.permutation(groups)
        
        for i, group_val in enumerate(shuffled_groups):
            group_df = df[df[group_by_col] == group_val]
            
            n_to_sample = samples_per_group + (1 if i < remainder else 0)
            n_to_sample = min(n_to_sample, len(group_df)) 
            
            if n_to_sample > 0:
                balanced_dfs.append(group_df.sample(n=n_to_sample, random_state=self.seed))

        final_df = pd.concat(balanced_dfs) if balanced_dfs else pd.DataFrame(columns=df.columns)
        
        gap = target_count - len(final_df)
        if gap > 0:
            available_df = df[~df.index.isin(final_df.index)]
            n_to_fill = min(gap, len(available_df)) 
            if n_to_fill > 0:
                gap_df = available_df.sample(n=n_to_fill, random_state=self.seed)
                final_df = pd.concat([final_df, gap_df])

        return final_df.sample(frac=1, random_state=self.seed)

    # --- ë°¸ëŸ°ì‹± ì „ëµ 1: ë¼ë²¨ ìš°ì„  ---
    def _split_by_label_priority(self, df):
        class_counts = df[self.label_col].value_counts()
        min_class_count = class_counts.min()
        
        print(f"Balancing Plan [Label Priority]: Downsampling all classes to {min_class_count} samples.")

        balanced_dfs = []
        for class_name in self.class_list:
            label_val = self.load_map[class_name]
            class_df = df[df[self.label_col] == label_val]
            
            if len(class_df) == 0: continue

            if len(class_df) <= min_class_count:
                balanced_dfs.append(class_df)
            else:
                # [ë¼ë²¨ ìš°ì„ ] ë‹¤ìˆ˜ ë¼ë²¨ -> 'ë„ë©”ì¸' ê· í˜• ìƒ˜í”Œë§
                balanced_class_df = self._sample_uniformly(
                    class_df, 
                    group_by_col='domain', # ë„ë©”ì¸ ê· í˜•
                    target_count=min_class_count
                )
                balanced_dfs.append(balanced_class_df)
        
        balanced_df = pd.concat(balanced_dfs).reset_index(drop=True)
        # ë¶„í•  ê¸°ì¤€: ë¼ë²¨
        return balanced_df, self.label_col 

    # --- ë°¸ëŸ°ì‹± ì „ëµ 2: ë„ë©”ì¸ ìš°ì„  ---
    def _split_by_domain_priority(self, df):
        domain_counts = df['domain'].value_counts()
        min_domain_count = domain_counts.min()
        
        print(f"Balancing Plan [Domain Priority]: Downsampling all domains to {min_domain_count} samples.")
        
        balanced_dfs = []
        for domain_name in df['domain'].unique():
            domain_df = df[df['domain'] == domain_name]

            if len(domain_df) <= min_domain_count:
                balanced_dfs.append(domain_df)
            else:
                # [ë„ë©”ì¸ ìš°ì„ ] ë‹¤ìˆ˜ ë„ë©”ì¸ -> 'ë¼ë²¨' ê· í˜• ìƒ˜í”Œë§
                balanced_domain_df = self._sample_uniformly(
                    domain_df, 
                    group_by_col=self.label_col, # ë¼ë²¨ ê· í˜•
                    target_count=min_domain_count
                )
                balanced_dfs.append(balanced_domain_df)

        balanced_df = pd.concat(balanced_dfs).reset_index(drop=True)
        # ë¶„í•  ê¸°ì¤€: ë„ë©”ì¸
        return balanced_df, 'domain'

    # --- ë°¸ëŸ°ì‹± ì „ëµ 3: êµì§‘í•© (ì™„ë²½ ê· í˜•) ---
    def _split_by_intersection(self, df):
        # (ë„ë©”ì¸, ë¼ë²¨) êµì§‘í•© ê·¸ë£¹ë³„ ì¹´ìš´íŠ¸
        group_counts = df.groupby(['domain', self.label_col]).size()
        
        if group_counts.empty:
            print("Error [Intersection]: No valid (domain, label) groups found.")
            return pd.DataFrame(columns=df.columns), self.label_col

        min_group_count = group_counts.min()
        min_group_name = group_counts.idxmin()
        
        print(f"Balancing Plan [Intersection]: Smallest group is {min_group_name} with {min_group_count} samples.")
        print(f"Downsampling ALL (domain, label) groups to {min_group_count} samples.")

        balanced_dfs = []
        # groupby().sample()ì€ ê·¸ë£¹ì´ min_group_countë³´ë‹¤ ì‘ìœ¼ë©´ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ apply ì‚¬ìš©
        for (domain, label), group_df in df.groupby(['domain', self.label_col]):
            if len(group_df) >= min_group_count:
                balanced_dfs.append(group_df.sample(n=min_group_count, random_state=self.seed))
            else:
                # (ì´ë¡ ìƒ min_group_countê°€ ìµœì†Œê°’ì´ë¯€ë¡œ ì´ ê²½ìš°ëŠ” ì—†ìŒ)
                print(f"Warning [Intersection]: Group ({domain}, {label}) has {len(group_df)} samples, skipping.")

        if not balanced_dfs:
            print("Error [Intersection]: No data left after sampling.")
            return pd.DataFrame(columns=df.columns), self.label_col

        balanced_df = pd.concat(balanced_dfs).reset_index(drop=True)
        # ë¶„í•  ê¸°ì¤€: ë¼ë²¨ (ë„ë©”ì¸ë„ ê°€ëŠ¥)
        return balanced_df, self.label_col

    # --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
    def save(self, train_df, val_df, test_df):
        os.makedirs(self.output, exist_ok=True)
        save_csv(train_df, os.path.join(self.output, "train.csv"))
        save_csv(val_df, os.path.join(self.output, "val.csv"))
        save_csv(test_df, os.path.join(self.output, "test.csv"))
        print(f"\nâœ… Split complete! Files saved in {self.output}")

    def run(self, report=True, stats_only=False):
        print("Loading datasets...", flush=True)

        # 1. ë°ì´í„° ë¡œë“œ
        df = load_datasets(self.data_path, self.class_list, self.load_map)
        
        if df.empty:
            print(f"Error: No data loaded. If you input it as cli check --data path and --classes {self.class_list}")
            return
            
        # 2. ì›ë³¸ ë°ì´í„° í†µê³„ ë¦¬í¬íŠ¸
        print("\n" + "="*40)
        print("ğŸ“Š Raw Data Stats (Before Balancing)")
        print("="*40)
        print(f"Total files found: {len(df)}")
        print(f"\nClass counts (raw):\n{df[self.label_col].value_counts()}")
        print(f"\nDomain counts (raw):\n{df['domain'].value_counts()}")
        print(f"\nCounts per (Domain, Label):\n{df.groupby('domain')[self.label_col].value_counts()}")
        print("="*40)

        label_dic = df[self.label_col].value_counts().to_dict()
        keys_less_than_10 = [key for key, value in label_dic.items() if value < 10]

        # 3. stats-only ëª¨ë“œë©´ ì—¬ê¸°ì„œ ì¤‘ì§€ (ë°¸ëŸ°ì‹± ê³„íš ì¶œë ¥ ì „)
        if stats_only:
            print(f"\n--stats-only mode enabled with --balance-mode='{self.balance_mode}'.")
            print("Stopping before balancing, splitting, or saving.")
            print("="*40)
            return
        
        # ê° class ê°œìˆ˜ê°€ 10ê°œ ë¯¸ë§Œì´ë©´ ì¤‘ì§€ ë° ì—ëŸ¬ë©”ì„¸ì§€ ì¶œë ¥ 
        if keys_less_than_10:
            print("Error: Please check your data. There are fewer than 10 data points in your data.")
            print(f"Please keep at least 10 data points per class. Missing data: {", ".join(keys_less_than_10)}")
            return

        # 4. ì„ íƒëœ ë°¸ëŸ°ì‹± ëª¨ë“œ ì‹¤í–‰
        print(f"\nRunning with --balance-mode = '{self.balance_mode}'")
        
        balanced_df = None
        stratify_col = None # ë¶„í•  ê¸°ì¤€ (label ë˜ëŠ” domain)

        if self.balance_mode == 'label':
            balanced_df, stratify_col = self._split_by_label_priority(df)
        elif self.balance_mode == 'domain':
            balanced_df, stratify_col = self._split_by_domain_priority(df)
        elif self.balance_mode == 'intersection':
            balanced_df, stratify_col = self._split_by_intersection(df)
        
        if balanced_df is None or balanced_df.empty:
            print("Error: No data left after balancing. Cannot proceed.")
            return

        print(f"\nTotal balanced dataset size: {len(balanced_df)}")
        print(f"Final balanced class counts:\n{balanced_df[self.label_col].value_counts()}")
        print(f"Final balanced domain counts:\n{balanced_df['domain'].value_counts()}")

        # 5. ìµœì¢… ë¶„í•  (Stratified)
        print(f"\nSplitting data (Stratify by '{stratify_col}')...", flush=True)
        train_ratio, val_ratio, test_ratio = self.ratio / self.ratio.sum()

        from sklearn.model_selection import train_test_split
        
        try:
            train_df, temp_df = train_test_split(
                balanced_df,
                test_size=(1 - train_ratio),
                stratify=balanced_df[stratify_col],
                random_state=self.seed
            )

            relative_val_ratio = val_ratio / (val_ratio + test_ratio)
            
            val_df, test_df = train_test_split(
                temp_df,
                test_size=(1 - relative_val_ratio),
                stratify=temp_df[stratify_col],
                random_state=self.seed
            )
        except ValueError as e:
            print("\n" + "="*50)
            print("CRITICAL ERROR during train_test_split:")
            print(f"'{e}'")
            print("\nThis usually means your smallest group count is too low for the ratio.")
            print("Check the 'Raw Data Stats' and README 'Troubleshooting' section.")
            print("="*50)
            return

        # 6. ì €ì¥ ë° ë¦¬í¬íŠ¸
        self.save(train_df, val_df, test_df)
        
        if report:
            print_ratio_report(
                train_df, val_df, test_df, 
                label_col=self.label_col, 
                label_map=self.label_map
            )