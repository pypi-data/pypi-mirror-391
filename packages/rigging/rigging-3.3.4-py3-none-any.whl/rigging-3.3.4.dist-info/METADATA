Metadata-Version: 2.4
Name: rigging
Version: 3.3.4
Summary: LLM Interaction Framework
License: MIT
License-File: LICENSE
Author: Nick Landers
Author-email: monoxgas@gmail.com
Requires-Python: >=3.10,<3.14
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Provides-Extra: all
Provides-Extra: data
Provides-Extra: examples
Provides-Extra: llm
Requires-Dist: accelerate (>=0.30.1,<0.31.0) ; extra == "llm" or extra == "all"
Requires-Dist: aiodocker (>=0.22.2,<0.23.0) ; extra == "examples" or extra == "all"
Requires-Dist: asyncssh (>=2.14.2,<3.0.0) ; extra == "examples" or extra == "all"
Requires-Dist: click (>=8.1.7,<9.0.0) ; extra == "examples" or extra == "all"
Requires-Dist: colorama (>=0.4.6,<0.5.0)
Requires-Dist: dreadnode (>=1.12.0)
Requires-Dist: elasticsearch (>=8.13.2,<9.0.0) ; extra == "data" or extra == "all"
Requires-Dist: httpx (>=0.28.0,<0.29.0) ; extra == "examples" or extra == "all"
Requires-Dist: jsonpath-ng (>=1.7.0,<2.0.0)
Requires-Dist: jsonref (>=1.1.0,<2.0.0)
Requires-Dist: litellm (>=1.67.2,<2.0.0)
Requires-Dist: loguru (>=0.7.2,<0.8.0)
Requires-Dist: mcp (>=1.5.0,<2.0.0)
Requires-Dist: pandas (>=2.2.2,<3.0.0) ; extra == "data" or extra == "all"
Requires-Dist: pydantic (>=2.7.3,<3.0.0)
Requires-Dist: pydantic-xml (<=2.17.0)
Requires-Dist: ruamel-yaml (>=0.18.10,<0.19.0)
Requires-Dist: transformers (>=4.41.0,<5.0.0) ; extra == "llm" or extra == "all"
Requires-Dist: vllm (>=0.5.0,<0.6.0) ; extra == "llm" or extra == "all"
Requires-Dist: websockets (>=13.0,<14.0) ; extra == "examples" or extra == "all"
Requires-Dist: xmltodict (>=0.13.0,<0.14.0)
Project-URL: Repository, https://github.com/dreadnode/rigging
Description-Content-Type: text/markdown

<p align="center">
    <img
    src="https://d1lppblt9t2x15.cloudfront.net/logos/5714928f3cdc09503751580cffbe8d02.png"
    alt="Logo"
    align="center"
    width="144px"
    height="144px"
    />
</p>

<h3 align="center">
Flexible LLM library for code and agents
</h3>

<h4 align="center">
    <img alt="PyPI - Python Version" src="https://img.shields.io/pypi/pyversions/rigging">
    <img alt="PyPI - Version" src="https://img.shields.io/pypi/v/rigging">
    <img alt="GitHub License" src="https://img.shields.io/github/license/dreadnode/rigging">
    <img alt="GitHub Actions Workflow Status" src="https://img.shields.io/github/actions/workflow/status/dreadnode/rigging/ci.yml">
</h4>

</br>

Rigging is a lightweight LLM framework to make using language models in production code as simple and effective as possible. Here are the highlights:

- **Structured Pydantic models** can be used interchangeably with unstructured text output.
- LiteLLM as the default generator giving you **instant access to a huge array of models**.
- Define prompts as python functions with **type hints and docstrings**.
- Simple **tool use**, even for models which don't support them at the API.
- Store different models and configs as **simple connection strings** just like databases.
- Integrated tracing support with [Logfire](https://logfire.pydantic.dev/docs/).
- Chat templating, forking, continuations, generation parameter overloads, stripping segments, etc.
- Async batching and fast iterations for **large scale generation**.
- Metadata, callbacks, and data format conversions.
- Modern python with type hints, async support, pydantic validation, serialization, etc.

```py
import rigging as rg

@rg.prompt(generator_id="gpt-4")
async def get_authors(count: int = 3) -> list[str]:
    """Provide famous authors."""

print(await get_authors())

# ['William Shakespeare', 'J.K. Rowling', 'Jane Austen']
```

Rigging is built by [**dreadnode**](https://dreadnode.io) where we use it daily.

## Installation

We publish every version to Pypi:
```bash
pip install rigging
```

If you want to build from source:
```bash
cd rigging/
poetry install
```

## Supported LLMs

Rigging will run just about any language model:

- Any model from [**LiteLLM**](https://litellm.vercel.app/docs/providers)
- Any model from [**vLLM**](https://docs.vllm.ai/en/latest/models/supported_models.html)
- Any model from [**transformers**](https://huggingface.co/docs/transformers/)

### API Keys

Pass the `api_key` in an generator id or use standard environment variables.

```py
rg.get_generator("gpt-4-turbo,api_key=...")
```

```bash
export OPENAI_API_KEY=...
export MISTRAL_API_KEY=...
export ANTHROPIC_API_KEY=...
...
```

Check out [the docs](https://docs.dreadnode.io/open-source/rigging/topics/generators#api-keys) for more.

## Getting Started

**Check out the guide [in the docs](https://docs.dreadnode.io/open-source/rigging/intro#getting-started)**

1. **Get a generator** using a connection string.
2. Build a **chat** or **completion** pipeline
3. **Run** the pipeline and get the output.

```py
import rigging as rg
import asyncio

async def main():
    # 1 - Get a generator
    generator = rg.get_generator("claude-3-sonnet-20240229")

    # 2 - Build a chat pipeline
    pipeline = generator.chat(
        [
            {"role": "system", "content": "Talk like a pirate."},
            {"role": "user", "content": "Say hello!"},
        ]
    )

    # 3 - Run the pipeline
    chat = await pipeline.run()
    print(chat.conversation)

# Run the main function
asyncio.run(main())

# [system]: Talk like a pirate.
# [user]: Say hello!
# [assistant]: Ahoy, matey! Here be the salty sea dog ready to trade greetings wit' ye. Arrr!
```

Want more?

- Use [structured pydantic parsing](https://docs.dreadnode.io/open-source/rigging/topics/chats-and-messages#parsed-parts)
- Check out [raw completions](https://docs.dreadnode.io/open-source/rigging/topics/completions/)
- Give the LLM [access to tools](https://docs.dreadnode.io/open-source/rigging/topics/tools/)
- Track behavior with [tracing](https://docs.dreadnode.io/open-source/rigging/topics/tracing/)
- Play with [generation params](https://docs.dreadnode.io/open-source/rigging/topics/generators/#overload-generation-params)
- Use [callbacks in the pipeline](https://docs.dreadnode.io/open-source/rigging/topics/callbacks-and-mapping/)
- Scale up with [iterating and batching](https://docs.dreadnode.io/open-source/rigging/topics/iterating-and-batching/)
- Save your work with [serialization](https://docs.dreadnode.io/open-source/rigging/topics/serialization/)

## Examples

- Basic interactive chat: [**chat.py**](examples/chat.py)
- Jupyter code interpreter: [**jupyter.py**](examples/jupyter.py)
- OverTheWire Bandit Agent: [**bandit.py**](examples/bandit.py)
- Damn Vulnerable Restaurant Agent: [**dvra.py**](examples/dvra.py)
- RAG Pipeline: [**rag.py**](examples/rag.py) (from [kyleavery](https://github.com/kyleavery/))
- Integrating dreadnode-owned [robopages](https://github.com/dreadnode/robopages-cli) as a tool server (basic nmap scan example): [**rigging_example.py**](https://github.com/dreadnode/robopages-cli/blob/main/examples/rigging_example.py)

## Documentation

**[docs.dreadnode.io](https://docs.dreadnode.io/open-source/rigging/intro)** has everything you need.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=dreadnode/rigging&type=Date)](https://star-history.com/#dreadnode/rigging&Date)

