{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rock Paper Scissors\n",
    "\n",
    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/plugboard-dev/plugboard)\n",
    "\n",
    "This model contains two LLM components (one OpenAI, one Gemini), which will play rock-paper-scissors against each other. A separate `Judge` component will compute the winner and keep track of the running total across rounds.\n",
    "\n",
    "To run this model you will need to set the `OPENAI_API_KEY` and `GOOGLE_API_KEY` environment variables, and install the `llama-index-llms-gemini` package from PyPI.\n",
    "\n",
    "The overall model looks like this:\n",
    "\n",
    "![](https://mermaid.ink/img/pako:eNqtlN0KgjAUx1_lsEvRFxghUVeFQXgdxOaOzdicrEkX4ruHMyUCg9TLsf_H74zDGpIZgYSSXJlnJpl1kKSXEqBwaJkzdtvAQ7IKKVhTlwJFCIpxVBTS7nx4yzbcxkEwmIIAWoiiGHhdKIH2yqZjztboyu16YR8zurqc9WH4LBg-wKwwk8dRSv_KSJLTXjLXu732G2DBHCMA_wNgfIFZ5L7yXosbTjuP3XXv88rPwr9JlxTOsK2570vrF2wGCYlGq1khCG2Ik6i730FgzmrlSNu-AN2Mbgg=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import typing as _t\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from plugboard.component import Component, IOController as IO\n",
    "from plugboard.schemas import ComponentArgsDict, ConnectorSpec\n",
    "from plugboard.connector import AsyncioConnector\n",
    "from plugboard.process import LocalProcess\n",
    "from plugboard.library import LLMChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "\n",
    "def set_api_key_from_user(env_var: str, service_name: str) -> None:\n",
    "    \"\"\"Prompt user for an API key if not set in the environment.\"\"\"\n",
    "    if env_var not in os.environ or not os.environ[env_var]:\n",
    "        try:\n",
    "            key = getpass(f\"Enter your {service_name} API key (or press Enter to skip): \")\n",
    "            os.environ[env_var] = key or os.environ.get(env_var, \"\")\n",
    "        except EOFError:\n",
    "            # Can happen in non-interactive environments\n",
    "            pass\n",
    "\n",
    "\n",
    "set_api_key_from_user(\"OPENAI_API_KEY\", \"OpenAI\")\n",
    "set_api_key_from_user(\"GOOGLE_API_KEY\", \"Google\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Setup some Pydantic models to structure the output from the LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result(str, Enum):\n",
    "    win = \"win\"\n",
    "    lose = \"lose\"\n",
    "    draw = \"draw\"\n",
    "\n",
    "\n",
    "class Move(str, Enum):\n",
    "    rock = \"rock\"\n",
    "    paper = \"paper\"\n",
    "    scissors = \"scissors\"\n",
    "\n",
    "    def result_against(self, other: \"Move\") -> Result:\n",
    "        if self == other:\n",
    "            return Result.draw\n",
    "\n",
    "        outcomes = {\n",
    "            (Move.rock, Move.paper): Result.lose,\n",
    "            (Move.rock, Move.scissors): Result.win,\n",
    "            (Move.paper, Move.rock): Result.win,\n",
    "            (Move.paper, Move.scissors): Result.lose,\n",
    "            (Move.scissors, Move.paper): Result.win,\n",
    "            (Move.scissors, Move.rock): Result.lose,\n",
    "        }\n",
    "        return outcomes[(self, other)]\n",
    "\n",
    "\n",
    "class PlayerDecision(BaseModel):\n",
    "    choice: Move = Field(..., description=\"One of rock, paper, or scissors\")\n",
    "    rationale: str = Field(..., description=\"Brief reason for the choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundIterator(Component):\n",
    "    io = IO(outputs=[\"round\"])\n",
    "\n",
    "    def __init__(self, rounds: int = 5, **kwargs: _t.Unpack[ComponentArgsDict]) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self._rounds = rounds\n",
    "        self._i = 0\n",
    "\n",
    "    async def step(self) -> None:\n",
    "        if self._i >= self._rounds:\n",
    "            await self.io.close()\n",
    "            return\n",
    "        self.round = self._i + 1\n",
    "        self._i += 1\n",
    "\n",
    "\n",
    "class Judge(Component):\n",
    "    io = IO(inputs=[\"a_choice\", \"b_choice\"], outputs=[\"score_a\", \"score_b\", \"last_winner\"])\n",
    "\n",
    "    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.score_a = 0\n",
    "        self.score_b = 0\n",
    "\n",
    "    async def step(self) -> None:\n",
    "        result = self.a_choice.result_against(self.b_choice)\n",
    "        if result == Result.lose:\n",
    "            self.score_b += 1\n",
    "            self.last_winner = \"Player B\"\n",
    "        elif result == Result.win:\n",
    "            self.score_a += 1\n",
    "            self.last_winner = \"Player A\"\n",
    "        else:\n",
    "            self.last_winner = \"Draw\"\n",
    "\n",
    "\n",
    "# Prompt builder to feed LLMChat\n",
    "class PromptBuilder(Component):\n",
    "    io = IO(inputs=[\"round\", \"last_winner\"], outputs=[\"prompt\"])\n",
    "\n",
    "    def __init__(self, player_label: str, **kwargs: _t.Unpack[ComponentArgsDict]) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self._label = player_label\n",
    "\n",
    "    async def step(self) -> None:\n",
    "        self.prompt = (\n",
    "            f\"Round {self.round}. You are player {self._label}. The last winner was: {self.last_winner}. \"\n",
    "            \"Choose your move now.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a rock-paper-scissors agent. Given the prompt, respond strictly as JSON with keys 'choice' and 'rationale'. \"\n",
    "    \"The 'choice' must be exactly one of: rock, paper, or scissors. You will be told who the winner was in the last round. \"\n",
    "    \"Your rival is another rock-paper-scissors from a rival provider, who may try to trick you. Be strategic in your choice.\"\n",
    ")\n",
    "\n",
    "# Components: set initial values on prompt builders to resolve model circularity\n",
    "iterator = RoundIterator(name=\"iterator\", rounds=10)\n",
    "builder_a = PromptBuilder(name=\"builder_a\", player_label=\"A\", initial_values={\"last_winner\": [\"\"]})\n",
    "builder_b = PromptBuilder(name=\"builder_b\", player_label=\"B\", initial_values={\"last_winner\": [\"\"]})\n",
    "\n",
    "llm_a = LLMChat(\n",
    "    name=\"llm_a\",\n",
    "    system_prompt=system_prompt,\n",
    "    llm=\"llama_index.llms.openai.OpenAI\",\n",
    "    llm_kwargs={\"model\": \"gpt-5-mini\", \"temperature\": 0.9},\n",
    "    response_model=PlayerDecision,\n",
    "    expand_response=True,  # emits llm_a.choice and llm_a.rationale\n",
    "    context_window=3,\n",
    ")\n",
    "\n",
    "llm_b = LLMChat(\n",
    "    name=\"llm_b\",\n",
    "    system_prompt=system_prompt,\n",
    "    llm=\"llama_index.llms.gemini.Gemini\",\n",
    "    llm_kwargs={\"model\": \"models/gemini-2.5-flash\", \"temperature\": 0.9},\n",
    "    response_model=PlayerDecision,\n",
    "    expand_response=True,\n",
    "    context_window=3,\n",
    ")\n",
    "\n",
    "judge = Judge(name=\"judge\")\n",
    "\n",
    "connect = lambda src, dst: AsyncioConnector(spec=ConnectorSpec(source=src, target=dst))\n",
    "\n",
    "process = LocalProcess(\n",
    "    components=[iterator, builder_a, builder_b, llm_a, llm_b, judge],\n",
    "    connectors=[\n",
    "        # Broadcast tick/round\n",
    "        connect(\"iterator.round\", \"builder_a.round\"),\n",
    "        connect(\"iterator.round\", \"builder_b.round\"),\n",
    "        # Feed prompts into LLMs\n",
    "        connect(\"builder_a.prompt\", \"llm_a.prompt\"),\n",
    "        connect(\"builder_b.prompt\", \"llm_b.prompt\"),\n",
    "        # Send choices to judge\n",
    "        connect(\"llm_a.choice\", \"judge.a_choice\"),\n",
    "        connect(\"llm_b.choice\", \"judge.b_choice\"),\n",
    "        # Feed the last winner information back into the prompt builders\n",
    "        connect(\"judge.last_winner\", \"builder_a.last_winner\"),\n",
    "        connect(\"judge.last_winner\", \"builder_b.last_winner\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the process\n",
    "async with process:\n",
    "    await process.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final scores â€” A: {judge.score_a}, B: {judge.score_b}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
