# DO NOT EDIT THIS FILE: these stubs have been autogenerated

# Polars Version: 1.34.0
from __future__ import annotations

from typing import TYPE_CHECKING, Any, Callable, TypeVar
import polars as pl
from paguro.models.vfm import VFrameModel, VFM
from collections.abc import Iterator
from typing import TYPE_CHECKING, Any, Callable, TypeVar
from polars.lazyframe.opt_flags import DEFAULT_QUERY_OPT_FLAGS
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import sys
    from collections.abc import Iterable, Mapping, Sequence
    from pathlib import Path


    from polars import DataFrame, LazyFrame
    from polars._typing import (
        IntoExpr,
        MaintainOrderJoin,
    )

    from paguro.dataset.dataset import Dataset

    if sys.version_info >= (3, 11):
        from typing import Self
    else:
        from typing_extensions import Self
if TYPE_CHECKING:
    from polars.schema import Schema
    from polars._dependencies import polars_cloud as pc
    from polars._utils.async_ import _GeventDataFrameResult
    from pathlib import Path
    from collections.abc import Collection, Iterable, Mapping
    import polars._reexport as pl
    import contextlib
    import sys
    from collections.abc import Awaitable, Iterator, Sequence
    from typing import Literal

    from polars.lazyframe.opt_flags import QueryOptFlags

    with contextlib.suppress(ImportError):  # Module not available when building docs
        pass

    with contextlib.suppress(ImportError):  # Module not available when building docs
        pass

    from polars import DataFrame, Expr
    from polars._dependencies import numpy as np
    from polars._typing import (
        ColumnNameOrSelector,
        EngineType,
        ExplainFormat,
        FillNullStrategy,
        IntoExpr,
        IntoExprColumn,
        MaintainOrderJoin,
        PlanStage,
        PolarsDataType,
        PythonDataType,
        QuantileMethod,
        SchemaDict,
        UniqueKeepStrategy,
    )

    if sys.version_info >= (3, 10):
        from typing import Concatenate, ParamSpec
    else:
        from typing_extensions import Concatenate, ParamSpec

    if sys.version_info >= (3, 11):
        from typing import Self
    else:
        from typing_extensions import Self

    if sys.version_info >= (3, 13):
        pass
    else:
        pass  # noqa: TC004

    T = TypeVar("T")
    P = ParamSpec("P")
if TYPE_CHECKING:
    from polars import LazyFrame

    import sys

    if sys.version_info >= (3, 11):
        from typing import Self
    else:
        from typing_extensions import Self
if TYPE_CHECKING:

    from paguro import Dataset, LazyDataset


    import sys

    if sys.version_info >= (3, 11):
        from typing import Self
    else:
        from typing_extensions import Self

U = TypeVar("U", bound=VFrameModel)

class _LazyDatasetMixin:
    """Stub class for _LazyDatasetMixin."""

    def _getattr(self, attr) -> Any:
         raise NotImplementedError

    def approx_n_unique(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("approx_n_unique")()

    def bottom_k(self, k: int, *, by: IntoExpr | Iterable[IntoExpr], reverse: bool | Sequence[bool] = False) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("bottom_k")(k, by=by, reverse=reverse)

    def cache(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("cache")()

    def cast(self, dtypes: Mapping[ColumnNameOrSelector | PolarsDataType, PolarsDataType | PythonDataType] | PolarsDataType | pl.DataTypeExpr, *, strict: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("cast")(dtypes, strict=strict)

    def clear(self, n: int = 0) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("clear")(n=n)

    def clone(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("clone")()

    def collect(self, **kwargs: Any) -> dict[str, Dataset[VFM]]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("collect")(**kwargs)

    def collect_async(self, *, gevent: bool = False, engine: EngineType = 'auto', optimizations: QueryOptFlags = DEFAULT_QUERY_OPT_FLAGS) -> dict[str, Awaitable[DataFrame] | _GeventDataFrameResult[DataFrame]]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("collect_async")(gevent=gevent, engine=engine, optimizations=optimizations)

    def collect_batches(self, *, chunk_size: int | None = None, maintain_order: bool = True, lazy: bool = False, engine: EngineType = 'auto', optimizations: QueryOptFlags = DEFAULT_QUERY_OPT_FLAGS) -> dict[str, Iterator[DataFrame]]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("collect_batches")(chunk_size=chunk_size, maintain_order=maintain_order, lazy=lazy, engine=engine, optimizations=optimizations)

    def collect_model_blueprint(self, path: str | Path | None = None, *, name: str | None = 'DatasetModel', dtypes: bool | Literal['as_values'] = False, allow_nulls: bool | None = None) -> dict[str, str]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("collect_model_blueprint")(path, name=name, dtypes=dtypes, allow_nulls=allow_nulls)

    def collect_schema(self) -> dict[str, Schema]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("collect_schema")()

    @property
    def columns(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("columns")

    def count(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("count")()

    def describe(self, percentiles: Sequence[float] | float | None = (0.25, 0.5, 0.75), *, interpolation: QuantileMethod = 'nearest') -> dict[str, DataFrame]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("describe")(percentiles, interpolation=interpolation)

    def drop(self, *columns: ColumnNameOrSelector | Iterable[ColumnNameOrSelector], strict: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("drop")(*columns, strict=strict)

    def drop_nans(self, subset: ColumnNameOrSelector | Collection[ColumnNameOrSelector] | None = None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("drop_nans")(subset=subset)

    def drop_nulls(self, subset: ColumnNameOrSelector | Collection[ColumnNameOrSelector] | None = None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("drop_nulls")(subset=subset)

    @property
    def dtypes(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("dtypes")

    def explain(self, *, format: ExplainFormat = 'plain', optimized: bool = True, type_coercion: bool = True, predicate_pushdown: bool = True, projection_pushdown: bool = True, simplify_expression: bool = True, slice_pushdown: bool = True, comm_subplan_elim: bool = True, comm_subexpr_elim: bool = True, cluster_with_columns: bool = True, collapse_joins: bool = True, streaming: bool = False, engine: EngineType = 'auto', tree_format: bool | None = None, optimizations: QueryOptFlags = DEFAULT_QUERY_OPT_FLAGS) -> dict[str, str]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("explain")(format=format, optimized=optimized, type_coercion=type_coercion, predicate_pushdown=predicate_pushdown, projection_pushdown=projection_pushdown, simplify_expression=simplify_expression, slice_pushdown=slice_pushdown, comm_subplan_elim=comm_subplan_elim, comm_subexpr_elim=comm_subexpr_elim, cluster_with_columns=cluster_with_columns, collapse_joins=collapse_joins, streaming=streaming, engine=engine, tree_format=tree_format, optimizations=optimizations)

    def explode(self, columns: ColumnNameOrSelector | Iterable[ColumnNameOrSelector], *more_columns: ColumnNameOrSelector) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("explode")(columns, *more_columns)

    def fetch(self, n_rows: int = 500, **kwargs: Any) -> dict[str, DataFrame]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("fetch")(n_rows=n_rows, **kwargs)

    def fill_nan(self, value: int | float | Expr | None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("fill_nan")(value=value)

    def fill_null(self, value: Any | Expr | None = None, strategy: FillNullStrategy | None = None, limit: int | None = None, *, matches_supertype: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("fill_null")(value, strategy, limit, matches_supertype=matches_supertype)

    def filter(self, *predicates: IntoExprColumn | Iterable[IntoExprColumn] | bool | list[bool] | np.ndarray[Any, Any], **constraints: Any) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("filter")(*predicates, **constraints)

    def first(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("first")()

    def gather_every(self, n: int, offset: int = 0) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("gather_every")(n=n, offset=offset)

    def head(self, n: int = 5) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("head")(n=n)

    def inspect(self, fmt: str = '{}') -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("inspect")(fmt=fmt)

    def interpolate(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("interpolate")()

    def last(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("last")()

    def limit(self, n: int = 5) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("limit")(n=n)

    def map_batches(self, function: Callable[[DataFrame], DataFrame], *, predicate_pushdown: bool = True, projection_pushdown: bool = True, slice_pushdown: bool = True, no_optimizations: bool = False, schema: None | SchemaDict = None, validate_output_schema: bool = True, streamable: bool = False) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("map_batches")(function, predicate_pushdown=predicate_pushdown, projection_pushdown=projection_pushdown, slice_pushdown=slice_pushdown, no_optimizations=no_optimizations, schema=schema, validate_output_schema=validate_output_schema, streamable=streamable)

    def match_to_schema(self, schema: SchemaDict | Schema, *, missing_columns: Literal['insert', 'raise'] | Mapping[str, Literal['insert', 'raise'] | Expr] = 'raise', missing_struct_fields: Literal['insert', 'raise'] | Mapping[str, Literal['insert', 'raise']] = 'raise', extra_columns: Literal['ignore', 'raise'] = 'raise', extra_struct_fields: Literal['ignore', 'raise'] | Mapping[str, Literal['ignore', 'raise']] = 'raise', integer_cast: Literal['upcast', 'forbid'] | Mapping[str, Literal['upcast', 'forbid']] = 'forbid', float_cast: Literal['upcast', 'forbid'] | Mapping[str, Literal['upcast', 'forbid']] = 'forbid') -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("match_to_schema")(schema, missing_columns=missing_columns, missing_struct_fields=missing_struct_fields, extra_columns=extra_columns, extra_struct_fields=extra_struct_fields, integer_cast=integer_cast, float_cast=float_cast)

    def max(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("max")()

    def mean(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("mean")()

    def median(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("median")()

    def melt(self, id_vars: ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None = None, value_vars: ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None = None, variable_name: str | None = None, value_name: str | None = None, *, streamable: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("melt")(id_vars, value_vars, variable_name, value_name, streamable=streamable)

    def merge_sorted(self, other: LazyDataset[U] | pl.LazyFrame, key: str) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("merge_sorted")(other=other, key=key)

    def min(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("min")()

    @property
    def model(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("model")

    def null_count(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("null_count")()

    def pipe(self, function: Callable[Concatenate[LazyFrame, P], T], *args: P.args, **kwargs: P.kwargs) -> dict[str, T]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("pipe")(function, *args, **kwargs)

    def pipe_with_schema(self, function: Callable[[LazyFrame, Schema], LazyFrame]) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("pipe_with_schema")(function=function)

    def profile(self, *, type_coercion: bool = True, predicate_pushdown: bool = True, projection_pushdown: bool = True, simplify_expression: bool = True, no_optimization: bool = False, slice_pushdown: bool = True, comm_subplan_elim: bool = True, comm_subexpr_elim: bool = True, cluster_with_columns: bool = True, collapse_joins: bool = True, show_plot: bool = False, truncate_nodes: int = 0, figsize: tuple[int, int] = (18, 8), engine: EngineType = 'auto', optimizations: QueryOptFlags = DEFAULT_QUERY_OPT_FLAGS, **_kwargs: Any) -> dict[str, tuple[DataFrame, DataFrame]]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("profile")(type_coercion=type_coercion, predicate_pushdown=predicate_pushdown, projection_pushdown=projection_pushdown, simplify_expression=simplify_expression, no_optimization=no_optimization, slice_pushdown=slice_pushdown, comm_subplan_elim=comm_subplan_elim, comm_subexpr_elim=comm_subexpr_elim, cluster_with_columns=cluster_with_columns, collapse_joins=collapse_joins, show_plot=show_plot, truncate_nodes=truncate_nodes, figsize=figsize, engine=engine, optimizations=optimizations, **_kwargs)

    def quantile(self, quantile: float | Expr, interpolation: QuantileMethod = 'nearest') -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("quantile")(quantile=quantile, interpolation=interpolation)

    def remote(self, context: pc.ComputeContext | None = None, plan_type: pc._typing.PlanTypePreference = 'dot') -> dict[str, pc.LazyFrameRemote]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("remote")(context=context, plan_type=plan_type)

    def remove(self, *predicates: IntoExprColumn | Iterable[IntoExprColumn] | bool | list[bool] | np.ndarray[Any, Any], **constraints: Any) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("remove")(*predicates, **constraints)

    def rename(self, mapping: Mapping[str, str] | Callable[[str], str], *, strict: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("rename")(mapping, strict=strict)

    def reverse(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("reverse")()

    @property
    def schema(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("schema")

    def select(self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("select")(*exprs, **named_exprs)

    def select_seq(self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("select_seq")(*exprs, **named_exprs)

    def set_sorted(self, column: str, *, descending: bool = False) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("set_sorted")(column, descending=descending)

    def shift(self, n: int | IntoExprColumn = 1, *, fill_value: IntoExpr | None = None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("shift")(n, fill_value=fill_value)

    def show_graph(self, *, optimized: bool = True, show: bool = True, output_path: str | Path | None = None, raw_output: bool = False, figsize: tuple[float, float] = (16.0, 12.0), type_coercion: bool = True, _type_check: bool = True, predicate_pushdown: bool = True, projection_pushdown: bool = True, simplify_expression: bool = True, slice_pushdown: bool = True, comm_subplan_elim: bool = True, comm_subexpr_elim: bool = True, cluster_with_columns: bool = True, collapse_joins: bool = True, engine: EngineType = 'auto', plan_stage: PlanStage = 'ir', _check_order: bool = True, optimizations: QueryOptFlags = DEFAULT_QUERY_OPT_FLAGS) -> dict[str, str | None]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("show_graph")(optimized=optimized, show=show, output_path=output_path, raw_output=raw_output, figsize=figsize, type_coercion=type_coercion, _type_check=_type_check, predicate_pushdown=predicate_pushdown, projection_pushdown=projection_pushdown, simplify_expression=simplify_expression, slice_pushdown=slice_pushdown, comm_subplan_elim=comm_subplan_elim, comm_subexpr_elim=comm_subexpr_elim, cluster_with_columns=cluster_with_columns, collapse_joins=collapse_joins, engine=engine, plan_stage=plan_stage, _check_order=_check_order, optimizations=optimizations)

    def skim(self, config: list[tuple] | None = None, *, by: str | list[str] | None = None, hist: bool = False, unnest_structs: bool | ColumnNameOrSelector = False) -> dict[str, Collection]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("skim")(config, by=by, hist=hist, unnest_structs=unnest_structs)

    def slice(self, offset: int, length: int | None = None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("slice")(offset=offset, length=length)

    def sort(self, by: IntoExpr | Iterable[IntoExpr], *more_by: IntoExpr, descending: bool | Sequence[bool] = False, nulls_last: bool | Sequence[bool] = False, maintain_order: bool = False, multithreaded: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("sort")(by, *more_by, descending=descending, nulls_last=nulls_last, maintain_order=maintain_order, multithreaded=multithreaded)

    def sql(self, query: str, *, table_name: str = 'self') -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("sql")(query, table_name=table_name)

    def std(self, ddof: int = 1) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("std")(ddof=ddof)

    def sum(self) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("sum")()

    def tail(self, n: int = 5) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("tail")(n=n)

    def to_dataframe(self) -> dict[str, pl.DataFrame]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("to_dataframe")()

    def to_lazyframe(self) -> dict[str, pl.LazyFrame]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("to_lazyframe")()

    def to_polars(self) -> dict[str, pl.LazyFrame]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("to_polars")()

    def top_k(self, k: int, *, by: IntoExpr | Iterable[IntoExpr], reverse: bool | Sequence[bool] = False) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("top_k")(k, by=by, reverse=reverse)

    def unique(self, subset: ColumnNameOrSelector | Collection[ColumnNameOrSelector] | None = None, *, keep: UniqueKeepStrategy = 'any', maintain_order: bool = False) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("unique")(subset, keep=keep, maintain_order=maintain_order)

    def unnest(self, columns: ColumnNameOrSelector | Collection[ColumnNameOrSelector], *more_columns: ColumnNameOrSelector) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("unnest")(columns, *more_columns)

    def unpivot(self, on: ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None = None, *, index: ColumnNameOrSelector | Sequence[ColumnNameOrSelector] | None = None, variable_name: str | None = None, value_name: str | None = None, streamable: bool = True) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("unpivot")(on, index=index, variable_name=variable_name, value_name=value_name, streamable=streamable)

    def update(self, other: LazyFrame, on: str | Sequence[str] | None = None, how: Literal['left', 'inner', 'full'] = 'left', *, left_on: str | Sequence[str] | None = None, right_on: str | Sequence[str] | None = None, include_nulls: bool = False, maintain_order: MaintainOrderJoin | None = 'left') -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("update")(other, on, how, left_on=left_on, right_on=right_on, include_nulls=include_nulls, maintain_order=maintain_order)

    def var(self, ddof: int = 1) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("var")(ddof=ddof)

    @property
    def vcol(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("vcol")

    @property
    def width(self) -> dict[str, Any]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("width")

    def with_columns(self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_columns")(*exprs, **named_exprs)

    def with_columns_seq(self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_columns_seq")(*exprs, **named_exprs)

    def with_context(self, other: Self | list[Self]) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_context")(other=other)

    def with_name(self, name: str | None) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_name")(name=name)

    def with_row_count(self, name: str = 'row_nr', offset: int = 0) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_row_count")(name=name, offset=offset)

    def with_row_index(self, name: str = 'index', offset: int = 0) -> Self:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("with_row_index")(name=name, offset=offset)

    def without_model(self) -> dict[str, LazyDataset[Any]]:
        """


        Group
        -----
            Delegated
        """
        return self._getattr("without_model")()

    # ------- dunder methods ---------

    def __ge__(self, other: Any):
        """


        Group
        -----
            Delegated
        """
        return self._getattr("__ge__")(other=other)

    def __gt__(self, other: Any):
        """


        Group
        -----
            Delegated
        """
        return self._getattr("__gt__")(other=other)

    def __le__(self, other: Any):
        """


        Group
        -----
            Delegated
        """
        return self._getattr("__le__")(other=other)

    def __lt__(self, other: Any):
        """


        Group
        -----
            Delegated
        """
        return self._getattr("__lt__")(other=other)
