"""
This module defines a Feed class to represent GTFS feeds.

The Feed class also has heaps of methods: a method to compute route stats,
a method to compute screen line counts, validations methods, etc.
To ease testing and reading, almost all of these methods are defined in other modules
and grouped by theme (``routes.py``, ``stops.py``, etc.).
These methods, or rather functions that operate on feeds, are
then imported within the Feed class.
This separation of methods unfortunately messes up slightly the ``Feed`` class
documentation generated by Sphinx, introducing an extra leading ``feed``
parameter in the method signatures.
Ignore that extra parameter; it refers to the Feed instance,
usually called ``self`` and usually hidden automatically by Sphinx.
"""

from __future__ import annotations

import pathlib as pb
import shutil
import tempfile
import zipfile

import polars as pl
import requests

from . import cleaners as cn
from . import constants as cs
from . import helpers as hp


class Feed(object):
    """
    An instance of this class represents a GTFS feed,
    where GTFS tables are stored as Polars LazyFrame and are coerced to such upon
    initialization and attribute updates.
    The methods assume the instance represents a valid GTFS feed but offer no
    validation, because that's complex and already done by dedicated libraries.
    So unless you know what you're doing, use
    the `Canonical GTFS Validator <https://gtfs-validator.mobilitydata.org/>`_
    before seriously analyzing a feed with this class.

    GTFS table instance attributes:

    - ``agency``
    - ``stops``
    - ``routes``
    - ``trips``
    - ``stop_times``
    - ``calendar``
    - ``calendar_dates``
    - ``fare_attributes``
    - ``fare_rules``
    - ``shapes``
    - ``frequencies``
    - ``transfers``
    - ``feed_info``
    - ``attributions``

    Metadata attributes:

    - ``dist_units``: a string in :const:`.constants.DIST_UNITS`;
      specifies the distance units of the `shape_dist_traveled` column values,
      if present; also effects whether to display trip and route stats in
      metric or imperial units
    - ``unzip_dir``: temporary file directory for unzipping feeds read from ZIP file

    """

    # Import heaps of methods from modules split by functionality, a trick taken from
    # https://groups.google.com/d/msg/comp.lang.python/goLBrqcozNY/DPgyaZ6gAwAJ
    from .calendar import get_dates, get_first_week, get_week, subset_dates
    from .cleaners import (
        aggregate_routes,
        aggregate_stops,
        clean,
        clean_ids,
        clean_route_short_names,
        clean_times,
        drop_invalid_columns,
        drop_zombies,
        extend_id,
    )
    from .miscellany import (
        assess_quality,
        compute_bounds,
        compute_centroid,
        compute_convex_hull,
        compute_network_stats,
        compute_network_time_series,
        compute_screen_line_counts,
        convert_dist,
        create_shapes,
        describe,
        list_fields,
        restrict_to_agencies,
        restrict_to_area,
        restrict_to_dates,
        restrict_to_routes,
        restrict_to_trips,
    )
    from .routes import (
        build_route_timetable,
        compute_route_stats,
        compute_route_time_series,
        get_routes,
        map_routes,
        routes_to_geojson,
    )
    from .shapes import (
        append_dist_to_shapes,
        build_geometry_by_shape,
        geometrize_shapes,
        get_shapes,
        get_shapes_intersecting_geometry,
        shapes_to_geojson,
        split_simple,
    )
    from .stop_times import (
        append_dist_to_stop_times,
        get_start_and_end_times,
        get_stop_times,
        stop_times_to_geojson,
    )
    from .stops import (
        build_geometry_by_stop,
        build_stop_timetable,
        compute_stop_activity,
        compute_stop_stats,
        compute_stop_time_series,
        geometrize_stops,
        get_stops,
        get_stops_in_area,
        map_stops,
        stops_to_geojson,
        ungeometrize_stops,
    )
    from .trips import (
        compute_busiest_date,
        compute_trip_activity,
        compute_trip_stats,
        get_active_services,
        get_trips,
        locate_trips,
        map_trips,
        name_stop_patterns,
        trips_to_geojson,
    )

    def __init__(
        self,
        dist_units: str,
        agency: pl.DataFrame | pl.LazyFrame | None = None,
        stops: pl.DataFrame | pl.LazyFrame | None = None,
        routes: pl.DataFrame | pl.LazyFrame | None = None,
        trips: pl.DataFrame | pl.LazyFrame | None = None,
        stop_times: pl.DataFrame | pl.LazyFrame | None = None,
        calendar: pl.DataFrame | pl.LazyFrame | None = None,
        calendar_dates: pl.DataFrame | pl.LazyFrame | None = None,
        fare_attributes: pl.DataFrame | pl.LazyFrame | None = None,
        fare_rules: pl.DataFrame | pl.LazyFrame | None = None,
        shapes: pl.DataFrame | pl.LazyFrame | None = None,
        frequencies: pl.DataFrame | pl.LazyFrame | None = None,
        transfers: pl.DataFrame | pl.LazyFrame | None = None,
        feed_info: pl.DataFrame | pl.LazyFrame | None = None,
        attributions: pl.DataFrame | pl.LazyFrame | None = None,
        unzip_dir: tempfile.TemporaryDirectory | None = None,
    ):
        """
        Upon initialization and later attribute updates,
        check that ``dist_units`` lies in :const:`.constants.DIST_UNITS`,
        and coerce every non-None table to a LazyFrame.

        No other format checking is performed.
        In particular, a Feed instance need not represent a valid GTFS
        feed.
        """
        # Set attributes from inputs.
        # The @property magic below will handle updates to ``dist_units``, and
        # __setattr__ will handle updates to tables.
        for prop, val in locals().items():
            if prop in cs.FEED_ATTRS:
                setattr(self, prop, val)

    def __setattr__(
        self: "Feed", name: str, value: pl.DataFrame | pl.LazyFrame
    ) -> None:
        """
        Coerce GTFS tables to LazyFrames.
        """
        if (
            name in cs.FEED_ATTRS
            and name not in {"dist_units", "unzip_dir"}
            and value is not None
        ):
            value = hp.make_lazy(value)

        super().__setattr__(name, value)

    @property
    def dist_units(self: "Feed") -> str:
        """
        The distance units of the Feed.
        """
        return self._dist_units

    @dist_units.setter
    def dist_units(self: "Feed", val: str) -> None:
        if val not in cs.DIST_UNITS:
            raise ValueError(
                f"Distance units are required and must lie in {cs.DIST_UNITS}"
            )
        else:
            self._dist_units = val

    def __str__(self: "Feed") -> str:
        """
        Print the first five rows of each GTFS table.
        """
        d = {}
        for table in cs.DTYPES:
            t = getattr(self, table)
            if t is not None:
                t = t.limit(5).collect()
            d[table] = t
        d["dist_units"] = self.dist_units

        return "\n".join([f"* {k} --------------------\n\t{v}" for k, v in d.items()])

    def __eq__(self: "Feed", other: "Feed") -> bool:
        """
        Define two feeds be equal if and only if their
        feed attributes, excluding ``unzip_dir``, are equal.
        Equality for Lazy/DateFrames is checked via :func:`.helpers.are_equal`,
        which canonically sorts table rows and columns.
        """
        if self is other:
            return True
        if not isinstance(other, Feed):
            return NotImplemented

        for key in set(cs.FEED_ATTRS) - {"unzip_dir"}:
            x = getattr(self, key)
            y = getattr(other, key)
            if isinstance(x, (pl.LazyFrame, pl.DataFrame)):
                if not hp.are_equal(x, y):
                    return False
            else:
                if x != y:
                    return False
        return True

    def copy(self: "Feed") -> "Feed":
        """
        Return a copy of this feed, that is, a feed with all the same
        attributes.
        """
        other = Feed(dist_units=self.dist_units, unzip_dir=self.unzip_dir)
        for key in set(cs.FEED_ATTRS) - {"unzip_dir", "dist_units"}:
            value = getattr(self, key)
            if isinstance(value, (pl.DataFrame, pl.LazyFrame)):
                value = hp.make_lazy(value.clone())
            setattr(other, key, value)
        return other

    def to_file(self: "Feed", path: pb.Path, ndigits: int | None = None) -> None:
        """
        Write this Feed to the given path.
        If the path ends in '.zip', then write the feed as a zip archive.
        Otherwise assume the path is a directory, and write the feed as a
        collection of CSV files to that directory, creating the directory
        if it does not exist.
        Round all decimals to ``ndigits`` decimal places, if given.
        All distances will be the distance units ``feed.dist_units``.
        By the way, 6 decimal degrees of latitude and longitude is enough to locate
        an individual cat.
        """
        path = pb.Path(path)

        if path.suffix == ".zip":
            # Write to temporary directory before zipping
            zipped = True
            tmp_dir = tempfile.TemporaryDirectory()
            new_path = pb.Path(tmp_dir.name)
        else:
            zipped = False
            if not path.exists():
                path.mkdir(parents=True, exist_ok=True)
            new_path = path

        for table in cs.DTYPES:
            f = getattr(self, table)
            if f is not None:
                p = new_path / (table + ".txt")

                # Materialize LazyFrame
                if isinstance(f, pl.LazyFrame):
                    f = f.collect()

                if ndigits is not None:
                    f.write_csv(p, float_precision=ndigits)
                else:
                    f.write_csv(p)

        # Zip directory
        if zipped:
            basename = str(path.parent / path.stem)
            shutil.make_archive(basename, format="zip", root_dir=tmp_dir.name)
            tmp_dir.cleanup()

    def close_unzip_dir(self: "Feed") -> None:
        """
        Close this Feed's temporary unzip directory, if it has one,
        which was created by reading the feed from a ZIP file.
        Frees memory.
        """
        if self.unzip_dir is not None:
            self.unzip_dir.cleanup()
            self.unzip_dir = None


# -------------------------------------
# Functions about input and output
# -------------------------------------
def list_feed(path: pb.Path) -> pl.DataFrame:
    """
    Given a path (string or Path object) to a GTFS zip file or
    directory, record the file names and file sizes of the contents,
    and return the result in a table with the columns:

    - ``'file_name'``
    - ``'file_size'``
    """
    path = pb.Path(path)
    if not path.exists():
        raise ValueError(f"Path {path} does not exist")

    rows = []
    if path.is_file():
        # Zip file
        with zipfile.ZipFile(str(path)) as src:
            for x in src.infolist():
                if x.filename == "./":
                    continue
                rows.append({"file_name": x.filename, "file_size": x.file_size})
    else:
        # Directory
        for x in path.iterdir():
            if x.is_file():
                rows.append({"file_name": x.name, "file_size": x.stat().st_size})

    return pl.LazyFrame(rows)


def _read_feed_from_path(path: pb.Path, dist_units: str) -> "Feed":
    """
    Helper function for :func:`read_feed`.
    Create a Feed instance from the given path and given distance units.
    The path should be a directory containing GTFS text files or a
    zip file that unzips as a collection of GTFS text files
    (and not as a directory containing GTFS text files).
    The distance units given must lie in :const:`constants.dist_units`

    Notes:

    - Ignore non-GTFS files in the feed
    - Automatically strip whitespace from the column names in GTFS files
    """
    path = pb.Path(path)
    if not path.exists():
        raise ValueError(f"Path {path} does not exist")

    # Read files into feed dictionary of tables
    feed_dict = {table: None for table in cs.DTYPES} | {"unzip_dir": None}

    # Unzip path to temporary directory if necessary
    if path.is_file():
        unzip_dir = tempfile.TemporaryDirectory()
        src_path = pb.Path(unzip_dir.name)
        shutil.unpack_archive(str(path), unzip_dir.name, "zip")
        feed_dict["unzip_dir"] = unzip_dir
    else:
        src_path = path

    for p in src_path.iterdir():
        table = p.stem
        # Skip empty files, irrelevant files, and files with no data
        if (
            p.is_file()
            and p.stat().st_size
            and p.suffix == ".txt"
            and table in feed_dict
        ):
            f = pl.scan_csv(
                p,
                schema_overrides=cs.DTYPES[table],
                encoding="utf8-lossy",
                null_values=["", " ", "nan", "NaN", "null"],
                ignore_errors=True,
            )
            if not hp.is_empty(f):
                feed_dict[table] = cn.clean_column_names(f)
            feed_dict[table] = f

    feed_dict["dist_units"] = dist_units

    return Feed(**feed_dict)


def _read_feed_from_url(url: str, dist_units: str) -> "Feed":
    """
    Helper function for :func:`read_feed`.
    Create a Feed instance from the given URL and given distance units.
    Assume the URL is valid and let the Requests library raise any errors.

    Notes:

    - Ignore non-GTFS files in the feed
    - Automatically strip whitespace from the column names in GTFS files


    """
    f = tempfile.NamedTemporaryFile(delete=False)
    with requests.get(url) as r:
        f.write(r.content)
    f.close()
    feed = _read_feed_from_path(pb.Path(f.name), dist_units=dist_units)
    pb.Path(f.name).unlink(missing_ok=True)
    return feed


def read_feed(path_or_url: pb.Path | str, dist_units: str) -> "Feed":
    """
    Create a Feed instance from the given path or URL and given distance units.
    If the path exists, then call :func:`_read_feed_from_path`.
    Else if the URL has OK status according to Requests, then call
    :func:`_read_feed_from_url`.
    Else raise a ValueError.

    Notes:

    - Ignore non-GTFS files in the feed
    - Automatically strip whitespace from the column names in GTFS files

    """
    try:
        path_exists = pb.Path(path_or_url).exists()
    except OSError:
        path_exists = False
    if path_exists:
        return _read_feed_from_path(pb.Path(path_or_url), dist_units=dist_units)
    elif requests.head(path_or_url).ok:
        return _read_feed_from_url(str(path_or_url), dist_units=dist_units)
    else:
        raise ValueError("Path does not exist or URL has bad status.")
