# ğŸ§  Contextual Studio AI Agent

> **Composable Agent Framework built on top of ADK.**  
> A modular Python library for creating, orchestrating, and managing autonomous AI agents with structured reasoning, prompt engineering, and LLM pipelines.

---

## ğŸš€ Overview

`contextual-studio-ai-agent` is a **high-level agent framework** built on top of the **Agent Development Kit (ADK)**.  
It provides a flexible architecture for building **stateful, composable, and reactive agents** capable of multi-step reasoning and coordination with large language models (LLMs).

This library powers the **Contextual Studio AI Stack**, offering a clean and extensible interface for integrating **LLMs**, **prompt systems**, and **multi-agent orchestration**.

---

## ğŸ§© Key Features

- ğŸ§  **Unified ADK Agent API** â€” Build and run autonomous agents directly on ADK.
- ğŸ” **Composable Managers** â€” Coordinate multiple reasoning pipelines using `AdkManager` and `AdkSequentialManager`.
- ğŸ§¾ **Dynamic Prompt Layer** â€” Create reusable, testable prompt templates directly in Python or Markdown.
- âš™ï¸ **Factory Pattern for LLMs** â€” Centralized configuration of language models and connectors through `LLMFactory`.
- ğŸ§± **Extensible Modular Design** â€” Easily extend components, factories, and managers without altering the core code.
- ğŸ§© **Integration Ready** â€” Compatible with external RAG systems, retrievers, and custom LLM endpoints.

---

## ğŸ—ï¸ Project Structure

```

contextual/
â””â”€â”€ agent/
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ agents/ # Core agent implementations (ADK-based)
â”‚ â”‚ â”œâ”€â”€ base.py
â”‚ â”‚ â”œâ”€â”€ adk_agent.py
â”‚ â”‚ â”œâ”€â”€ adk_a_agent.py
â”‚ â”‚ â”œâ”€â”€ adk_b_agent.py
â”‚ â”‚ â””â”€â”€ adk_sequential_agent.py
â”‚ â””â”€â”€ prompts/ # Prompt templates, base classes, and test prompts
â”‚ â”œâ”€â”€ base.py
â”‚ â”œâ”€â”€ test_a_prompt.py
â”‚ â”œâ”€â”€ test_b_prompt.py
â”‚ â””â”€â”€ test_seq_prompt.py
â”‚
â”œâ”€â”€ factories/
â”‚ â””â”€â”€ llm_factory.py # Factory for building and configuring LLMs
â”‚
â”œâ”€â”€ managers/
â”‚ â”œâ”€â”€ base.py # Base manager class
â”‚ â”œâ”€â”€ adk_manager.py # ADK manager
â”‚ â””â”€â”€ adk_seq_manager.py # Sequential orchestration manager
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ content.py # Content and message models (Pydantic)
â”‚ â””â”€â”€ llm_model.py # LLM configuration and schema models
â”‚
â””â”€â”€ utils/ # Utilities and shared helpers

```

This modular structure allows each layer â€” **components**, **factories**, **managers**, and **models** â€” to evolve independently while remaining tightly integrated.

---

## âš¡ Installation

Install from **TestPyPI** future in **PyPI**:

```bash
pip install -i https://test.pypi.org/simple/ contextual-studio-ai-agent
```

Once available on PyPI:

```bash
pip install contextual-studio-ai-agent
```

### Requirements

- Python â‰¥ 3.12
- Compatible with `uv`, `pip`, or `poetry`

---

## ğŸ§  Quick Start

### âœ³ï¸ Basic Agent Execution

```python
from contextual.agent.managers import AdkManager
from contextual.agent.factories import LLMFactory
from contextual.agent.components.agents import AdkAgent

# 1. Create an LLM factory
llm = LLMFactory.create("openai", model="gpt-4-turbo")

# 2. Initialize an ADK agent
agent = AdkAgent(llm=llm, name="contextual-agent")

# 3. Manage agent lifecycle
manager = AdkManager(agent)

# 4. Run a reasoning task
response = manager.run("Summarize the legal implications of AI-driven contracts.")
print(response)
```

---

### ğŸ” Sequential Orchestration

```python
from contextual.agent.managers import AdkSequentialManager
from contextual.agent.components.agents import AdkSequentialAgent

manager = AdkSequentialManager()
agent = AdkSequentialAgent()

result = manager.run(agent, "Draft and review a non-disclosure agreement.")
print(result)
```

---

### ğŸ§± Extending Prompts

```python
from contextual.agent.components.prompts import base

class LegalPrompt(base.BasePrompt):
    def render(self, case_facts: str) -> str:
        return f"Given the following case:\n{case_facts}\nExplain the key legal issues."

prompt = LegalPrompt()
print(prompt.render("An employee was terminated after an AI system error."))
```

---

## ğŸ§© Integration Example: RAG Pipelines

```python
from contextual.agent.factories import LLMFactory
from contextual.agent.managers import AdkManager

llm = LLMFactory.create("openai", model="gpt-4o")
manager = AdkManager.from_retriever("pinecone", llm)
```

---

## ğŸ§ª Testing

Tests follow standard `pytest` conventions and are located under `tests/`.

Run all tests with:

```bash
uv run pytest -v
```

---

## ğŸ§© Development Setup

```bash
# Clone the repository
git clone https://github.com/contextual-studio/agent.git
cd agent

# Sync dependencies
uv sync --dev

# Run tests
uv run pytest
```

---

## ğŸ§­ Roadmap

- [ ] Multi-agent orchestration with ADK sequential control
- [ ] Graph-based memory and state tracking
- [ ] RAG integration with contextual retrievers
- [ ] LangFuse analytics integration
- [ ] Async streaming for real-time reasoning

---

## ğŸ¤ Contributing

We welcome contributions!
Please follow [PEP 8](https://peps.python.org/pep-0008/) and [Conventional Commits](https://www.conventionalcommits.org/) standards.

Submit issues or pull requests via the [GitHub repository](https://github.com/contextual-studio/agent).

---

## ğŸ§¾ License

Licensed under the **MIT License**.
See [`LICENSE`](./LICENSE) for more information.

---

## ğŸŒ Project Links

- ğŸ  [Homepage](https://contextualstudio.com/)
- ğŸ“˜ [Documentation](https://github.com/contextual-studio/agent)
- ğŸ§© [Repository](https://github.com/contextual-studio/agent)
- ğŸ§ª [TestPyPI Package](https://test.pypi.org/project/contextual-studio-ai-agent/)
