# ğŸš€ Token Data Import Guide

å®Œæ•´çš„ä»£å¸æ•°æ®å¯¼å…¥æŒ‡å—ï¼ŒåŒ…æ‹¬éªŒè¯ã€å¯¼å…¥å’Œä½¿ç”¨è¯´æ˜ã€‚

---

## ğŸ“‹ å¯¼å…¥å‰æ£€æŸ¥æ¸…å•

### âœ… æ‰€æœ‰éªŒè¯å·²é€šè¿‡

è¿è¡ŒéªŒè¯è„šæœ¬ç¡®è®¤ç³»ç»Ÿå°±ç»ªï¼š
```bash
# ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆ7/7 é€šè¿‡ï¼‰
python scripts/verify_consistency.py

# æ•°æ®éªŒè¯ï¼ˆ1000 tokens æœ‰æ•ˆï¼‰
python scripts/test_import_data.py
```

**éªŒè¯ç»“æœ**:
- âœ… Prisma Schema â†” Python Model: 32å­—æ®µå®Œå…¨åŒ¹é…
- âœ… TokenImporter å­—æ®µå¤„ç†: 16ä¸ªå¿…éœ€å­—æ®µ
- âœ… ä¸»é“¾ä¼˜å…ˆçº§: ethereum > BSC > polygon > solana...
- âœ… ä¸»ç½‘ä»£å¸å¤„ç†: ä½¿ç”¨ coingecko_id ä½œä¸º token_address
- âœ… å”¯ä¸€çº¦æŸ: (chain, token_address) + coingecko_id
- âœ… æ¨¡å‹å…³ç³»: 4ä¸ªå…³ç³»ï¼Œä½¿ç”¨ viewonly=True
- âœ… å¯¼å…¥è„šæœ¬: è‡ªåŠ¨åŠ è½½å¹¶åˆå¹¶ aliases

---

## ğŸ“Š æ•°æ®æ¦‚è§ˆ

### æ•°æ®æ–‡ä»¶ä½ç½®
```
python/token_recognition/data/
â”œâ”€â”€ tokens.json    (1000 tokens)
â””â”€â”€ aliases.json   (741 alias mappings)
```

### æ•°æ®ç»Ÿè®¡
| ç±»å‹ | æ•°é‡ | è¯´æ˜ |
|------|------|------|
| **æ€»ä»£å¸æ•°** | 1000 | å…¨éƒ¨æœ‰æ•ˆ |
| **ä¸»ç½‘ä»£å¸** | 111 | BTC, ETH, LTC... |
| **è·¨é“¾ä»£å¸** | 457 | 2æ¡ä»¥ä¸Šé“¾ |
| **å•é“¾ä»£å¸** | 432 | ä»…ä¸€æ¡é“¾ |
| **å¸¦åˆ«åä»£å¸** | 797 | è‡ªåŠ¨åˆå¹¶ |

### Top é“¾åˆ†å¸ƒ
1. ethereum: 486
2. binance-smart-chain: 293
3. solana: 186
4. base: 184
5. arbitrum-one: 148
6. polygon-pos: 98
7. avalanche: 78

### ç¤¾äº¤é“¾æ¥è¦†ç›–ç‡
- Website: 96.5%
- Twitter: 88.9%
- Telegram: 58.3%
- GitHub: 49.9%
- Discord: 42.5%

---

## ğŸš€ æ‰§è¡Œå¯¼å…¥

### åŸºæœ¬å¯¼å…¥å‘½ä»¤

```bash
cd /Users/qinghuan/Documents/code/prisma-web3/python

# æ ‡å‡†å¯¼å…¥ï¼ˆæ¨èï¼‰- è‡ªåŠ¨åˆå¹¶ aliases
python scripts/import_token_recognition_data.py
```

### å¯é€‰å‚æ•°

```bash
# åªåˆ›å»ºæ–°ä»£å¸ï¼Œè·³è¿‡å·²å­˜åœ¨çš„
python scripts/import_token_recognition_data.py --no-update

# è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤50ï¼‰
python scripts/import_token_recognition_data.py --batch-size 100

# æŒ‡å®šè‡ªå®šä¹‰æ–‡ä»¶è·¯å¾„
python scripts/import_token_recognition_data.py \
  --tokens-file path/to/tokens.json \
  --aliases-file path/to/aliases.json
```

### é¢„æœŸè¾“å‡º

```
============================================================
Token Recognition Data Import
============================================================
Tokens file: /path/to/tokens.json
Aliases file: /path/to/aliases.json
Update existing: True
Batch size: 50
============================================================
Loading tokens from tokens.json...
Loaded 1000 tokens
Loading aliases from aliases.json...
Loaded 741 alias mappings
Created alias map with 741 entries
Merged aliases for 797 tokens  â† è‡ªåŠ¨åˆå¹¶ï¼
Database connection established
Importing 1000 tokens...
Progress: 50/1000 tokens processed
Progress: 100/1000 tokens processed
Progress: 150/1000 tokens processed
...
Progress: 1000/1000 tokens processed
Import complete
============================================================
Import Complete!
============================================================
Total tokens processed: 1000
Created: 1000
Updated: 0
Skipped: 0
Errors: 0
============================================================
```

---

## ğŸ”§ å…³é”®æŠ€æœ¯ç»†èŠ‚

### 1. ä¸»ç½‘ä»£å¸å¤„ç†ï¼ˆBug Fixï¼‰

**é—®é¢˜**: å¤šä¸ªä¸»ç½‘ä»£å¸ï¼ˆBTC, ETHç­‰ï¼‰éƒ½æœ‰ `chain=''` å’Œ `token_address=''`ï¼Œè¿åå”¯ä¸€çº¦æŸã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¸»ç½‘ä»£å¸ç°åœ¨ä½¿ç”¨:
chain = ""
token_address = coingecko_id  # e.g., "bitcoin", "ethereum"
platforms = {}
```

**ç¤ºä¾‹**:
| Token | chain | token_address | platforms |
|-------|-------|---------------|-----------|
| BTC | `""` | `"bitcoin"` | `{}` |
| ETH | `""` | `"ethereum"` | `{}` |

### 2. è·¨é“¾ä»£å¸å¤„ç†

ä¸»é“¾ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰:
1. ethereum
2. binance-smart-chain
3. base
4. arbitrum-one
5. optimistic-ethereum
6. polygon-pos
7. solana
8. avalanche

**ç¤ºä¾‹ï¼ˆUSDTï¼‰**:
```python
# ä¸»é“¾å­˜å‚¨åœ¨ chain/token_address
chain = "ethereum"
token_address = "0xdac17f958d2ee523a2206206994597c13d831ec7"

# å…¶ä»–é“¾å­˜å‚¨åœ¨ platforms JSON
platforms = {
  "tron": "TR7NHqjeKQxGTCi8q8ZY4pL8otSzgjLj6t",
  "solana": "Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB",
  "polygon-pos": "0xc2132d05d31c914a87c6611c10748aeb04b58e8f"
}
```

### 3. é“¾åç§°è§„èŒƒåŒ–ä¸ç¼©å†™ (Chain Configuration)

**è®¾è®¡åŸåˆ™**:
- æ•°æ®åº“å­˜å‚¨ CoinGecko æ ‡å‡†åç§°ï¼ˆæ•°æ®ä¸€è‡´æ€§ï¼‰
- åº”ç”¨å±‚ä½¿ç”¨ç¼©å†™ï¼ˆä¾¿æ·æ€§ï¼‰

**æ ‡å‡†åç§° <-> ç¼©å†™æ˜ å°„**:
| æ ‡å‡†åç§° | ç¼©å†™ | æ˜¾ç¤ºåç§° |
|---------|------|---------|
| `ethereum` | `eth` | Ethereum |
| `binance-smart-chain` | `bsc` | BNB Chain |
| `solana` | `sol` | Solana |
| `base` | `base` | Base |
| `arbitrum-one` | `arb` | Arbitrum |
| `polygon-pos` | `poly` | Polygon |
| `avalanche` | `avax` | Avalanche |
| `optimistic-ethereum` | `op` | Optimism |

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from prisma_web3_py.utils import ChainConfig, Chain

# æ–¹å¼1: ä½¿ç”¨ ChainConfig ç±»
ChainConfig.get_abbreviation("ethereum")  # -> "eth"
ChainConfig.get_standard_name("eth")      # -> "ethereum"
ChainConfig.get_display_name("eth")       # -> "Ethereum"

# æ–¹å¼2: ä½¿ç”¨ä¾¿æ·å‡½æ•°
from prisma_web3_py.utils import abbr, standard, display

abbr("ethereum")      # -> "eth"
standard("eth")       # -> "ethereum"
display("bsc")        # -> "BNB Chain"

# æ–¹å¼3: ä½¿ç”¨å¸¸é‡
Chain.ETH             # -> "eth"
Chain.BSC             # -> "bsc"
Chain.ETHEREUM        # -> "ethereum"
```

**Token æ¨¡å‹é›†æˆ**:
```python
token = await token_repo.get_by_symbol(session, "UNI")

# è·å–é“¾ç¼©å†™
token.get_chain_abbr()                    # -> "eth"
token.get_chain_display_name()            # -> "Ethereum"

# ä½¿ç”¨ç¼©å†™è·å–åœ°å€
token.get_address_on_chain_abbr("eth")    # æ”¯æŒç¼©å†™
token.get_address_on_chain("ethereum")    # æ”¯æŒæ ‡å‡†åç§°

# è·å–æ‰€æœ‰é“¾ä¿¡æ¯ï¼ˆå«ç¼©å†™ï¼‰
chains = token.get_all_chains_with_abbr()
# [
#   {'standard': 'ethereum', 'abbr': 'eth', 'display': 'Ethereum'},
#   {'standard': 'polygon-pos', 'abbr': 'poly', 'display': 'Polygon'}
# ]
```

**TokenRecognition æ”¯æŒ**:
```python
from prisma_web3_py.utils import TokenRecognition

recognizer = TokenRecognition()

# ç°åœ¨åŒæ—¶æ”¯æŒæ ‡å‡†åç§°å’Œç¼©å†™ï¼
address1 = await recognizer.get_token_address(session, "UNI", "ethereum")
address2 = await recognizer.get_token_address(session, "UNI", "eth")
# address1 == address2  âœ…

token1 = await recognizer.get_token_by_address(session, "ethereum", "0x...")
token2 = await recognizer.get_token_by_address(session, "eth", "0x...")
# token1 == token2  âœ…
```

### 4. Aliases åˆå¹¶é€»è¾‘

**aliases.json**:
```json
{
  "canonical": "BTC",
  "aliases": ["MEZO WRAPPED BTC", "MEZO BTC"]
}
```

**tokens.json** (åŸå§‹):
```json
{
  "symbol": "BTC",
  "name": "Bitcoin",
  "aliases": []
}
```

**åˆå¹¶åå¯¼å…¥åˆ°æ•°æ®åº“**:
```json
{
  "symbol": "BTC",
  "name": "Bitcoin",
  "aliases": ["MEZO WRAPPED BTC", "MEZO BTC"]
}
```

---

## ğŸ§ª å¯¼å…¥åéªŒè¯

### 1. æ£€æŸ¥æ•°æ®åº“

```sql
-- æ€»ä»£å¸æ•°
SELECT COUNT(*) FROM "Token";
-- é¢„æœŸ: 1000

-- ä¸»ç½‘ä»£å¸
SELECT symbol, name, chain, token_address
FROM "Token"
WHERE chain = ''
LIMIT 10;
-- é¢„æœŸ: BTC (bitcoin), ETH (ethereum), etc.

-- è·¨é“¾ä»£å¸ï¼ˆUSDTï¼‰
SELECT
  symbol,
  name,
  chain as primary_chain,
  token_address as primary_address,
  platforms
FROM "Token"
WHERE symbol = 'USDT';

-- æ£€æŸ¥åˆ«å
SELECT symbol, name, aliases
FROM "Token"
WHERE jsonb_array_length(aliases) > 0
LIMIT 10;
-- é¢„æœŸ: 797ä¸ªä»£å¸æœ‰åˆ«å

-- å„é“¾ä»£å¸æ•°é‡ç»Ÿè®¡
SELECT chain, COUNT(*) as count
FROM "Token"
WHERE chain != ''
GROUP BY chain
ORDER BY count DESC;
```

### 2. è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# æµ‹è¯• TokenRecognition æ¨¡å—
python scripts/test_token_recognition.py

# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python scripts/run_all_tests.py
```

### 3. ä½¿ç”¨ TokenRecognition

```python
from prisma_web3_py import get_db
from prisma_web3_py.utils import TokenRecognition

recognizer = TokenRecognition()

async with get_db() as session:
    # æµ‹è¯•æ–‡æœ¬è¯†åˆ«
    text = "I bought $BTC and USDT"
    tokens = await recognizer.recognize_from_text(session, text)
    assert len(tokens) == 2  # BTC and USDT

    # æµ‹è¯•åˆ«ååŒ¹é…
    token = await recognizer.get_token_by_symbol(session, "MEZO WRAPPED BTC")
    assert token.symbol == "BTC"  # é€šè¿‡åˆ«åæ‰¾åˆ° BTC

    # æµ‹è¯•è·¨é“¾åœ°å€
    addresses = await recognizer.get_all_chain_addresses(session, "USDT")
    assert "ethereum" in addresses
    assert "tron" in addresses
    assert "solana" in addresses

    # æµ‹è¯•ä¸»ç½‘ä»£å¸
    btc = await recognizer.get_token_by_symbol(session, "BTC")
    assert btc.is_mainnet_token() == True
    assert btc.chain == ""
    assert btc.token_address == "bitcoin"
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q1: å¯¼å…¥æ—¶å‡ºç°å”¯ä¸€çº¦æŸé”™è¯¯ï¼Ÿ
**A**: å·²ä¿®å¤ã€‚ä¸»ç½‘ä»£å¸ç°åœ¨ä½¿ç”¨ coingecko_id ä½œä¸º token_addressï¼Œé¿å…å†²çªã€‚

### Q2: å¦‚ä½•ç¡®è®¤ aliases å·²å¯¼å…¥ï¼Ÿ
**A**: æŸ¥è¯¢æ•°æ®åº“ï¼š
```sql
SELECT COUNT(*) FROM "Token"
WHERE jsonb_array_length(aliases) > 0;
-- åº”è¯¥è¿”å› 797
```

### Q3: å¦‚ä½•é‡æ–°å¯¼å…¥ï¼Ÿ
**A**: å¦‚æœéœ€è¦å®Œå…¨é‡æ–°å¯¼å…¥ï¼š
1. åˆ é™¤ç°æœ‰æ•°æ®: `DELETE FROM "Token" WHERE coingecko_id IS NOT NULL;`
2. é‡æ–°è¿è¡Œå¯¼å…¥: `python scripts/import_token_recognition_data.py`

### Q4: å¦‚ä½•æ›´æ–°ä»£å¸æ•°æ®?
**A**: æ›´æ–° JSON æ–‡ä»¶åï¼Œç›´æ¥é‡æ–°è¿è¡Œå¯¼å…¥ï¼ˆé»˜è®¤ä¼šæ›´æ–°å·²å­˜åœ¨çš„ä»£å¸ï¼‰ï¼š
```bash
python scripts/import_token_recognition_data.py
```

### Q5: TokenRecognition æ— æ³•è¯†åˆ«æŸä¸ªä»£å¸ï¼Ÿ
**A**: æ£€æŸ¥æ­¥éª¤ï¼š
```python
# 1. ç¡®è®¤ä»£å¸å·²å¯¼å…¥
token = await recognizer.get_token_by_symbol(session, "SYMBOL")
if not token:
    print("Token not imported")

# 2. æ£€æŸ¥åˆ«å
token = await recognizer.get_token_by_symbol(session, "ALIAS_NAME")

# 3. æœç´¢ä»£å¸
results = await recognizer.search_tokens(session, "partial_name")
```

---

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### è„šæœ¬æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `import_token_recognition_data.py` | **ä¸»å¯¼å…¥è„šæœ¬**ï¼ˆè‡ªåŠ¨åˆå¹¶ aliasesï¼‰ |
| `test_import_data.py` | æ•°æ®éªŒè¯ï¼ˆå¯¼å…¥å‰ï¼‰ |
| `verify_consistency.py` | ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆæ¨¡å‹ã€schemaã€è„šæœ¬ï¼‰ |
| `test_token_recognition.py` | åŠŸèƒ½æµ‹è¯•ï¼ˆå¯¼å…¥åï¼‰ |
| `run_all_tests.py` | å®Œæ•´æµ‹è¯•å¥—ä»¶ |

### æ ¸å¿ƒæ¨¡å—

| æ¨¡å— | è¯´æ˜ |
|------|------|
| `prisma_web3_py/utils/token_importer.py` | TokenImporter ç±» |
| `prisma_web3_py/utils/token_recognition.py` | TokenRecognition ç±» |
| `prisma_web3_py/models/token.py` | Token æ¨¡å‹ |
| `prisma_web3_py/repositories/token_repository.py` | Token ä»“å‚¨ |

### æ–‡æ¡£æ–‡ä»¶

| æ–‡æ¡£ | å†…å®¹ |
|------|------|
| `IMPORT_GUIDE.md` | **æœ¬æ–‡æ¡£** - å®Œæ•´å¯¼å…¥æŒ‡å— |
| `docs/SIMPLIFIED_TOKEN_DESIGN.md` | è®¾è®¡æ–‡æ¡£ |
| `docs/TOKEN_REFACTOR_IMPLEMENTATION.md` | å®ç°ç»†èŠ‚ |
| `prisma_web3_py/utils/README.md` | Utils æ¨¡å—æ–‡æ¡£ |
| `token_recognition/IMPORT_GUIDE.md` | è¯¦ç»†æŠ€æœ¯è¯´æ˜ |

---

## âš¡ å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„å¯¼å…¥æµç¨‹

```bash
# 1. åˆ‡æ¢åˆ° python ç›®å½•
cd /Users/qinghuan/Documents/code/prisma-web3/python

# 2. ï¼ˆå¯é€‰ï¼‰éªŒè¯ä¸€åˆ‡å°±ç»ª
python scripts/verify_consistency.py

# 3. æ‰§è¡Œå¯¼å…¥
python scripts/import_token_recognition_data.py

# 4. éªŒè¯å¯¼å…¥ç»“æœ
python scripts/test_token_recognition.py

# å®Œæˆï¼ğŸ‰
```

### éªŒè¯å¯¼å…¥æˆåŠŸ

```sql
-- è¿æ¥æ•°æ®åº“
psql $DATABASE_URL

-- å¿«é€Ÿæ£€æŸ¥
SELECT
  COUNT(*) as total_tokens,
  COUNT(*) FILTER (WHERE chain = '') as mainnet_tokens,
  COUNT(*) FILTER (WHERE jsonb_array_length(aliases) > 0) as tokens_with_aliases
FROM "Token";

-- é¢„æœŸç»“æœ:
-- total_tokens: 1000
-- mainnet_tokens: 111
-- tokens_with_aliases: 797
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å¯¼å…¥æˆåŠŸåï¼š

1. âœ… **æ•°æ®å·²æŒä¹…åŒ–**: 1000ä¸ªä»£å¸åœ¨æ•°æ®åº“ä¸­
2. âœ… **ä½¿ç”¨ TokenRecognition**: ä»æ•°æ®åº“æŸ¥è¯¢ï¼Œä¸å†éœ€è¦ JSON æ–‡ä»¶
3. âœ… **æ”¯æŒåˆ«åæœç´¢**: 797ä¸ªä»£å¸å¯é€šè¿‡åˆ«åæŸ¥æ‰¾
4. âœ… **è·¨é“¾åœ°å€æŸ¥è¯¢**: æ”¯æŒæŸ¥è¯¢ä»£å¸åœ¨ä¸åŒé“¾ä¸Šçš„åœ°å€

### åœ¨åº”ç”¨ä¸­ä½¿ç”¨

```python
from prisma_web3_py.utils import TokenRecognition

recognizer = TokenRecognition()

# è¯†åˆ«ç”¨æˆ·æ¶ˆæ¯ä¸­çš„ä»£å¸
user_message = "Just bought some $BTC and USDT!"
tokens = await recognizer.recognize_from_text(session, user_message)

# è·å–ä»£å¸åœ°å€
uni_eth = await recognizer.get_token_address(session, "UNI", "ethereum")
uni_polygon = await recognizer.get_token_address(session, "UNI", "polygon")

# æœç´¢ä»£å¸
results = await recognizer.search_tokens(session, "uniswap", limit=10)
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

- ğŸ“– æŸ¥çœ‹ `docs/TOKEN_REFACTOR_IMPLEMENTATION.md` äº†è§£æŠ€æœ¯ç»†èŠ‚
- ğŸ”§ è¿è¡Œ `python scripts/verify_consistency.py` æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
- ğŸ§ª è¿è¡Œ `python scripts/test_import_data.py` éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
- ğŸ’¬ æŸ¥çœ‹è„šæœ¬è¾“å‡ºçš„è¯¦ç»†æ—¥å¿—å®šä½é—®é¢˜

---

**å‡†å¤‡å°±ç»ªï¼è¿è¡Œå¯¼å…¥å‘½ä»¤å¼€å§‹å§ï¼** ğŸš€

```bash
python scripts/import_token_recognition_data.py
```
