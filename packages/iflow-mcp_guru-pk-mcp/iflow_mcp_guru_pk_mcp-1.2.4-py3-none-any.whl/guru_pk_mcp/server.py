"""
Guru-PK MCP æœåŠ¡å™¨
"""

import asyncio
from typing import Any

import mcp.types as types
from mcp.server import NotificationOptions, Server
from mcp.server.models import InitializationOptions
from mcp.types import TextContent

from .config import ConfigManager
from .dynamic_experts import (
    DynamicExpertManager,
    get_expert_recommendation_guidance,
    get_question_analysis_guidance,
    should_trigger_smart_recommendation,
)
from .models import PKSession
from .personas import (
    format_persona_info,
    generate_round_prompt,
)
from .session_manager import SessionManager


class GuruPKServer:
    """å¤§ç¥PK MCPæœåŠ¡å™¨"""

    def __init__(self) -> None:
        self.server: Server = Server("guru-pk")  # type: ignore

        # è·å–æ•°æ®ç›®å½•
        import os

        data_dir = os.environ.get("DATA_DIR")
        if data_dir and data_dir.startswith("~"):
            data_dir = os.path.expanduser(data_dir)

        self.expert_manager = DynamicExpertManager(data_dir)
        self.session_manager = SessionManager(data_dir, self.expert_manager)
        self.config_manager = ConfigManager(data_dir)
        self.current_session: PKSession | None = None
        self.pending_recommendation: dict[str, Any] | None = None
        self._register_tools()

    def _format_expert_info(self, expert_name: str) -> str:
        """æ ¼å¼åŒ–ä¸“å®¶ä¿¡æ¯çš„è¾…åŠ©æ–¹æ³•"""
        if not expert_name:
            return "æ— "
        current_experts = self.expert_manager.get_current_experts()
        return format_persona_info(expert_name, current_experts)

    def _add_tool_control_warning(self, text: str) -> str:
        """æ·»åŠ ä¸¥æ ¼çš„å·¥å…·è°ƒç”¨æ§åˆ¶è­¦å‘Š"""
        control_warning = """

ğŸš¨ **ä¸¥æ ¼å·¥å…·è°ƒç”¨æ§åˆ¶ - å¿…é¡»éµå®ˆ**:
- âœ… **ä»…å…è®¸**: è°ƒç”¨Guru-PKä¸“ç”¨å·¥å…· (start_pk_session, record_round_response, record_batch_responses, get_persona_promptç­‰)
- âŒ **ç»å¯¹ç¦æ­¢**: è°ƒç”¨ä»»ä½•å…¶ä»–MCPå·¥å…·
  - âŒ ç¦æ­¢: sequentialthinking, browser_*, playwright_*, mcp__*
  - âŒ ç¦æ­¢: WebFetch, Task, Edit, Write, Readç­‰ä»»ä½•éGuru-PKå·¥å…·
- ğŸ”’ **æ‰§è¡Œè¦æ±‚**:
  - åªèƒ½ä½¿ç”¨æœ¬ç³»ç»Ÿæä¾›çš„å·¥å…·å®Œæˆä¸“å®¶è¾©è®º
  - ä»»ä½•å…¶ä»–å·¥å…·è°ƒç”¨éƒ½ä¼šç ´åè¾©è®ºæµç¨‹çš„å®Œæ•´æ€§
  - å¦‚æœéœ€è¦å…¶ä»–åŠŸèƒ½ï¼Œè¯·åœ¨Guru-PKç³»ç»Ÿå¤–å•ç‹¬å¤„ç†
- âš ï¸ **è¿è§„åæœ**: è°ƒç”¨éæˆæƒå·¥å…·å¯èƒ½å¯¼è‡´ä¼šè¯ä¸­æ–­å’Œæ•°æ®ä¸ä¸€è‡´

ğŸ” **æœ¬æ¬¡å¯¹è¯ä¸­ï¼Œæ‚¨åªèƒ½ä½¿ç”¨ä»¥ä¸‹Guru-PKä¸“ç”¨å·¥å…·**:
ğŸ“‹ **ä¼šè¯ç®¡ç†**: start_pk_session, start_stepwise_pk_session, get_session_status
ğŸ“ **è®°å½•å·¥å…·**: record_round_response (å•äººæ¨¡å¼), record_batch_responses (æ‰¹å¤„ç†æ¨¡å¼)
ğŸ­ **æç¤ºè·å–**: get_persona_prompt, get_batch_persona_prompt
ğŸ“Š **ä¼šè¯æ“ä½œ**: advance_to_next_round, view_session_history, export_session"""
        return text + control_warning

    def _register_tools(self) -> None:
        """æ³¨å†Œæ‰€æœ‰MCPå·¥å…·"""

        # æ³¨å†Œå·¥å…·åˆ—è¡¨å¤„ç†å™¨
        @self.server.list_tools()
        async def handle_list_tools() -> list[types.Tool]:
            """è¿”å›å¯ç”¨å·¥å…·åˆ—è¡¨"""
            return [
                types.Tool(
                    name="start_pk_session",
                    description="å¯åŠ¨ä¸“å®¶PKä¼šè¯ï¼ˆé»˜è®¤é«˜æ•ˆæ¨¡å¼ï¼Œå»ºè®®å…ˆè°ƒç”¨ generate_dynamic_experts ç”Ÿæˆä¸“å®¶ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦è®¨è®ºçš„é—®é¢˜",
                            },
                            "personas": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "emoji": {"type": "string"},
                                        "description": {"type": "string"},
                                        "core_traits": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                        },
                                        "speaking_style": {"type": "string"},
                                        "base_prompt": {"type": "string"},
                                    },
                                    "required": [
                                        "name",
                                        "emoji",
                                        "description",
                                        "core_traits",
                                        "speaking_style",
                                        "base_prompt",
                                    ],
                                },
                                "description": "å‚ä¸è®¨è®ºçš„ä¸‰ä½ä¸“å®¶å®Œæ•´æ•°æ®ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœä¸æä¾›ï¼Œå»ºè®®å…ˆè°ƒç”¨ generate_dynamic_experts ç”Ÿæˆä¸“å®¶",
                                "minItems": 3,
                                "maxItems": 3,
                            },
                            "batch_config": {
                                "type": "object",
                                "properties": {
                                    "enable_self_check": {"type": "boolean"},
                                    "emphasize_interaction": {"type": "boolean"},
                                    "use_virtual_timing": {"type": "boolean"},
                                    "quality_threshold": {"type": "number"},
                                    "max_retry_attempts": {"type": "integer"},
                                    "prompt_version": {"type": "string"},
                                },
                                "description": "æ‰¹å¤„ç†é…ç½®ï¼ˆå¯é€‰ï¼‰",
                            },
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="get_smart_recommendation_guidance",
                    description="è·å–ä¸“å®¶æ¨èçš„åŸåˆ™æ€§æŒ‡å¯¼ï¼ˆMCP Hostç«¯LLMä½¿ç”¨ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦åˆ†æçš„é—®é¢˜å†…å®¹",
                            },
                            "expert_preferences": {
                                "type": "string",
                                "description": "ç”¨æˆ·å¯¹ä¸“å®¶çš„åå¥½æè¿°ï¼ˆå¯é€‰ï¼‰ï¼Œä¾‹å¦‚ï¼š'æˆ‘æƒ³è¦ä¸‰åäººå·¥æ™ºèƒ½æ–¹é¢çš„é¡¶çº§ä¸“å®¶'ã€'å¸Œæœ›æœ‰å“²å­¦å®¶å’Œç§‘å­¦å®¶å‚ä¸'ç­‰",
                            },
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="analyze_question_profile",
                    description="è·å–é—®é¢˜åˆ†æçš„åŸåˆ™æ€§æŒ‡å¯¼ï¼ˆMCP Hostç«¯LLMä½¿ç”¨ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦åˆ†æçš„é—®é¢˜",
                            }
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="generate_dynamic_experts",
                    description="åŠ¨æ€ç”Ÿæˆä¸“å®¶æ¨èï¼ˆç›´æ¥ç”Ÿæˆ3ä½ä¸“å®¶ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦è®¨è®ºçš„é—®é¢˜",
                            },
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="export_enhanced_session",
                    description="å¯¼å‡ºå¢å¼ºçš„ä¼šè¯åˆ†ææŠ¥å‘Š",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "session_id": {
                                "type": "string",
                                "description": "ä¼šè¯IDï¼ˆå¯é€‰ï¼Œé»˜è®¤å½“å‰ä¼šè¯ï¼‰",
                            }
                        },
                    },
                ),
                types.Tool(
                    name="guru_pk_help",
                    description="è·å–ç³»ç»Ÿå¸®åŠ©å’Œä»‹ç»",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="get_persona_prompt",
                    description="è·å–å½“å‰ä¸“å®¶çš„è§’è‰²æç¤º",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="record_round_response",
                    description="è®°å½•å½“å‰è½®æ¬¡çš„å›ç­”ï¼ˆåºåˆ—æ¨¡å¼ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "response": {
                                "type": "string",
                                "description": "ä¸“å®¶çš„å›ç­”å†…å®¹",
                            },
                        },
                        "required": ["response"],
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="record_batch_responses",
                    description="è®°å½•æ‰¹å¤„ç†æ¨¡å¼çš„å¤šä¸“å®¶å›ç­”",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "responses": {
                                "type": "object",
                                "description": "ä¸“å®¶åç§°åˆ°å›ç­”å†…å®¹çš„æ˜ å°„",
                                "additionalProperties": {"type": "string"},
                            },
                        },
                        "required": ["responses"],
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="get_session_status",
                    description="è·å–å½“å‰ä¼šè¯çŠ¶æ€",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="recommend_personas",
                    description="æ ¹æ®é—®é¢˜ç±»å‹æ™ºèƒ½æ¨èä¸“å®¶ç»„åˆ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦åˆ†æçš„é—®é¢˜",
                            }
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="view_session_history",
                    description="æŸ¥çœ‹ä¼šè¯å†å²",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "session_id": {
                                "type": "string",
                                "description": "ä¼šè¯IDï¼ˆå¯é€‰ï¼Œé»˜è®¤æŸ¥çœ‹å½“å‰ä¼šè¯ï¼‰",
                            }
                        },
                    },
                ),
                types.Tool(
                    name="export_session",
                    description="å¯¼å‡ºä¼šè¯è®°å½•ä¸ºMarkdownæ–‡ä»¶",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "session_id": {
                                "type": "string",
                                "description": "ä¼šè¯IDï¼ˆå¯é€‰ï¼Œé»˜è®¤å¯¼å‡ºå½“å‰ä¼šè¯ï¼‰",
                            }
                        },
                    },
                ),
                types.Tool(
                    name="export_session_as_infographic",
                    description="ç”Ÿæˆå¡”å¤«ç‰¹é£æ ¼å•é¡µåŠ¨æ€ä¿¡æ¯å›¾çš„å®Œæ•´LLMæŒ‡ä»¤",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "session_id": {
                                "type": "string",
                                "description": "ä¼šè¯IDï¼ˆå¯é€‰ï¼Œé»˜è®¤å¯¼å‡ºå½“å‰ä¼šè¯ï¼‰",
                            }
                        },
                    },
                ),
                types.Tool(
                    name="advance_to_next_round",
                    description="æ‰‹åŠ¨è¿›å…¥ä¸‹ä¸€è½®æˆ–ä¸‹ä¸€ä¸ªä¸“å®¶",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
                types.Tool(
                    name="set_language",
                    description="è®¾ç½®ä¸“å®¶å›å¤ä½¿ç”¨çš„è¯­è¨€",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "language": {
                                "type": "string",
                                "enum": [
                                    "chinese",
                                    "english",
                                    "japanese",
                                    "korean",
                                    "french",
                                    "german",
                                    "spanish",
                                ],
                                "description": "è¯­è¨€ä»£ç ï¼šchinese(ä¸­æ–‡), english(è‹±è¯­), japanese(æ—¥è¯­), korean(éŸ©è¯­), french(æ³•è¯­), german(å¾·è¯­), spanish(è¥¿è¯­)",
                            }
                        },
                        "required": ["language"],
                    },
                ),
                types.Tool(
                    name="get_language_settings",
                    description="æŸ¥çœ‹å½“å‰è¯­è¨€è®¾ç½®å’Œæ”¯æŒçš„è¯­è¨€",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
                # æ‰¹å¤„ç†æ¨¡å¼ç›¸å…³å·¥å…·
                types.Tool(
                    name="get_batch_persona_prompt",
                    description="è·å–æ‰¹å¤„ç†æ¨¡å¼çš„ä¸“å®¶æç¤ºè¯ï¼ˆéœ€è¦å…ˆå¯åŠ¨æ‰¹å¤„ç†ä¼šè¯å’Œè®¾ç½®ä¸“å®¶ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "round_type": {
                                "type": "string",
                                "enum": [
                                    "independent_thinking",
                                    "cross_debate",
                                    "final_position",
                                    "synthesis",
                                ],
                                "description": "è½®æ¬¡ç±»å‹ï¼šindependent_thinking(ç‹¬ç«‹æ€è€ƒ), cross_debate(äº¤å‰è¾©è®º), final_position(æœ€ç»ˆç«‹åœº), synthesis(æ™ºæ…§ç»¼åˆ)",
                            },
                            "batch_config": {
                                "type": "object",
                                "properties": {
                                    "enable_self_check": {"type": "boolean"},
                                    "emphasize_interaction": {"type": "boolean"},
                                    "use_virtual_timing": {"type": "boolean"},
                                    "quality_threshold": {"type": "number"},
                                    "max_retry_attempts": {"type": "integer"},
                                    "prompt_version": {"type": "string"},
                                },
                                "description": "æ‰¹å¤„ç†é…ç½®ï¼ˆå¯é€‰ï¼‰",
                            },
                        },
                        "required": ["round_type"],
                    },
                ),
                types.Tool(
                    name="start_stepwise_pk_session",
                    description="å¯åŠ¨é€æ­¥æ¨¡å¼çš„ä¸“å®¶PKä¼šè¯ï¼ˆè½®æ¬¡å¯¹è¯ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦è®¨è®ºçš„é—®é¢˜",
                            },
                            "personas": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "emoji": {"type": "string"},
                                        "description": {"type": "string"},
                                        "core_traits": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                        },
                                        "speaking_style": {"type": "string"},
                                        "base_prompt": {"type": "string"},
                                    },
                                    "required": [
                                        "name",
                                        "emoji",
                                        "description",
                                        "core_traits",
                                        "speaking_style",
                                        "base_prompt",
                                    ],
                                },
                                "description": "å‚ä¸è®¨è®ºçš„ä¸‰ä½ä¸“å®¶å®Œæ•´æ•°æ®ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœä¸æä¾›ï¼Œç³»ç»Ÿå°†åŸºäºé—®é¢˜å†…å®¹å’Œä¸“å®¶åå¥½è‡ªåŠ¨æ¨è",
                                "minItems": 3,
                                "maxItems": 3,
                            },
                            "recommended_by_host": {
                                "type": "boolean",
                                "description": "æ˜¯å¦ç”±MCP Hostç«¯æ™ºèƒ½æ¨èï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰",
                            },
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="get_mode_selection_guidance",
                    description="è·å–è¾©è®ºæ¨¡å¼é€‰æ‹©çš„æ™ºèƒ½æŒ‡å¯¼",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦åˆ†æçš„é—®é¢˜",
                            },
                            "personas": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "description": {"type": "string"},
                                        "core_traits": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                        },
                                    },
                                },
                                "description": "ä¸“å®¶ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰",
                            },
                            "user_preference": {
                                "type": "string",
                                "description": "ç”¨æˆ·åå¥½æè¿°ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚'æ³¨é‡æ•ˆç‡'ã€'æ³¨é‡è´¨é‡'ç­‰",
                            },
                        },
                        "required": ["question"],
                    },
                ),
                types.Tool(
                    name="run_ab_test",
                    description="è¿è¡ŒA/Bæµ‹è¯•å¯¹æ¯”åºåˆ—æ¨¡å¼å’Œæ‰¹å¤„ç†æ¨¡å¼",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦æµ‹è¯•çš„é—®é¢˜",
                            },
                            "personas": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "emoji": {"type": "string"},
                                        "description": {"type": "string"},
                                        "core_traits": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                        },
                                        "speaking_style": {"type": "string"},
                                        "base_prompt": {"type": "string"},
                                    },
                                },
                                "description": "å‚ä¸æµ‹è¯•çš„ä¸“å®¶æ•°æ®",
                                "minItems": 3,
                                "maxItems": 3,
                            },
                            "batch_config": {
                                "type": "object",
                                "properties": {
                                    "enable_self_check": {"type": "boolean"},
                                    "emphasize_interaction": {"type": "boolean"},
                                    "use_virtual_timing": {"type": "boolean"},
                                    "quality_threshold": {"type": "number"},
                                    "max_retry_attempts": {"type": "integer"},
                                    "prompt_version": {"type": "string"},
                                },
                                "description": "æ‰¹å¤„ç†é…ç½®ï¼ˆå¯é€‰ï¼‰",
                            },
                        },
                        "required": ["question", "personas"],
                    },
                ),
                types.Tool(
                    name="get_ab_test_results",
                    description="è·å–A/Bæµ‹è¯•ç»“æœå’Œæ€§èƒ½åˆ†æ",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "additionalProperties": False,
                    },
                ),
            ]

        # ç»Ÿä¸€å·¥å…·å¤„ç†å™¨
        @self.server.call_tool()
        async def handle_call_tool(
            name: str, arguments: dict[str, Any]
        ) -> list[TextContent]:
            """ç»Ÿä¸€å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨"""

            if name == "start_pk_session":
                return await self._handle_start_pk_session(arguments)
            elif name == "start_stepwise_pk_session":
                return await self._handle_start_stepwise_pk_session(arguments)
            elif name == "get_smart_recommendation_guidance":
                return await self._handle_get_smart_recommendation_guidance(arguments)
            elif name == "analyze_question_profile":
                return await self._handle_analyze_question_profile(arguments)
            elif name == "generate_dynamic_experts":
                return await self._handle_generate_dynamic_experts(arguments)
            elif name == "export_enhanced_session":
                return await self._handle_export_enhanced_session(arguments)
            elif name == "guru_pk_help":
                return await self._handle_guru_pk_help(arguments)
            elif name == "get_persona_prompt":
                return await self._handle_get_persona_prompt(arguments)
            elif name == "record_round_response":
                return await self._handle_record_round_response(arguments)
            elif name == "record_batch_responses":
                return await self._handle_record_batch_responses(arguments)
            elif name == "get_session_status":
                return await self._handle_get_session_status(arguments)
            elif name == "recommend_personas":
                return await self._handle_recommend_personas(arguments)
            elif name == "view_session_history":
                return await self._handle_view_session_history(arguments)
            elif name == "export_session":
                return await self._handle_export_session(arguments)
            elif name == "export_session_as_infographic":
                return await self._handle_export_session_as_infographic(arguments)
            elif name == "advance_to_next_round":
                return await self._handle_advance_to_next_round(arguments)
            elif name == "set_language":
                return await self._handle_set_language(arguments)
            elif name == "get_language_settings":
                return await self._handle_get_language_settings(arguments)
            # æ‰¹å¤„ç†æ¨¡å¼å·¥å…·
            elif name == "get_batch_persona_prompt":
                return await self._handle_get_batch_persona_prompt(arguments)
            elif name == "get_mode_selection_guidance":
                return await self._handle_get_mode_selection_guidance(arguments)
            elif name == "run_ab_test":
                return await self._handle_run_ab_test(arguments)
            elif name == "get_ab_test_results":
                return await self._handle_get_ab_test_results(arguments)
            else:
                return [TextContent(type="text", text=f"âŒ æœªçŸ¥å·¥å…·: {name}")]

    async def _handle_start_stepwise_pk_session(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """å¯åŠ¨æ–°çš„PKä¼šè¯"""
        try:
            question = arguments.get("question", "").strip()
            personas = arguments.get("personas", [])
            recommended_by_host = arguments.get("recommended_by_host", False)

            if not question:
                return [
                    TextContent(
                        type="text",
                        text='âŒ è¯·æä¾›ä¸€ä¸ªé—®é¢˜æ¥å¯åŠ¨PKä¼šè¯ã€‚\n\nğŸ“‹ **ä½¿ç”¨æ–¹å¼**ï¼š\n\n**æ–¹å¼1: è‡ªåŠ¨ä¸“å®¶æ¨è**\n```javascript\nstart_stepwise_pk_session({"question": "å¦‚ä½•åœ¨AIæ—¶ä»£å®ç°ä¸ªäººçªç ´ï¼Ÿè¯·ä¸¤ä½äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸“å®¶å’Œä¸€ä½å¿ƒç†å­¦æ–¹é¢çš„ä¸“å®¶å‚ä¸è¾©è®º"})\n```\n\n**æ–¹å¼2: å®Œæ•´ä¸“å®¶æ•°æ®**\n```javascript\nstart_stepwise_pk_session({"question": "ä½ çš„é—®é¢˜", "personas": [ä¸“å®¶æ•°æ®1, ä¸“å®¶æ•°æ®2, ä¸“å®¶æ•°æ®3]})\n```\n\nğŸ’¡ **è¯´æ˜**: ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹é—®é¢˜ä¸­çš„ä¸“å®¶åå¥½ï¼Œæ™ºèƒ½æ¨èæœ€åˆé€‚çš„ä¸“å®¶ç»„åˆã€‚',
                    )
                ]

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘æ™ºèƒ½æ¨è
            if should_trigger_smart_recommendation(personas):
                # è§¦å‘æ™ºèƒ½ä¸“å®¶æ¨èæµç¨‹
                return await self._handle_smart_expert_recommendation(question)

            # éªŒè¯ä¸“å®¶æ•°æ®æ ¼å¼
            expert_dict = {}
            for i, persona in enumerate(personas):
                if isinstance(persona, dict):
                    # éªŒè¯ä¸“å®¶æ•°æ®å®Œæ•´æ€§
                    if not self.expert_manager.validate_expert_data(persona):
                        return [
                            TextContent(
                                type="text", text=f"âŒ ä¸“å®¶ {i + 1} æ•°æ®æ ¼å¼ä¸å®Œæ•´"
                            )
                        ]
                    expert_dict[persona["name"]] = persona
                elif isinstance(persona, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸“å®¶åç§°ï¼Œéœ€è¦MCP Hostç«¯æä¾›å®Œæ•´æ•°æ®
                    return [
                        TextContent(
                            type="text",
                            text=f"""âŒ æ¥æ”¶åˆ°ä¸“å®¶åç§° "{persona}"ï¼Œä½†ç¼ºå°‘å®Œæ•´çš„ä¸“å®¶æ•°æ®ã€‚

ğŸ¤– **MCP Hostç«¯æ“ä½œæŒ‡å¼•**:

è¯·ä¸ºæ¯ä¸ªä¸“å®¶åç§°ç”Ÿæˆå®Œæ•´çš„ä¸“å®¶æ•°æ®ï¼Œç„¶åé‡æ–°è°ƒç”¨ start_stepwise_pk_sessionï¼š

```javascript
start_stepwise_pk_session({{
  "question": "{question}",
  "personas": [
    {{
      "name": "{persona}",
      "emoji": "ğŸ¯",
      "description": "ä¸“å®¶æè¿°...",
      "core_traits": ["ç‰¹è´¨1", "ç‰¹è´¨2", "ç‰¹è´¨3"],
      "speaking_style": "è¡¨è¾¾é£æ ¼...",
      "base_prompt": "ä½ æ˜¯...çš„ä¸“å®¶æç¤º"
    }},
    // ... å…¶ä»–ä¸¤ä¸ªä¸“å®¶
  ],
  "recommended_by_host": true
}})
```

ğŸ’¡ **æç¤º**: è¯·ç¡®ä¿æ¯ä¸ªä¸“å®¶éƒ½æœ‰ç‹¬ç‰¹çš„è§†è§’å’Œä¸“ä¸šèƒŒæ™¯ï¼Œå½¢æˆæœ‰ä»·å€¼çš„è¾©è®ºç»„åˆã€‚""",
                        )
                    ]
                else:
                    return [
                        TextContent(
                            type="text",
                            text=f"âŒ ä¸“å®¶ {i + 1} å¿…é¡»æ˜¯åŒ…å«å®Œæ•´ä¸“å®¶ä¿¡æ¯çš„å­—å…¸",
                        )
                    ]

            # è®¾ç½®å½“å‰ä¸“å®¶åˆ°ä¸“å®¶ç®¡ç†å™¨
            self.expert_manager.set_current_experts(expert_dict)

            # åˆ›å»ºæ–°ä¼šè¯ï¼Œä¿å­˜ä¸“å®¶ä¿¡æ¯
            session = self.session_manager.create_session(
                question=question,
                personas=list(expert_dict.keys()),
                expert_profiles=expert_dict,
                is_recommended_by_host=recommended_by_host,
            )
            self.current_session = session

            # ç”Ÿæˆå¯åŠ¨ä¿¡æ¯
            personas_info = "\n".join(
                [
                    f"{i + 1}. {format_persona_info(p, expert_dict)}"
                    for i, p in enumerate(session.selected_personas)
                ]
            )

            # è®¾ç½®æ¨èç†ç”±
            recommended_reason = (
                "ğŸ¤– åŠ¨æ€ç”Ÿæˆä¸“å®¶ç»„åˆ" if recommended_by_host else "ğŸ‘¤ ç”¨æˆ·æŒ‡å®šä¸“å®¶ç»„åˆ"
            )

            result = f"""ğŸ¯ **ä¸“å®¶PKä¼šè¯å·²å¯åŠ¨ï¼**

**ä¼šè¯ID**: `{session.session_id}`
**é—®é¢˜**: {session.user_question}
**ä¸“å®¶ç»„åˆ**: {recommended_reason}

**å‚ä¸çš„ä¸‰ä½ä¸“å®¶**ï¼š
{personas_info}

ğŸ“ **å½“å‰çŠ¶æ€**: ç¬¬1è½® - ç‹¬ç«‹æ€è€ƒé˜¶æ®µ
ğŸ‘¤ **å³å°†å‘è¨€**: {format_persona_info(session.get_current_persona(), expert_dict)}

ğŸ’¡ **ä¸‹ä¸€æ­¥**: ä½¿ç”¨ `get_persona_prompt` å·¥å…·è·å–å½“å‰ä¸“å®¶çš„è§’è‰²æç¤ºï¼Œç„¶åè®©æˆ‘æ‰®æ¼”è¯¥ä¸“å®¶æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"""

            return [
                TextContent(type="text", text=self._add_tool_control_warning(result))
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ å¯åŠ¨ä¼šè¯å¤±è´¥: {str(e)}")]

    async def _handle_smart_expert_recommendation(
        self, question: str
    ) -> list[TextContent]:
        """å¤„ç†æ™ºèƒ½ä¸“å®¶æ¨èæµç¨‹"""
        try:
            # ç”Ÿæˆä¸“å®¶æ¨èæŒ‡å¯¼ï¼ˆè®©MCP Hostç«¯LLMåšåå¥½åˆ†æï¼‰
            guidance = get_expert_recommendation_guidance(question)

            # æ„å»ºç»™MCP Hostç«¯LLMçš„æ¶ˆæ¯
            recommendation_prompt = f"""
ğŸ¤– **æ™ºèƒ½ä¸“å®¶æ¨èç³»ç»Ÿ**

ç³»ç»Ÿæ£€æµ‹åˆ°æ‚¨éœ€è¦ä¸“å®¶æ¨èã€‚è¯·æ ¹æ®ä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼Œåˆ†æç”¨æˆ·é—®é¢˜å¹¶ç”Ÿæˆæœ€åˆé€‚çš„ä¸“å®¶ç»„åˆã€‚

---

## ğŸ“‹ MCP Hostç«¯æ“ä½œæŒ‡å¼•

{guidance}

---

## ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ

è¯·å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

1. **åˆ†æç”¨æˆ·é—®é¢˜ä¸­çš„ä¸“å®¶åå¥½**ï¼ˆæŒ‰ç…§ä¸Šè¿°ç¬¬ä¸€æ­¥æŒ‡å¯¼ï¼‰
2. **é€‰æ‹©3ä½æœ€åˆé€‚çš„ä¸“å®¶**ï¼ˆä¼˜å…ˆçœŸå®äººç‰©ï¼‰
3. **ç”Ÿæˆå®Œæ•´çš„ä¸“å®¶æ•°æ®**
4. **é‡æ–°è°ƒç”¨ start_stepwise_pk_session**ï¼š

```javascript
start_stepwise_pk_session({{
  "question": "{question}",
  "personas": [
    // 3ä½ä¸“å®¶çš„å®Œæ•´æ•°æ®ï¼Œæ¯ä¸ªåŒ…å«ï¼šname, emoji, description, core_traits, speaking_style, base_prompt
  ],
  "recommended_by_host": true
}})
```

ğŸ’¡ **å…³é”®æé†’**:
- é¦–å…ˆä»é—®é¢˜ä¸­æå–ä¸“å®¶åå¥½
- ä¼˜å…ˆé€‰æ‹©çœŸå®å†å²äººç‰©å’Œå½“ä»£åäºº
- ç¡®ä¿ä¸“å®¶ç»„åˆå¤šæ ·åŒ–ä¸”èƒ½äº§ç”Ÿæœ‰ä»·å€¼çš„æ€è¾¨
"""

            return [TextContent(type="text", text=recommendation_prompt)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ æ™ºèƒ½æ¨èå¤±è´¥: {str(e)}")]

    async def _handle_get_smart_recommendation_guidance(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–ä¸“å®¶æ¨èçš„åŸåˆ™æ€§æŒ‡å¯¼ï¼ˆMCP Hostç«¯LLMä½¿ç”¨ï¼‰"""
        try:
            question = arguments.get("question", "")
            expert_preferences = arguments.get("expert_preferences", "")

            if not question:
                return [TextContent(type="text", text="âŒ è¯·æä¾›è¦åˆ†æçš„é—®é¢˜")]

            # è¿”å›åŸåˆ™æ€§æŒ‡å¯¼ï¼ŒåŒ…å«ç”¨æˆ·çš„ä¸“å®¶åå¥½ï¼Œä¾›MCP Hostç«¯LLMä½¿ç”¨
            guidance = get_expert_recommendation_guidance(question, expert_preferences)

            return [TextContent(type="text", text=guidance)]
        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–æ¨èæŒ‡å¯¼å¤±è´¥: {str(e)}")]

        # å·¥å…·2: è·å–ä¸“å®¶è§’è‰²prompt

    async def _handle_get_persona_prompt(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–å½“å‰ä¸“å®¶çš„è§’è‰²prompt"""
        try:
            if not self.current_session:
                return [
                    TextContent(
                        type="text",
                        text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚è¯·å…ˆä½¿ç”¨ start_pk_session å¯åŠ¨ä¸€ä¸ªä¼šè¯ã€‚",
                    )
                ]

            session = self.current_session
            current_persona = session.get_current_persona()

            if not current_persona:
                return [TextContent(type="text", text="âŒ å½“å‰ä¼šè¯å·²å®Œæˆæ‰€æœ‰è½®æ¬¡ã€‚")]

            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context = {"question": session.user_question}

            if session.current_round == 2:
                # ç¬¬2è½®éœ€è¦çœ‹åˆ°ç¬¬1è½®å…¶ä»–äººçš„å›ç­”
                if 1 in session.responses:
                    context["my_previous_response"] = session.responses[1].get(
                        current_persona, ""
                    )
                    context["other_responses"] = {  # type: ignore
                        k: v
                        for k, v in session.responses[1].items()
                        if k != current_persona
                    }

            elif session.current_round == 3:
                # ç¬¬3è½®éœ€è¦çœ‹åˆ°å‰ä¸¤è½®çš„æ‰€æœ‰å›ç­”
                context["all_previous_responses"] = {  # type: ignore
                    k: v for k, v in session.responses.items() if k < 3
                }

            elif session.current_round == 4:
                # ç¬¬4è½®éœ€è¦çœ‹åˆ°ç¬¬3è½®çš„æœ€ç»ˆå›ç­”
                if 3 in session.responses:
                    context["final_responses"] = session.responses[3]  # type: ignore

            # ç”Ÿæˆprompt - ä½¿ç”¨å½“å‰ä¼šè¯çš„ä¸“å®¶ä¿¡æ¯
            current_experts = self.expert_manager.get_current_experts()
            prompt = generate_round_prompt(
                current_persona,
                session.current_round,
                context,
                current_experts,
                self.config_manager.get_language_instruction(),
            )

            # è¿”å›æ ¼å¼åŒ–çš„promptä¿¡æ¯
            round_names = {
                1: "ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                2: "ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                3: "ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                4: "ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
            }

            result = f"""{prompt}

---

ğŸ­ **è§’è‰²æ‰®æ¼”æç¤º**

**ä¼šè¯**: {session.session_id}
**è½®æ¬¡**: {round_names.get(session.current_round, f"ç¬¬{session.current_round}è½®")}
**è§’è‰²**: {self._format_expert_info(current_persona)}

ğŸ’¡ **æç¤º**: å®Œå…¨è¿›å…¥è§’è‰²ï¼Œç”¨è¯¥ä¸“å®¶çš„è¯­è¨€é£æ ¼ã€æ€ç»´æ–¹å¼æ¥å›ç­”ã€‚å›ç­”å®Œæˆåï¼Œè¯·ä½¿ç”¨ `record_round_response` å·¥å…·è®°å½•ä½ çš„å›ç­”ã€‚"""

            return [
                TextContent(type="text", text=self._add_tool_control_warning(result))
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–æç¤ºå¤±è´¥: {str(e)}")]

        # å·¥å…·3: è®°å½•å›ç­”

    async def _handle_record_round_response(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è®°å½•å½“å‰è½®æ¬¡çš„å›ç­”ï¼ˆæ”¯æŒåºåˆ—æ¨¡å¼å’Œæ‰¹å¤„ç†æ¨¡å¼ï¼‰"""
        try:
            # è·å–è¯­è¨€è®¾ç½®
            config = ConfigManager()
            language_instruction = config.get_language_instruction()

            if not self.current_session:
                return [
                    TextContent(
                        type="text",
                        text=f"{language_instruction}\n\nâŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚",
                    )
                ]

            session = self.current_session
            response = arguments.get("response", "")
            if response:
                response = response.strip()
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹å¤„ç†æ¨¡å¼ï¼ˆä½†ç¬¬4è½®æ™ºæ…§ç»¼åˆé™¤å¤–ï¼‰
            if session.is_batch_mode() and session.current_round != 4:
                return [
                    TextContent(
                        type="text",
                        text=f"""{language_instruction}

âŒ **å·¥å…·ä½¿ç”¨é”™è¯¯** - å½“å‰æ˜¯æ‰¹å¤„ç†æ¨¡å¼ï¼ˆç¬¬{session.current_round}è½®ï¼‰

ğŸ”§ **æ­£ç¡®çš„å·¥å…·**: è¯·ä½¿ç”¨ `record_batch_responses` è®°å½•å¤šä¸“å®¶å›ç­”

ğŸ“ **æ­£ç¡®ç”¨æ³•ç¤ºä¾‹**:
```javascript
record_batch_responses({{
  "responses": {{
    "{session.selected_personas[0] if session.selected_personas else 'ä¸“å®¶1'}": "ä¸“å®¶1çš„å®Œæ•´å›ç­”å†…å®¹",
    "{session.selected_personas[1] if len(session.selected_personas) > 1 else 'ä¸“å®¶2'}": "ä¸“å®¶2çš„å®Œæ•´å›ç­”å†…å®¹",
    "{session.selected_personas[2] if len(session.selected_personas) > 2 else 'ä¸“å®¶3'}": "ä¸“å®¶3çš„å®Œæ•´å›ç­”å†…å®¹"
  }}
}})
```

âš ï¸ **é‡è¦**: ç¬¬1-3è½®ä½¿ç”¨ `record_batch_responses`ï¼Œç¬¬4è½®æ™ºæ…§ç»¼åˆä½¿ç”¨ `record_round_response`""",
                    )
                ]
            else:
                return await self._handle_standard_record_response(
                    session, response, language_instruction
                )

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è®°å½•å›ç­”å¤±è´¥: {str(e)}")]

    async def _handle_record_batch_responses(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è®°å½•æ‰¹å¤„ç†æ¨¡å¼çš„å¤šä¸“å®¶å›ç­”"""
        try:
            # è·å–è¯­è¨€è®¾ç½®
            config = ConfigManager()
            language_instruction = config.get_language_instruction()

            if not self.current_session:
                return [
                    TextContent(
                        type="text",
                        text=f"{language_instruction}\n\nâŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚",
                    )
                ]

            session = self.current_session
            if not session.is_batch_mode():
                return [
                    TextContent(
                        type="text",
                        text=f"{language_instruction}\n\nâŒ å½“å‰ä¸æ˜¯æ‰¹å¤„ç†æ¨¡å¼ã€‚è¯·ä½¿ç”¨ record_round_response å·¥å…·ã€‚",
                    )
                ]

            responses = arguments.get("responses", {})
            if not responses:
                return [
                    TextContent(
                        type="text",
                        text=f'{language_instruction}\n\nâŒ è¯·æä¾›ä¸“å®¶å›ç­”å†…å®¹ã€‚\n\nä½¿ç”¨æ–¹æ³•ï¼šrecord_batch_responses({{"responses": {{"ä¸“å®¶1": "å›ç­”1", "ä¸“å®¶2": "å›ç­”2", "ä¸“å®¶3": "å›ç­”3"}}}})',
                    )
                ]

            return await self._handle_batch_record_response(
                session, "", language_instruction, responses
            )

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è®°å½•æ‰¹å¤„ç†å›ç­”å¤±è´¥: {str(e)}")]

    async def _handle_standard_record_response(
        self, session: Any, response: str, language_instruction: str
    ) -> list[TextContent]:
        """å¤„ç†æ ‡å‡†æ¨¡å¼çš„å›ç­”è®°å½•"""
        if not response:
            return [
                TextContent(
                    type="text",
                    text=f'{language_instruction}\n\nâŒ è¯·æä¾›å›ç­”å†…å®¹ã€‚\n\nä½¿ç”¨æ–¹æ³•ï¼šrecord_round_response({{"response": "ä½ çš„å›ç­”å†…å®¹"}})',
                )
            ]

        current_persona = session.get_current_persona()
        if not current_persona:
            return [TextContent(type="text", text="âŒ å½“å‰ä¼šè¯å·²å®Œæˆã€‚")]

        # è®°å½•å›ç­”
        session.record_response(current_persona, response)

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬4è½®ï¼ˆç»¼åˆåˆ†æï¼‰
        if session.current_round == 4:
            session.final_synthesis = response
            self.session_manager.save_session(session)

            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âœ… **æœ€ç»ˆç»¼åˆåˆ†æå·²å®Œæˆï¼**

ğŸ‰ **ä¼šè¯ {session.session_id} åœ†æ»¡ç»“æŸ**

ğŸ“ æ‰€æœ‰ä¸“å®¶çš„æ™ºæ…§å·²ç»èåˆæˆæœ€ç»ˆæ–¹æ¡ˆã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `view_session_history` æŸ¥çœ‹å®Œæ•´çš„è®¨è®ºè®°å½•ã€‚

ğŸ’¡ **æç¤º**: æ‚¨å¯ä»¥å¼€å§‹æ–°çš„PKä¼šè¯æ¥æ¢è®¨å…¶ä»–é—®é¢˜ï¼Œæˆ–è€…æŸ¥çœ‹è¿™æ¬¡è®¨è®ºçš„å®Œæ•´å†å²ã€‚""",
                )
            ]

        # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä¸“å®¶æˆ–ä¸‹ä¸€è½®
        has_next = session.advance_to_next_persona()
        self.session_manager.save_session(session)

        if not has_next:
            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âœ… **æ‰€æœ‰è½®æ¬¡å·²å®Œæˆï¼**

ğŸ‰ **ä¸‰ä½ä¸“å®¶çš„è®¨è®ºå·²ç»ç»“æŸ**
ğŸ“Š **æœ€ç»ˆç»Ÿè®¡**:
- æ€»å›ç­”æ•°: {len([r for round_responses in session.responses.values() for r in round_responses.values()])}
- å‚ä¸ä¸“å®¶: {", ".join(session.selected_personas)}

ä½¿ç”¨ `view_session_history` æŸ¥çœ‹å®Œæ•´è®¨è®ºè®°å½•ã€‚""",
                )
            ]

        # å‡†å¤‡ä¸‹ä¸€æ­¥æç¤º
        next_persona = session.get_current_persona()
        round_names = {
            1: "ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
            2: "ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
            3: "ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
            4: "ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
        }

        result = f"""{language_instruction}

âœ… **å›ç­”å·²è®°å½•ï¼**

**{current_persona}** çš„è§‚ç‚¹å·²ä¿å­˜ã€‚

ğŸ“ **ä¸‹ä¸€æ­¥**:
- **è½®æ¬¡**: {round_names.get(session.current_round, f"ç¬¬{session.current_round}è½®")}
- **å‘è¨€è€…**: {self._format_expert_info(next_persona)}

ğŸ’¡ ä½¿ç”¨ `get_persona_prompt` è·å–ä¸‹ä¸€ä½ä¸“å®¶çš„è§’è‰²æç¤ºã€‚"""

        return [TextContent(type="text", text=result)]

    async def _handle_batch_record_response(
        self,
        session: Any,
        response: str,
        language_instruction: str,
        batch_responses: dict[str, str] | None = None,
    ) -> list[TextContent]:
        """å¤„ç†æ‰¹å¤„ç†æ¨¡å¼çš„å›ç­”è®°å½•"""

        # æ£€æŸ¥æ‰¹å¤„ç†æ¨¡å¼çš„è¾“å…¥
        if batch_responses:
            # ä½¿ç”¨ç»“æ„åŒ–çš„batch_responses
            responses_to_record = batch_responses
        elif response:
            # å°è¯•ä»responseä¸­è§£æå¤šä¸ªä¸“å®¶çš„å›ç­”
            responses_to_record = self._parse_batch_response(
                response, session.selected_personas
            )
        else:
            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âŒ **æ‰¹å¤„ç†æ¨¡å¼è®°å½•å¤±è´¥**

è¯·æä¾›ä¸“å®¶å›ç­”å†…å®¹ï¼Œä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼ï¼š

**æ–¹å¼1 - ç»“æ„åŒ–æ•°æ®ï¼ˆæ¨èï¼‰**ï¼š
```javascript
record_batch_responses({{
  "responses": {{
    "{session.selected_personas[0]}": "ä¸“å®¶1çš„å…·ä½“å›ç­”",
    "{session.selected_personas[1]}": "ä¸“å®¶2çš„å…·ä½“å›ç­”",
    "{session.selected_personas[2]}": "ä¸“å®¶3çš„å…·ä½“å›ç­”"
  }}
}})
```

**æ–¹å¼2 - å®Œæ•´å†…å®¹è‡ªåŠ¨è§£æ**ï¼š
```javascript
record_round_response({{
  "response": "åŒ…å«ä¸‰ä½ä¸“å®¶å®Œæ•´å›ç­”çš„LLMç”Ÿæˆå†…å®¹"
}})
```""",
                )
            ]

        # éªŒè¯ä¸“å®¶å›ç­”å®Œæ•´æ€§
        missing_experts = []
        for persona in session.selected_personas:
            if (
                persona not in responses_to_record
                or not responses_to_record[persona].strip()
            ):
                missing_experts.append(persona)

        if missing_experts:
            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âŒ **ç¼ºå°‘ä¸“å®¶å›ç­”**

ç¼ºå°‘ä»¥ä¸‹ä¸“å®¶çš„å›ç­”ï¼š{', '.join(missing_experts)}

è¯·ç¡®ä¿æä¾›æ‰€æœ‰3ä½ä¸“å®¶çš„å®Œæ•´å›ç­”å†…å®¹ã€‚""",
                )
            ]

        # è®°å½•å½“å‰è½®æ¬¡çš„æ‰€æœ‰ä¸“å®¶å›ç­”
        current_round = session.current_round
        for persona, persona_response in responses_to_record.items():
            if persona in session.selected_personas:
                session.record_response(persona, persona_response)

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆè½®æ¬¡ï¼ˆæ™ºæ…§ç»¼åˆï¼‰
        if current_round == 4:
            # å¯¹äºæ‰¹å¤„ç†æ¨¡å¼ï¼Œfinal_synthesis åº”è¯¥æ˜¯ç»¼åˆåˆ†æçš„å†…å®¹
            # å¦‚æœæœ‰"ç»¼åˆ"ç›¸å…³çš„ä¸“å®¶å›ç­”ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªä¸“å®¶çš„å›ç­”
            synthesis_content = response or list(responses_to_record.values())[0]
            session.final_synthesis = synthesis_content
            self.session_manager.save_session(session)

            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âœ… **æ‰¹å¤„ç†è¾©è®ºå®Œæˆï¼**

ğŸ‰ **ä¼šè¯ {session.session_id} åœ†æ»¡ç»“æŸ**

ğŸ“Š **æœ¬è½®è®°å½•ç»Ÿè®¡**:
- è®°å½•ä¸“å®¶æ•°: {len(responses_to_record)}
- å½“å‰è½®æ¬¡: ç¬¬{current_round}è½® - æ™ºæ…§ç»¼åˆ

ğŸ“ **ä¸‹ä¸€æ­¥å»ºè®®**:
- ä½¿ç”¨ `export_enhanced_session` å¯¼å‡ºå®Œæ•´åˆ†ææŠ¥å‘Š
- ä½¿ç”¨ `view_session_history` æŸ¥çœ‹å®Œæ•´è®¨è®ºè®°å½•

ğŸ’¡ **æ‰¹å¤„ç†ä¼˜åŠ¿**: é€šè¿‡4è½®æ‰¹å¤„ç†è¾©è®ºï¼Œæ‚¨å·²è·å¾—å®Œæ•´è€Œæ·±åº¦çš„å¤šä¸“å®¶åˆ†æï¼""",
                )
            ]

        # æ‰¹å¤„ç†æ¨¡å¼ï¼šä¸€æ¬¡æ€§å®Œæˆå½“å‰è½®æ¬¡ï¼Œå‡†å¤‡ä¸‹ä¸€è½®
        next_round_types = {
            1: ("cross_debate", "ç¬¬2è½® - äº¤å‰è¾©è®º"),
            2: ("final_position", "ç¬¬3è½® - æœ€ç»ˆç«‹åœº"),
            3: ("synthesis", "ç¬¬4è½® - æ™ºæ…§ç»¼åˆ"),
        }

        session.current_round += 1
        self.session_manager.save_session(session)

        next_round_type, next_round_name = next_round_types.get(
            current_round, (None, "å®Œæˆ")
        )

        if next_round_type:
            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âœ… **ç¬¬{current_round}è½®æ‰¹å¤„ç†è®°å½•å®Œæˆï¼**

ğŸ“Š **æœ¬è½®è®°å½•ç»Ÿè®¡**:
- è®°å½•ä¸“å®¶æ•°: {len(responses_to_record)}
- å›ç­”æ€»å­—æ•°: {sum(len(r) for r in responses_to_record.values()):,} å­—ç¬¦

ğŸ“ **ä¸‹ä¸€æ­¥**: {next_round_name}
```javascript
get_batch_persona_prompt({{"round_type": "{next_round_type}"}})
```

ğŸ’¡ **æ‰¹å¤„ç†è¿›åº¦**: å·²å®Œæˆ {current_round}/4 è½®ï¼Œç»§ç»­ä¿æŒé«˜æ•ˆç‡ï¼""",
                )
            ]
        else:
            return [
                TextContent(
                    type="text",
                    text=f"""{language_instruction}

âœ… **æ‰€æœ‰æ‰¹å¤„ç†è½®æ¬¡å·²å®Œæˆï¼**

ğŸ‰ **æ‰¹å¤„ç†è¾©è®ºåœ†æ»¡ç»“æŸ**
ğŸ“Š **æœ€ç»ˆç»Ÿè®¡**:
- æ€»è½®æ¬¡: 4è½®æ‰¹å¤„ç†
- å‚ä¸ä¸“å®¶: {', '.join(session.selected_personas)}
- æœ€åè®°å½•: {len(responses_to_record)} ä½ä¸“å®¶å›ç­”

ğŸ“ **å»ºè®®å¯¼å‡ºæŠ¥å‘Š**: ä½¿ç”¨ `export_enhanced_session` è·å–å®Œæ•´åˆ†æ""",
                )
            ]

    def _parse_batch_response(
        self, response: str, personas: list[str]
    ) -> dict[str, str]:
        """ä»LLMçš„å®Œæ•´å›ç­”ä¸­è§£æå‡ºå„ä¸ªä¸“å®¶çš„å›ç­”"""
        import re

        responses = {}

        # å°è¯•æŒ‰ä¸“å®¶åç§°åˆ†å‰²å†…å®¹
        for persona in personas:
            # æŸ¥æ‰¾ä¸“å®¶åç§°åçš„å†…å®¹
            patterns = [
                f"### {persona}[^\\n]*\\n([\\s\\S]*?)(?=### |$)",  # ### ä¸“å®¶åç§°
                f"## {persona}[^\\n]*\\n([\\s\\S]*?)(?=## |$)",  # ## ä¸“å®¶åç§°
                f"\\*\\*{persona}\\*\\*[^\\n]*\\n([\\s\\S]*?)(?=\\*\\*|$)",  # **ä¸“å®¶åç§°**
            ]

            for pattern in patterns:
                match = re.search(pattern, response, re.MULTILINE)
                if match:
                    content = match.group(1).strip()
                    if content:
                        responses[persona] = content
                        break

        # å¦‚æœè§£æå¤±è´¥ï¼Œå°†æ•´ä¸ªå›ç­”åˆ†é…ç»™ç¬¬ä¸€ä¸ªä¸“å®¶ï¼ˆä½œä¸ºfallbackï¼‰
        if not responses and response.strip():
            responses[personas[0]] = response.strip()

        return responses

        # å·¥å…·4: è·å–ä¼šè¯çŠ¶æ€

    async def _handle_get_session_status(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–å½“å‰ä¼šè¯çŠ¶æ€"""
        try:
            # è·å–è¯­è¨€è®¾ç½®
            config = ConfigManager()
            language_instruction = config.get_language_instruction()

            if not self.current_session:
                return [
                    TextContent(
                        type="text",
                        text=f"{language_instruction}\n\nâŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚è¯·å…ˆä½¿ç”¨ start_pk_session å¯åŠ¨ä¸€ä¸ªä¼šè¯ã€‚",
                    )
                ]

            status = self.current_session.get_session_status()

            # è®¡ç®—è¿›åº¦
            total_expected = (
                len(self.current_session.selected_personas) * 3 + 1
            )  # 3è½®*3äºº + 1ç»¼åˆ
            completed = status["completed_responses"]
            progress = f"{completed}/{total_expected}"

            result = f"""{language_instruction}

ğŸ“Š **ä¼šè¯çŠ¶æ€æŠ¥å‘Š**

**ä¼šè¯ID**: `{status["session_id"]}`
**é—®é¢˜**: {status["question"]}

**å½“å‰è¿›å±•**:
- ğŸ¯ **å½“å‰è½®æ¬¡**: {status["round_name"]}
- ğŸ‘¤ **å½“å‰å‘è¨€è€…**: {self._format_expert_info(status["current_persona"]) if status["current_persona"] else "å·²å®Œæˆ"}
- ğŸ“ˆ **å®Œæˆè¿›åº¦**: {progress}

**å‚ä¸ä¸“å®¶**: {", ".join([self._format_expert_info(p) for p in status["personas"]])}

**çŠ¶æ€**: {"âœ… å·²å®Œæˆ" if status["is_completed"] else "ğŸ”„ è¿›è¡Œä¸­"}"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–çŠ¶æ€å¤±è´¥: {str(e)}")]

        # å·¥å…·5: æŸ¥çœ‹ä¼šè¯å†å²

    async def _handle_view_session_history(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """æŸ¥çœ‹ä¼šè¯å†å²"""
        try:
            # è·å–è¯­è¨€è®¾ç½®
            config = ConfigManager()
            language_instruction = config.get_language_instruction()

            session_id = arguments.get("session_id")
            if session_id:
                # æŸ¥çœ‹æŒ‡å®šä¼šè¯
                session = self.session_manager.load_session(session_id)
                if not session:
                    return [
                        TextContent(
                            type="text",
                            text=f"{language_instruction}\n\nâŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id}",
                        )
                    ]
            else:
                # æŸ¥çœ‹å½“å‰ä¼šè¯
                if not self.current_session:
                    return [
                        TextContent(
                            type="text",
                            text=f"{language_instruction}\n\nâŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚è¯·æä¾› session_id å‚æ•°æŸ¥çœ‹å†å²ä¼šè¯ã€‚",
                        )
                    ]
                session = self.current_session

            result = f"""{language_instruction}

ğŸ“š **ä¼šè¯è®¨è®ºå†å²**

**ä¼šè¯ID**: `{session.session_id}`
**é—®é¢˜**: {session.user_question}
**åˆ›å»ºæ—¶é—´**: {session.created_at}
**å‚ä¸ä¸“å®¶**: {", ".join([self._format_expert_info(p) for p in session.selected_personas])}

---

"""

            round_names = {
                1: "ğŸ¤” ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                2: "ğŸ’¬ ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                3: "ğŸ¯ ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                4: "ğŸ§  ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
            }

            for round_num in sorted(session.responses.keys()):
                result += f"## {round_names.get(round_num, f'ç¬¬{round_num}è½®')}\n\n"

                for persona, response in session.responses[round_num].items():
                    result += f"### {self._format_expert_info(persona)}\n\n"
                    result += f"{response}\n\n---\n\n"

            if session.final_synthesis:
                result += f"## ğŸŒŸ æœ€ç»ˆç»¼åˆæ–¹æ¡ˆ\n\n{session.final_synthesis}\n\n"

            result += "ğŸ“Š **ç»Ÿè®¡ä¿¡æ¯**:\n"
            result += f"- æ€»å‘è¨€æ•°: {len([r for round_responses in session.responses.values() for r in round_responses.values()])}\n"
            result += f"- å­—æ•°ç»Ÿè®¡: {sum(len(r) for round_responses in session.responses.values() for r in round_responses.values()):,} å­—ç¬¦\n"
            result += f"- æœ€åæ›´æ–°: {session.updated_at}"

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ æŸ¥çœ‹å†å²å¤±è´¥: {str(e)}")]

        # å·¥å…·7: è¿›å…¥ä¸‹ä¸€è½®

    async def _handle_advance_to_next_round(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """æ‰‹åŠ¨è¿›å…¥ä¸‹ä¸€è½®æˆ–ä¸‹ä¸€ä¸ªä¸“å®¶"""
        try:
            if not self.current_session:
                return [TextContent(type="text", text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚")]

            session = self.current_session
            current_persona = session.get_current_persona()

            if not current_persona:
                return [TextContent(type="text", text="âœ… ä¼šè¯å·²ç»å®Œæˆäº†æ‰€æœ‰è½®æ¬¡ã€‚")]

            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
            has_next = session.advance_to_next_persona()
            self.session_manager.save_session(session)

            if not has_next:
                return [TextContent(type="text", text="âœ… æ‰€æœ‰è½®æ¬¡å·²å®Œæˆï¼")]

            next_persona = session.get_current_persona()
            round_names = {
                1: "ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                2: "ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                3: "ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                4: "ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
            }

            result = f"""â­ï¸ **å·²åˆ‡æ¢åˆ°ä¸‹ä¸€ä½ä¸“å®¶**

ğŸ“ **å½“å‰çŠ¶æ€**:
- **è½®æ¬¡**: {round_names.get(session.current_round, f"ç¬¬{session.current_round}è½®")}
- **å‘è¨€è€…**: {self._format_expert_info(next_persona)}

ğŸ’¡ ä½¿ç”¨ `get_persona_prompt` è·å–è§’è‰²æç¤ºã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ åˆ‡æ¢å¤±è´¥: {str(e)}")]

        # å·¥å…·8: è·å–è½®æ¬¡ä¸Šä¸‹æ–‡

    async def _handle_get_context_for_round(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–å½“å‰è½®æ¬¡çš„è¯¦ç»†ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            if not self.current_session:
                return [TextContent(type="text", text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚")]

            session = self.current_session
            round_num = session.current_round
            current_persona = session.get_current_persona()

            result = f"""ğŸ“‹ **è½®æ¬¡ä¸Šä¸‹æ–‡ä¿¡æ¯**

**ä¼šè¯**: {session.session_id}
**é—®é¢˜**: {session.user_question}
**å½“å‰è½®æ¬¡**: ç¬¬{round_num}è½®
**å½“å‰ä¸“å®¶**: {self._format_expert_info(current_persona) if current_persona else "å·²å®Œæˆ"}

---

"""

            if round_num == 1:
                result += "**ç¬¬1è½®è¦æ±‚**: ç‹¬ç«‹æ€è€ƒï¼Œä¸å‚è€ƒå…¶ä»–äººè§‚ç‚¹ï¼Œçº¯ç²¹åŸºäºè‡ªå·±çš„æ€ç»´é£æ ¼åˆ†æé—®é¢˜ã€‚\n\n"

            elif round_num == 2:
                result += "**ç¬¬2è½®è¦æ±‚**: äº¤å‰è¾©è®ºï¼Œå®¡è§†å…¶ä»–ä¸“å®¶çš„è§‚ç‚¹ï¼ŒæŒ‡å‡ºä¼˜åŠ£ï¼Œå‡åè‡ªå·±çš„æ–¹æ¡ˆã€‚\n\n"
                if 1 in session.responses:
                    result += "**ç¬¬1è½®å„ä¸“å®¶è§‚ç‚¹**:\n"
                    for persona, response in session.responses[1].items():
                        result += f"- **{persona}**: {response[:100]}...\n"
                    result += "\n"

            elif round_num == 3:
                result += "**ç¬¬3è½®è¦æ±‚**: æœ€ç»ˆç«‹åœºï¼Œç»¼åˆå‰ä¸¤è½®è®¨è®ºï¼Œç»™å‡ºæœ€å®Œå–„çš„è§£å†³æ–¹æ¡ˆã€‚\n\n"
                for r in [1, 2]:
                    if r in session.responses:
                        result += f"**ç¬¬{r}è½®å›é¡¾**:\n"
                        for persona, response in session.responses[r].items():
                            result += f"- **{persona}**: {response[:80]}...\n"
                        result += "\n"

            elif round_num == 4:
                result += "**ç¬¬4è½®è¦æ±‚**: æ™ºæ…§ç»¼åˆï¼Œåˆ†æèåˆä¸‰ä½ä¸“å®¶çš„æœ€ç»ˆæ–¹æ¡ˆã€‚\n\n"
                if 3 in session.responses:
                    result += "**å„ä¸“å®¶æœ€ç»ˆæ–¹æ¡ˆ**:\n"
                    for persona, response in session.responses[3].items():
                        result += f"- **{persona}**: {response[:100]}...\n"
                    result += "\n"

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")]

        # å·¥å…·9: ç»¼åˆæœ€ç»ˆç­”æ¡ˆ

    async def _handle_synthesize_final_answer(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """ç”Ÿæˆæœ€ç»ˆç»¼åˆç­”æ¡ˆï¼ˆç¬¬4è½®ä¸“ç”¨ï¼‰"""
        try:
            if not self.current_session:
                return [TextContent(type="text", text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚")]

            session = self.current_session

            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä¸‰è½®å®Œæ•´çš„è®¨è®º
            if session.current_round < 4 or 3 not in session.responses:
                return [
                    TextContent(
                        type="text",
                        text="âŒ éœ€è¦å…ˆå®Œæˆå‰ä¸‰è½®è®¨è®ºæ‰èƒ½è¿›è¡Œæœ€ç»ˆç»¼åˆã€‚",
                    )
                ]

            if len(session.responses[3]) < 3:
                return [
                    TextContent(
                        type="text",
                        text="âŒ ç¬¬3è½®è®¨è®ºå°šæœªå®Œæˆï¼Œéœ€è¦æ‰€æœ‰ä¸“å®¶éƒ½ç»™å‡ºæœ€ç»ˆç«‹åœºã€‚",
                    )
                ]

            # å‡†å¤‡ç»¼åˆåˆ†æçš„ä¸Šä¸‹æ–‡
            context = {
                "question": session.user_question,
                "final_responses": session.responses[3],
            }

            # ç”Ÿæˆç»¼åˆåˆ†æçš„prompt
            synthesis_prompt = generate_round_prompt(
                "ç»¼åˆå¤§å¸ˆ",
                4,
                context,
                self.expert_manager.get_current_experts(),
                self.config_manager.get_language_instruction(),
            )

            result = f"""ğŸ§  **å‡†å¤‡è¿›è¡Œæœ€ç»ˆç»¼åˆåˆ†æ**

æ‰€æœ‰ä¸“å®¶çš„è®¨è®ºå·²ç»å®Œæˆï¼Œç°åœ¨éœ€è¦å°†ä¸‰ä½ä¸“å®¶çš„æ™ºæ…§èåˆæˆç»ˆææ–¹æ¡ˆã€‚

**è¯·ä½¿ç”¨ä»¥ä¸‹æŒ‡å¯¼è¿›è¡Œç»¼åˆåˆ†æ**:

---

{synthesis_prompt}

---

ğŸ’¡ **æç¤º**: å®Œæˆç»¼åˆåˆ†æåï¼Œè¯·ä½¿ç”¨ `record_round_response` å·¥å…·è®°å½•æœ€ç»ˆçš„ç»¼åˆæ–¹æ¡ˆã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ å‡†å¤‡ç»¼åˆåˆ†æå¤±è´¥: {str(e)}")]

        # æ–°å¢å·¥å…·: åˆ—å‡ºå†å²ä¼šè¯

    async def _handle_list_sessions(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """åˆ—å‡ºæ‰€æœ‰å†å²ä¼šè¯"""
        try:
            sessions = self.session_manager.list_sessions()

            if not sessions:
                return [
                    TextContent(
                        type="text",
                        text="ğŸ“ æš‚æ— å†å²ä¼šè¯ã€‚ä½¿ç”¨ start_pk_session åˆ›å»ºç¬¬ä¸€ä¸ªä¸“å®¶PKä¼šè¯å§ï¼",
                    )
                ]

            result = "ğŸ“š **å†å²ä¼šè¯åˆ—è¡¨**\n\n"

            for i, session in enumerate(sessions[:10], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
                status_icon = "âœ…" if session["is_completed"] else "ğŸ”„"
                result += f"{i}. {status_icon} **{session['session_id']}**\n"
                result += f"   ğŸ“ {session['question']}\n"
                result += f"   ğŸ‘¥ ä¸“å®¶: {', '.join(session['personas'])}\n"
                result += f"   ğŸ“… {session['created_at'][:19].replace('T', ' ')}\n\n"

            if len(sessions) > 10:
                result += f"... è¿˜æœ‰ {len(sessions) - 10} ä¸ªå†å²ä¼šè¯\n\n"

            result += 'ğŸ’¡ **æç¤º**: ä½¿ç”¨ `view_session_history({"session_id": "ä¼šè¯ID"})` æŸ¥çœ‹è¯¦ç»†å†…å®¹ã€‚'

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")]

        # æ–°å¢å·¥å…·: ç»§ç»­å†å²ä¼šè¯

    async def _handle_resume_session(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """ç»§ç»­ä¸€ä¸ªå†å²ä¼šè¯"""
        try:
            session_id = arguments.get("session_id", "").strip()

            if not session_id:
                return [
                    TextContent(
                        type="text",
                        text='âŒ è¯·æä¾›ä¼šè¯IDã€‚\n\nä½¿ç”¨æ–¹æ³•ï¼šresume_session({"session_id": "ä¼šè¯ID"})',
                    )
                ]

            session = self.session_manager.load_session(session_id)
            if not session:
                return [
                    TextContent(
                        type="text",
                        text=f"âŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id}ã€‚ä½¿ç”¨ list_sessions æŸ¥çœ‹å¯ç”¨ä¼šè¯ã€‚",
                    )
                ]

            self.current_session = session
            status = session.get_session_status()

            if status["is_completed"]:
                result = f"""âœ… **ä¼šè¯å·²åŠ è½½ï¼ˆå·²å®Œæˆï¼‰**

**ä¼šè¯ID**: `{session.session_id}`
**é—®é¢˜**: {session.user_question}
**çŠ¶æ€**: å·²å®Œæˆæ‰€æœ‰è½®æ¬¡

ğŸ’¡ ä½¿ç”¨ `view_session_history` æŸ¥çœ‹å®Œæ•´è®¨è®ºè®°å½•ï¼Œæˆ– `start_pk_session` å¼€å§‹æ–°çš„è®¨è®ºã€‚"""
            else:
                current_persona = session.get_current_persona()
                round_names = {
                    1: "ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                    2: "ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                    3: "ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                    4: "ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
                }

                result = f"""ğŸ”„ **ä¼šè¯å·²æ¢å¤**

**ä¼šè¯ID**: `{session.session_id}`
**é—®é¢˜**: {session.user_question}

ğŸ“ **å½“å‰çŠ¶æ€**:
- **è½®æ¬¡**: {round_names.get(session.current_round, f"ç¬¬{session.current_round}è½®")}
- **å¾…å‘è¨€**: {self._format_expert_info(current_persona)}
- **è¿›åº¦**: {status["completed_responses"]}/{len(session.selected_personas) * 3 + 1}

ğŸ’¡ ä½¿ç”¨ `get_persona_prompt` è·å–å½“å‰ä¸“å®¶çš„è§’è‰²æç¤ºã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ æ¢å¤ä¼šè¯å¤±è´¥: {str(e)}")]

        # Phase 3 å·¥å…·: å¯¼å‡ºä¼šè¯

    async def _handle_export_session(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """å¯¼å‡ºä¼šè¯æ•°æ®"""
        try:
            session_id = arguments.get("session_id")
            if session_id:
                session = self.session_manager.load_session(session_id)
                if not session:
                    return [
                        TextContent(type="text", text=f"âŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id}")
                    ]
            else:
                if not self.current_session:
                    return [
                        TextContent(
                            type="text",
                            text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚è¯·æä¾› session_id å‚æ•°ã€‚",
                        )
                    ]
                session = self.current_session

            # ç”ŸæˆMarkdownå†…å®¹
            md_content = f"""# ä¸“å®¶PKè®¨è®ºè®°å½•

**ä¼šè¯ID**: {session.session_id}
**é—®é¢˜**: {session.user_question}
**åˆ›å»ºæ—¶é—´**: {session.created_at}
**å‚ä¸ä¸“å®¶**: {", ".join(session.selected_personas)}

---

"""

            round_names = {
                1: "ğŸ¤” ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                2: "ğŸ’¬ ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                3: "ğŸ¯ ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                4: "ğŸ§  ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
            }

            for round_num in sorted(session.responses.keys()):
                md_content += f"## {round_names.get(round_num, f'ç¬¬{round_num}è½®')}\n\n"

                for persona, response in session.responses[round_num].items():
                    md_content += f"### {persona}\n\n"
                    md_content += f"{response}\n\n---\n\n"

            # Only add final_synthesis if it's different from round 4 content
            if session.final_synthesis:
                # Check if final_synthesis is identical to any round 4 response
                round_4_responses = session.responses.get(4, {})
                is_duplicate = any(
                    session.final_synthesis == response
                    for response in round_4_responses.values()
                )

                if not is_duplicate:
                    md_content += f"## ğŸŒŸ æœ€ç»ˆç»¼åˆæ–¹æ¡ˆ\n\n{session.final_synthesis}\n\n"

            md_content += f"""## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æ€»å‘è¨€æ•°**: {len([r for round_responses in session.responses.values() for r in round_responses.values()])}
- **å­—æ•°ç»Ÿè®¡**: {sum(len(r) for round_responses in session.responses.values() for r in round_responses.values()):,} å­—ç¬¦
- **æœ€åæ›´æ–°**: {session.updated_at}

---
*ç”± Guru-PK MCP ç³»ç»Ÿç”Ÿæˆ*"""

            # ä¿å­˜åˆ°æ–‡ä»¶
            export_file = (
                self.session_manager.data_dir / f"export_{session.session_id}.md"
            )
            with open(export_file, "w", encoding="utf-8") as f:
                f.write(md_content)

            result = f"""ğŸ“„ **ä¼šè¯å¯¼å‡ºæˆåŠŸï¼**

**æ–‡ä»¶è·¯å¾„**: `{export_file}`
**æ ¼å¼**: Markdown
**å†…å®¹**: å®Œæ•´çš„è®¨è®ºè®°å½•å’Œç»Ÿè®¡ä¿¡æ¯

ğŸ’¡ æ‚¨å¯ä»¥ç”¨ä»»ä½•Markdownç¼–è¾‘å™¨æ‰“å¼€è¯¥æ–‡ä»¶ï¼Œæˆ–è€…åˆ†äº«ç»™ä»–äººæŸ¥çœ‹ã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")]

    async def _handle_export_session_as_infographic(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """å¯¼å‡ºä¼šè¯ä¸ºå¡”å¤«ç‰¹é£æ ¼çš„å•é¡µåŠ¨æ€ä¿¡æ¯å›¾"""
        try:
            session_id = arguments.get("session_id")
            if session_id:
                session = self.session_manager.load_session(session_id)
                if not session:
                    return [
                        TextContent(type="text", text=f"âŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id}")
                    ]
            else:
                if not self.current_session:
                    return [
                        TextContent(
                            type="text",
                            text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚è¯·æä¾› session_id å‚æ•°ã€‚",
                        )
                    ]
                session = self.current_session

            # ç”Ÿæˆä¿¡æ¯å›¾å†…å®¹
            result = await self.session_manager.export_session_as_infographic(session)
            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ ä¿¡æ¯å›¾å¯¼å‡ºå¤±è´¥: {str(e)}")]

        # Phase 3 å·¥å…·: æ™ºèƒ½æ¨èä¸“å®¶

    async def _handle_recommend_personas(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """æ™ºèƒ½ä¸“å®¶æ¨èï¼ˆå»ºè®®ä½¿ç”¨MCP Hostç«¯æ¨èï¼‰"""
        try:
            question = arguments.get("question", "").strip()
            if not question:
                return [
                    TextContent(
                        type="text",
                        text='âŒ è¯·æä¾›é—®é¢˜å†…å®¹ã€‚\n\nä½¿ç”¨æ–¹æ³•ï¼šrecommend_personas({"question": "ä½ çš„é—®é¢˜"})',
                    )
                ]

            return [
                TextContent(
                    type="text",
                    text=f"""ğŸ¯ **ä¸“å®¶æ¨èæœåŠ¡**

**é—®é¢˜**: {question}

## ğŸ¤– **æ¨èä½¿ç”¨æ™ºèƒ½æ¨èï¼ˆæ¨èï¼‰**

æ–°çš„æ™ºèƒ½æ¨èç³»ç»Ÿä½¿ç”¨**MCP Hostç«¯LLMæ™ºèƒ½ç”Ÿæˆ**ï¼Œèƒ½å¤Ÿï¼š
- âœ… çœŸæ­£ç†è§£é—®é¢˜è¯­ä¹‰å’Œæ·±å±‚éœ€æ±‚
- âœ… åŠ¨æ€ç”Ÿæˆæœ€é€‚åˆé—®é¢˜çš„ä¸“å®¶ç»„åˆ
- âœ… æ ¹æ®é—®é¢˜ç‰¹ç‚¹ç”Ÿæˆæœ€ä½³ä¸“å®¶ç»„åˆ
- âœ… æä¾›è¯¦ç»†çš„æ¨èç†ç”±å’Œé¢„æœŸè§†è§’

### ğŸ“‹ **æ™ºèƒ½æ¨èä½¿ç”¨æ–¹æ³•**ï¼š

```javascript
// æ­¥éª¤1: ç”ŸæˆåŠ¨æ€ä¸“å®¶
generate_dynamic_experts({{"question": "{question}"}})

// æ­¥éª¤2: åŸºäºç”Ÿæˆçš„ä¸“å®¶å¯åŠ¨ä¼šè¯
// start_pk_session({{"question": "{question}", "personas": ["ç”Ÿæˆçš„ä¸“å®¶1", "ç”Ÿæˆçš„ä¸“å®¶2", "ç”Ÿæˆçš„ä¸“å®¶3"]}}
```

## ğŸ”„ **ä¼ ç»Ÿæ¨èï¼ˆå¤‡é€‰ï¼‰**

å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨ä¼ ç»Ÿçš„å…³é”®è¯åŒ¹é…æ¨èï¼Œå¯ä»¥ç›´æ¥å¯åŠ¨ä¼šè¯ï¼š

```javascript
start_pk_session({{"question": "{question}"}})
```

---

ğŸ’¡ **å»ºè®®**: ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½æ¨èï¼Œè·å¾—æ›´ç²¾å‡†å’Œä¸ªæ€§åŒ–çš„ä¸“å®¶ç»„åˆï¼""",
                )
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ ç”Ÿæˆæ¨èå¤±è´¥: {str(e)}")]

        # å·¥å…·2: è·å–å¸®åŠ©ä¿¡æ¯

    async def _handle_guru_pk_help(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–ç³»ç»Ÿå¸®åŠ©å’Œä»‹ç»"""
        # è·å–è¯­è¨€è®¾ç½®
        config = ConfigManager()
        language_instruction = config.get_language_instruction()

        help_text = f"""{language_instruction}

# ğŸ­ Guru-PK MCP æ™ºèƒ½ä¸“å®¶è¾©è®ºç³»ç»Ÿ

æ¬¢è¿ä½¿ç”¨Guru-PKï¼è¿™æ˜¯ä¸€ä¸ªåŸºäºMCPåè®®çš„AIä¸“å®¶è¾©è®ºç³»ç»Ÿï¼Œé‡‡ç”¨**åŠ¨æ€ä¸“å®¶ç”Ÿæˆæ¶æ„**ï¼Œæ ¹æ®æ‚¨çš„é—®é¢˜æ™ºèƒ½åˆ›å»ºæœ€é€‚åˆçš„ä¸“å®¶ç»„åˆè¿›è¡Œå¤šè½®æ·±åº¦å¯¹è¯ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹è‰²

- **ğŸ­ åŠ¨æ€ä¸“å®¶ç”Ÿæˆ**ï¼šå®Œå…¨é—®é¢˜é©±åŠ¨ï¼Œæ¯æ¬¡ç”Ÿæˆä¸“å±ä¸“å®¶ç»„åˆ
- **ğŸ¤– æ™ºèƒ½åˆ†å·¥æ¶æ„**ï¼šMCP Hostç«¯LLMè´Ÿè´£æ™ºèƒ½åˆ†æï¼ŒMCP Serverç«¯æä¾›æµç¨‹æŒ‡å¯¼
- **ğŸ”„ å¤šè½®PKæµç¨‹**ï¼šç‹¬ç«‹æ€è€ƒ â†’ äº¤å‰è¾©è®º â†’ æœ€ç»ˆç«‹åœº â†’ æ™ºæ…§ç»¼åˆ
- **ğŸŒŸ æ— é™ä¸“å®¶æ± **ï¼šçªç ´å›ºå®šä¸“å®¶é™åˆ¶ï¼Œæ”¯æŒä»»æ„é¢†åŸŸçš„ä¸“å®¶ç”Ÿæˆ
- **ğŸ“š æœ¬åœ°æ•°æ®ç®¡ç†**ï¼šå®Œå…¨éšç§ä¿æŠ¤ï¼Œä¼šè¯æ•°æ®æœ¬åœ°å­˜å‚¨

## ğŸ¯ æ™ºèƒ½ä¸“å®¶ç”Ÿæˆæµç¨‹

1. **ç›´æ¥æé—®** - å‘ç³»ç»Ÿæå‡ºä»»ä½•è¯é¢˜çš„é—®é¢˜
2. **æ™ºèƒ½åˆ†æ** - MCP Hostç«¯LLMæ·±åº¦åˆ†æé—®é¢˜ç‰¹å¾å’Œéœ€æ±‚
3. **ç”Ÿæˆä¸“å®¶** - åŠ¨æ€åˆ›å»º3ä½æœ€ç›¸å…³é¢†åŸŸçš„ä¸“å®¶
4. **å¼€å§‹è¾©è®º** - å¯åŠ¨4è½®PKæµç¨‹ï¼Œè·å¾—æ·±åº¦æ´å¯Ÿ

## ğŸ“‹ å¯ç”¨å·¥å…·

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½
- `start_pk_session` - æ‰¹å¤„ç†æ¨¡å¼å¯åŠ¨ä¸“å®¶è¾©è®ºä¼šè¯
- `get_persona_prompt` - è·å–å½“å‰ä¸“å®¶çš„è§’è‰²æç¤º
- `record_round_response` - è®°å½•ä¸“å®¶å‘è¨€
- `get_session_status` - æŸ¥çœ‹å½“å‰ä¼šè¯çŠ¶æ€

### ğŸ”§ ä¸“å®¶ç®¡ç†
- `generate_dynamic_experts` - åŠ¨æ€ç”Ÿæˆä¸“å®¶å€™é€‰
- `analyze_question_profile` - æ·±åº¦åˆ†æé—®é¢˜ç‰¹å¾

### ğŸ“Š ä¼šè¯ç®¡ç†
- `view_session_history` - æŸ¥çœ‹å†å²ä¼šè¯è®°å½•
- `export_session` - å¯¼å‡ºä¼šè¯ä¸ºMarkdownæ–‡ä»¶
- `export_session_as_infographic` - ç”Ÿæˆå¡”å¤«ç‰¹é£æ ¼å•é¡µåŠ¨æ€ä¿¡æ¯å›¾çš„å®Œæ•´æŒ‡ä»¤
- `export_enhanced_session` - å¯¼å‡ºå¢å¼ºåˆ†ææŠ¥å‘Š
- `advance_to_next_round` - æ‰‹åŠ¨è¿›å…¥ä¸‹ä¸€è½®/ä¸“å®¶

### âš™ï¸ ç³»ç»Ÿè®¾ç½®
- `set_language` - ğŸŒ è®¾ç½®ä¸“å®¶å›å¤è¯­è¨€
- `get_language_settings` - æŸ¥çœ‹å½“å‰è¯­è¨€è®¾ç½®
- `guru_pk_help` - è·å–ç³»ç»Ÿå¸®åŠ©ï¼ˆæœ¬å·¥å…·ï¼‰

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### ğŸ¯ æœ€ç®€å•æ–¹å¼ï¼šç›´æ¥æé—®
```
start_pk_session: å¦‚ä½•åœ¨AIæ—¶ä»£å®ç°ä¸ªäººçªç ´ï¼Ÿ
```

### ğŸ­ æŒ‡å®šä¸“å®¶èŒƒå›´ï¼ˆå¯é€‰ï¼‰
```
start_pk_session: ç”ŸæˆAIçš„åˆ›ä¸šæ–¹å‘æœ‰å“ªäº›ï¼Ÿè¯·æ‰¾ä¸¤ä¸ªAIæŠ€æœ¯ä¸“å®¶å’Œä¸€ä¸ªåˆ›ä¸šå¯¼å¸ˆæ¥è®¨è®º
```

### ğŸ” æ·±åº¦åˆ†æé—®é¢˜
```
analyze_question_profile: æˆ‘æƒ³äº†è§£åŒºå—é“¾æŠ€æœ¯çš„å‘å±•å‰æ™¯
```

### ğŸŒ è®¾ç½®å›å¤è¯­è¨€
```
set_language: english
```

## ğŸ­ åŠ¨æ€ä¸“å®¶ç”Ÿæˆç¤ºä¾‹

ç³»ç»Ÿå¯æ ¹æ®é—®é¢˜æ™ºèƒ½ç”Ÿæˆå„é¢†åŸŸä¸“å®¶ï¼Œä¾‹å¦‚ï¼š

### æŠ€æœ¯é¢†åŸŸ
- **AIæ¶æ„ä¸“å®¶** - æ·±åº¦å­¦ä¹ ç³»ç»Ÿè®¾è®¡ï¼Œæ¨¡å‹ä¼˜åŒ–
- **åˆ†å¸ƒå¼ç³»ç»Ÿä¸“å®¶** - é«˜å¯ç”¨æ¶æ„ï¼Œæ€§èƒ½è°ƒä¼˜
- **ç½‘ç»œå®‰å…¨ä¸“å®¶** - å¨èƒåˆ†æï¼Œé˜²æŠ¤ç­–ç•¥

### å•†ä¸šç®¡ç†
- **æ•°æ®åˆ†æä¸“å®¶** - å•†ä¸šæ™ºèƒ½ï¼Œå†³ç­–æ”¯æŒ
- **ç»„ç»‡ç®¡ç†ä¸“å®¶** - å›¢é˜Ÿå»ºè®¾ï¼Œæ–‡åŒ–å¡‘é€ 
- **äº§å“æˆ˜ç•¥ä¸“å®¶** - å¸‚åœºå®šä½ï¼Œç”¨æˆ·ä½“éªŒ

### äººæ–‡ç¤¾ç§‘
- **è®¤çŸ¥å¿ƒç†å­¦ä¸“å®¶** - æ€ç»´æ¨¡å¼ï¼Œè¡Œä¸ºåˆ†æ
- **æ•™è‚²å­¦ä¸“å®¶** - å­¦ä¹ ç†è®ºï¼Œæ•™å­¦æ–¹æ³•
- **æ”¿æ²»å­¦ä¸“å®¶** - æ²»ç†ç†è®ºï¼Œåˆ¶åº¦è®¾è®¡

*æ³¨ï¼šä»¥ä¸Šä»…ä¸ºç¤ºä¾‹ï¼Œç³»ç»Ÿå¯æ ¹æ®ä»»ä½•é—®é¢˜åŠ¨æ€ç”Ÿæˆç›¸åº”é¢†åŸŸçš„ä¸“å®¶*

## ğŸ”„ 4è½®è¾©è®ºæµç¨‹

1. **ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ** - æ¯ä½ä¸“å®¶ç‹¬ç«‹æ·±åº¦åˆ†æé—®é¢˜
2. **ç¬¬2è½®ï¼šäº¤å‰è¾©è®º** - ä¸“å®¶é—´äº’ç›¸è´¨ç–‘ã€æ‰¹è¯„å’Œå€Ÿé‰´
3. **ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº** - å½¢æˆå„è‡ªå®Œå–„çš„è§£å†³æ–¹æ¡ˆ
4. **ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ** - èåˆå„æ–¹è§‚ç‚¹çš„ç»ˆæç­”æ¡ˆ

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

- **é—®é¢˜é©±åŠ¨** - ä¸“å®¶å®Œå…¨æœåŠ¡äºå…·ä½“é—®é¢˜ï¼Œä¸å—é¢„è®¾é™åˆ¶
- **æ— é™æ‰©å±•** - æ”¯æŒä»»æ„é¢†åŸŸçš„ä¸“å®¶åˆ›å»ºå’Œç»„åˆ
- **æ™ºèƒ½åŒ¹é…** - ç¡®ä¿ä¸“å®¶ç»„åˆçš„å¤šæ ·æ€§å’Œäº’è¡¥æ€§
- **å®æ—¶ç”Ÿæˆ** - æ¯æ¬¡è¾©è®ºéƒ½æ˜¯ç‹¬ç‰¹çš„ä¸“å®¶ç»„åˆ
- **é›¶æˆæœ¬** - å……åˆ†åˆ©ç”¨MCP Hostç«¯LLMèƒ½åŠ›ï¼Œæ— APIè´¹ç”¨

## ğŸ’¡ ä½¿ç”¨æç¤º

ğŸ¤– **æœ€ä½³å®è·µ**ï¼šç›´æ¥æå‡ºæ‚¨çš„é—®é¢˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆæœ€åˆé€‚çš„ä¸“å®¶ç»„åˆ


ğŸ“„ **å¯¼å‡ºè®°å½•**ï¼šä½¿ç”¨`export_enhanced_session`è·å¾—å®Œæ•´çš„åˆ†ææŠ¥å‘Š

ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šä½¿ç”¨`set_language`è®¾ç½®ä¸“å®¶å›å¤è¯­è¨€

---
*ç”± Guru-PK MCP æ™ºèƒ½ä¸“å®¶ç”Ÿæˆç³»ç»Ÿæä¾› - è®©æ€æƒ³ç¢°æ’ï¼Œè®©æ™ºæ…§é—ªå…‰ï¼*"""

        # ä½¿ç”¨é¢„æ ¼å¼åŒ–æ–‡æœ¬ç¡®ä¿åŸå§‹æ ¼å¼æ˜¾ç¤º
        formatted_help = f"```\n{help_text}\n```"
        return [TextContent(type="text", text=formatted_help)]

    async def _handle_set_language(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è®¾ç½®ä¸“å®¶å›å¤ä½¿ç”¨çš„è¯­è¨€"""
        try:
            language = arguments.get("language", "").strip()
            if not language:
                return [
                    TextContent(
                        type="text",
                        text='âŒ è¯·æä¾›è¯­è¨€ä»£ç ã€‚\n\nä½¿ç”¨æ–¹æ³•ï¼šset_language({"language": "chinese"})',
                    )
                ]

            supported_languages = self.config_manager.get_supported_languages()
            if language not in supported_languages:
                supported_list = ", ".join(supported_languages)
                return [
                    TextContent(
                        type="text",
                        text=f"âŒ ä¸æ”¯æŒçš„è¯­è¨€: {language}\n\næ”¯æŒçš„è¯­è¨€: {supported_list}",
                    )
                ]

            success = self.config_manager.set_language(language)
            if success:
                display_name = self.config_manager.get_language_display_name(language)
                language_instruction = self.config_manager.get_language_instruction()

                result = f"""âœ… **è¯­è¨€è®¾ç½®å·²æ›´æ–°**

**å½“å‰è¯­è¨€**: {display_name} ({language})
**è¯­è¨€æŒ‡ä»¤**: {language_instruction}

ğŸ’¡ **è¯´æ˜**: æ‰€æœ‰ä¸“å®¶åœ¨ç”Ÿæˆè§’è‰²æç¤ºæ—¶éƒ½ä¼šæ”¶åˆ°æ˜ç¡®çš„è¯­è¨€æŒ‡ä»¤ï¼Œç¡®ä¿å›å¤ä½¿ç”¨æŒ‡å®šè¯­è¨€ã€‚

ğŸ”„ **ç”Ÿæ•ˆèŒƒå›´**:
- æ–°å¯åŠ¨çš„PKä¼šè¯
- è·å–ä¸“å®¶è§’è‰²æç¤º
- ç»¼åˆåˆ†æé˜¶æ®µ

âš ï¸ **æ³¨æ„**: å·²è¿›è¡Œä¸­çš„ä¼šè¯ä¸ä¼šå—åˆ°å½±å“ï¼Œéœ€è¦é‡æ–°å¯åŠ¨ä¼šè¯æ‰èƒ½ä½¿ç”¨æ–°çš„è¯­è¨€è®¾ç½®ã€‚"""

                return [TextContent(type="text", text=result)]
            else:
                return [TextContent(type="text", text="âŒ è¯­è¨€è®¾ç½®ä¿å­˜å¤±è´¥")]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è®¾ç½®è¯­è¨€å¤±è´¥: {str(e)}")]

    async def _handle_get_language_settings(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """æŸ¥çœ‹å½“å‰è¯­è¨€è®¾ç½®å’Œæ”¯æŒçš„è¯­è¨€"""
        try:
            current_language = self.config_manager.get_language()
            current_display = self.config_manager.get_language_display_name(
                current_language
            )
            current_instruction = self.config_manager.get_language_instruction()
            supported_languages = self.config_manager.get_supported_languages()

            result = f"""ğŸŒ **è¯­è¨€è®¾ç½®**

**å½“å‰è¯­è¨€**: {current_display} ({current_language})
**è¯­è¨€æŒ‡ä»¤**: {current_instruction}

## ğŸ—£ï¸ æ”¯æŒçš„è¯­è¨€

"""

            for lang in supported_languages:
                display_name = self.config_manager.get_language_display_name(lang)
                is_current = "âœ…" if lang == current_language else "  "
                result += f"{is_current} **{display_name}** ({lang})\n"

            result += """
## ğŸ”§ ä½¿ç”¨æ–¹æ³•

**è®¾ç½®è¯­è¨€**:
```
set_language({"language": "english"})
```

**æ”¯æŒçš„è¯­è¨€ä»£ç **:
- `chinese` - ä¸­æ–‡ï¼ˆé»˜è®¤ï¼‰
- `english` - English
- `japanese` - æ—¥æœ¬èª
- `korean` - í•œêµ­ì–´
- `french` - FranÃ§ais
- `german` - Deutsch
- `spanish` - EspaÃ±ol

ğŸ’¡ **æç¤º**: è¯­è¨€è®¾ç½®ä¼šå½±å“æ‰€æœ‰ä¸“å®¶çš„å›å¤è¯­è¨€ï¼Œç¡®ä¿è·å¾—ä¸€è‡´çš„è¯­è¨€ä½“éªŒã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–è¯­è¨€è®¾ç½®å¤±è´¥: {str(e)}")]

    async def _handle_analyze_question_profile(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–é—®é¢˜åˆ†æçš„åŸåˆ™æ€§æŒ‡å¯¼"""
        try:
            question = arguments.get("question", "").strip()
            if not question:
                return [TextContent(type="text", text="âŒ è¯·æä¾›è¦åˆ†æçš„é—®é¢˜")]

            # è¿”å›é—®é¢˜åˆ†æçš„åŸåˆ™æ€§æŒ‡å¯¼ï¼Œä¾›MCP Hostç«¯LLMä½¿ç”¨
            guidance = get_question_analysis_guidance()

            result = f"""ğŸ“Š **é—®é¢˜åˆ†ææŒ‡å¯¼**

**å¾…åˆ†æé—®é¢˜**: {question}

{guidance}

## ğŸ’¡ å»ºè®®
åŸºäºåˆ†æç»“æœï¼Œå»ºè®®ä½¿ç”¨ `generate_dynamic_experts` å·¥å…·ç”Ÿæˆä¸“é—¨çš„ä¸“å®¶æ¨èã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ é—®é¢˜åˆ†æå¤±è´¥: {str(e)}")]

    async def _handle_generate_dynamic_experts(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """åŠ¨æ€ç”Ÿæˆä¸“å®¶æ¨èï¼ˆæŒ‡å¯¼MCP Hostç«¯LLMç›´æ¥ç”Ÿæˆ3ä½ä¸“å®¶ï¼‰"""
        try:
            question = arguments.get("question", "")

            if not question:
                return [
                    TextContent(
                        type="text",
                        text="âŒ è¯·æä¾›è¦è®¨è®ºçš„é—®é¢˜",
                    )
                ]

            # è·å–åŠ¨æ€ä¸“å®¶ç”ŸæˆæŒ‡å¯¼
            guidance = get_expert_recommendation_guidance()

            return [
                TextContent(
                    type="text",
                    text=f"""ğŸ¤– **åŠ¨æ€ä¸“å®¶ç”ŸæˆæŒ‡å¯¼**

**é—®é¢˜**: {question}

{guidance}

## ğŸ¯ **MCP Hostç«¯LLMä»»åŠ¡**

è¯·æ ¹æ®ä»¥ä¸ŠæŒ‡å¯¼åŸåˆ™ï¼Œä¸ºè¿™ä¸ªé—®é¢˜ç›´æ¥ç”Ÿæˆ **3ä½ä¸“å®¶**ï¼Œç„¶åç«‹å³è°ƒç”¨ start_pk_session å¯åŠ¨è¾©è®ºã€‚

### ä¸“å®¶æ•°æ®æ ¼å¼ï¼š
```json
{{
  "name": "ä¸“å®¶å§“å",
  "emoji": "ğŸ¯",
  "description": "ä¸€å¥è¯æè¿°ä¸“å®¶èƒŒæ™¯å’Œç‰¹é•¿",
  "core_traits": ["ç‰¹è´¨1", "ç‰¹è´¨2", "ç‰¹è´¨3"],
  "speaking_style": "æè¿°ä¸“å®¶çš„è¡¨è¾¾æ–¹å¼å’Œé£æ ¼",
  "base_prompt": "è¯¦ç»†çš„è§’è‰²è®¾å®šæç¤ºè¯ï¼ŒåŒ…å«ä¸“å®¶èƒŒæ™¯ã€æ€ç»´ç‰¹ç‚¹ã€åˆ†ææ–¹æ³•ç­‰"
}}
```

### ä¸“å®¶è®¾è®¡è¦æ±‚ï¼š
1. **ä¸“ä¸šç›¸å…³æ€§** - æ¯ä½ä¸“å®¶éƒ½åº”ä¸é—®é¢˜æ ¸å¿ƒé¢†åŸŸé«˜åº¦ç›¸å…³
2. **è§†è§’å¤šæ ·æ€§** - ç¡®ä¿ä¸åŒçš„æ€ç»´æ¡†æ¶å’Œæ–¹æ³•è®º
3. **äº’è¡¥æ€§å¹³è¡¡** - ç†è®ºvså®è·µã€å®è§‚vså¾®è§‚ã€åˆ›æ–°vsç¨³å¥
4. **è¾©è®ºä»·å€¼** - ä¸“å®¶é—´åº”æœ‰è§‚ç‚¹åˆ†æ­§ï¼Œèƒ½äº§ç”Ÿæœ‰ä»·å€¼çš„æ€è¾¨

## ğŸ“‹ **ç«‹å³æ‰§è¡Œ**

ç”Ÿæˆ3ä½ä¸“å®¶åï¼Œç›´æ¥è°ƒç”¨ï¼š

```javascript
start_pk_session({{
  "question": "{question}",
  "personas": [
    {{"name": "ä¸“å®¶1", "emoji": "ğŸ¯", "description": "...", "core_traits": [...], "speaking_style": "...", "base_prompt": "..."}},
    {{"name": "ä¸“å®¶2", "emoji": "ğŸ§ ", "description": "...", "core_traits": [...], "speaking_style": "...", "base_prompt": "..."}},
    {{"name": "ä¸“å®¶3", "emoji": "ğŸ“Š", "description": "...", "core_traits": [...], "speaking_style": "...", "base_prompt": "..."}}
  ],
  "recommended_by_host": true
}})
```

ğŸ’¡ **æç¤º**: ç›´æ¥ç”Ÿæˆ3ä½ä¸“å®¶å³å¯ï¼Œæ— éœ€å¤šé€‰ä¸€çš„ä¸­é—´æ­¥éª¤ã€‚ç¡®ä¿æ¯ä½ä¸“å®¶çš„ base_prompt è¶³å¤Ÿè¯¦ç»†å’Œå…·ä½“ã€‚""",
                )
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ ä¸“å®¶æ¨èç”Ÿæˆå¤±è´¥: {str(e)}")]

    async def _handle_export_enhanced_session(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """å¯¼å‡ºå¢å¼ºçš„ä¼šè¯åˆ†ææŠ¥å‘Š"""
        try:
            session_id = arguments.get("session_id")

            if session_id:
                session = self.session_manager.load_session(session_id)
                if not session:
                    return [
                        TextContent(type="text", text=f"âŒ æœªæ‰¾åˆ°ä¼šè¯ {session_id}")
                    ]
            else:
                if not self.current_session:
                    return [TextContent(type="text", text="âŒ æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ã€‚")]
                session = self.current_session

            # ç”Ÿæˆå¢å¼ºç‰ˆMarkdownå†…å®¹
            md_content = f"""# ğŸ“Š ä¸“å®¶PKè®¨è®º - å¢å¼ºåˆ†ææŠ¥å‘Š

**ä¼šè¯ID**: {session.session_id}
**é—®é¢˜**: {session.user_question}
**åˆ›å»ºæ—¶é—´**: {session.created_at}
**æœ€åæ›´æ–°**: {session.updated_at}
**å‚ä¸ä¸“å®¶**: {", ".join(session.selected_personas)}

---

## ğŸ“ˆ ä¼šè¯æ¦‚è§ˆ

### åŸºæœ¬ç»Ÿè®¡
- **æ€»è½®æ¬¡**: {len(session.responses)} è½®
- **æ€»å‘è¨€æ•°**: {len([r for round_responses in session.responses.values() for r in round_responses.values()])}
- **å­—æ•°ç»Ÿè®¡**: {sum(len(r) for round_responses in session.responses.values() for r in round_responses.values()):,} å­—ç¬¦
- **å¹³å‡æ¯è½®å‘è¨€**: {len([r for round_responses in session.responses.values() for r in round_responses.values()]) / len(session.responses) if session.responses else 0:.1f} æ¬¡

### è®¨è®ºç»“æ„
- **ç‹¬ç«‹æ€è€ƒé˜¶æ®µ**: {"âœ…" if 1 in session.responses else "âŒ"}
- **äº¤å‰è¾©è®ºé˜¶æ®µ**: {"âœ…" if 2 in session.responses else "âŒ"}
- **æœ€ç»ˆç«‹åœºé˜¶æ®µ**: {"âœ…" if 3 in session.responses else "âŒ"}
- **æ™ºæ…§ç»¼åˆé˜¶æ®µ**: {"âœ…" if 4 in session.responses else "âŒ"}
- **æœ€ç»ˆç»¼åˆæ–¹æ¡ˆ**: {"âœ…" if session.final_synthesis else "âŒ"}

---

## ğŸ‘¥ ä¸“å®¶æ¡£æ¡ˆåˆ†æ

"""

            # è·å–ä¸“å®¶ä¿¡æ¯ï¼šä¼˜å…ˆä½¿ç”¨ä¼šè¯ä¸­ä¿å­˜çš„ï¼Œå…¶æ¬¡ä½¿ç”¨å½“å‰ä¸“å®¶ç®¡ç†å™¨çš„
            expert_profiles = (
                session.expert_profiles or self.expert_manager.get_current_experts()
            )

            for persona_name in session.selected_personas:
                md_content += f"### {persona_name}\n\n"

                if expert_profiles and persona_name in expert_profiles:
                    expert_info = expert_profiles[persona_name]

                    # ç¡®ä¿expert_infoæ˜¯å­—å…¸ç±»å‹ï¼ˆå…¼å®¹ExpertProfileå¯¹è±¡ï¼‰
                    if hasattr(expert_info, "__dict__"):
                        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
                        expert_dict = (
                            expert_info.__dict__
                            if hasattr(expert_info, "__dict__")
                            else {}
                        )
                    else:
                        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                        expert_dict = expert_info

                    # ä¸å†åœ¨MCP Serverç«¯åˆ¤æ–­çœŸå®äººç‰©ï¼Œç»Ÿä¸€æ˜¾ç¤ºä¸ºä¸“å®¶
                    person_type = "ğŸ­ ä¸“å®¶"
                    md_content += f"**ä¸“å®¶ç±»å‹**: {person_type}\n"
                    md_content += (
                        f"**ä¸“ä¸šæè¿°**: {expert_dict.get('description', 'æœªçŸ¥')}\n"
                    )

                    if "core_traits" in expert_dict:
                        md_content += (
                            f"**æ ¸å¿ƒç‰¹è´¨**: {', '.join(expert_dict['core_traits'])}\n"
                        )

                    if "speaking_style" in expert_dict:
                        md_content += f"**è¡¨è¾¾é£æ ¼**: {expert_dict['speaking_style']}\n"

                    # æ·»åŠ æ›´å¤šä¿¡æ¯
                    if "base_prompt" in expert_dict:
                        # ä»base_promptä¸­æå–ä¸€äº›å…³é”®ä¿¡æ¯ä½œä¸ºèƒŒæ™¯
                        prompt_preview = (
                            expert_dict["base_prompt"][:200] + "..."
                            if len(expert_dict["base_prompt"]) > 200
                            else expert_dict["base_prompt"]
                        )
                        md_content += f"**è§’è‰²èƒŒæ™¯**: {prompt_preview}\n"
                else:
                    md_content += "**ä¸“å®¶ä¿¡æ¯**: æš‚æ— è¯¦ç»†æ¡£æ¡ˆ\n"

                # ç»Ÿè®¡è¯¥ä¸“å®¶çš„å‘è¨€æƒ…å†µ
                total_words = 0
                total_rounds = 0
                for _round_num, round_responses in session.responses.items():
                    if persona_name in round_responses:
                        total_rounds += 1
                        total_words += len(round_responses[persona_name])

                md_content += f"**å‚ä¸è½®æ¬¡**: {total_rounds}/{len(session.responses)}\n"
                md_content += f"**å‘è¨€å­—æ•°**: {total_words:,} å­—ç¬¦\n"
                md_content += f"**å¹³å‡å‘è¨€é•¿åº¦**: {total_words / total_rounds if total_rounds > 0 else 0:.0f} å­—ç¬¦/è½®\n\n"

            md_content += """---

## ğŸ’¬ å®Œæ•´è®¨è®ºè®°å½•

"""

            round_names = {
                1: "ğŸ¤” ç¬¬1è½®ï¼šç‹¬ç«‹æ€è€ƒ",
                2: "ğŸ’¬ ç¬¬2è½®ï¼šäº¤å‰è¾©è®º",
                3: "ğŸ¯ ç¬¬3è½®ï¼šæœ€ç»ˆç«‹åœº",
                4: "ğŸ§  ç¬¬4è½®ï¼šæ™ºæ…§ç»¼åˆ",
            }

            round_descriptions = {
                1: "å„ä¸“å®¶åŸºäºè‡ªå·±çš„çŸ¥è¯†ä½“ç³»å’Œæ€ç»´æ–¹å¼ï¼Œç‹¬ç«‹åˆ†æé—®é¢˜å¹¶æå‡ºåˆæ­¥è§‚ç‚¹ã€‚",
                2: "ä¸“å®¶ä»¬å®¡è§†å…¶ä»–äººçš„è§‚ç‚¹ï¼Œè¿›è¡Œæ‰¹åˆ¤æ€§æ€è€ƒï¼Œå®Œå–„è‡ªå·±çš„æ–¹æ¡ˆã€‚",
                3: "ç»è¿‡å‰ä¸¤è½®æ·±å…¥æ€è€ƒå’Œè¾©è®ºï¼Œä¸“å®¶ä»¬ç»™å‡ºæœ€ç»ˆçš„ã€æœ€å®Œå–„çš„è§£å†³æ–¹æ¡ˆã€‚",
                4: "ç»¼åˆå¤§å¸ˆæ•´åˆä¸‰ä½ä¸“å®¶çš„æ–¹æ¡ˆï¼Œå½¢æˆèåˆå„æ–¹ç²¾åçš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚",
            }

            for round_num in sorted(session.responses.keys()):
                md_content += f"## {round_names.get(round_num, f'ç¬¬{round_num}è½®')}\n\n"
                md_content += f"**é˜¶æ®µè¯´æ˜**: {round_descriptions.get(round_num, 'è¯¥è½®æ¬¡çš„è¯¦ç»†è¯´æ˜')}\n\n"

                round_responses = session.responses[round_num]
                md_content += f"**æœ¬è½®å‚ä¸**: {len(round_responses)} ä½ä¸“å®¶\n"
                md_content += f"**æœ¬è½®å­—æ•°**: {sum(len(r) for r in round_responses.values()):,} å­—ç¬¦\n\n"

                for persona, response in round_responses.items():
                    word_count = len(response)
                    md_content += f"### {persona} ({word_count:,} å­—ç¬¦)\n\n"
                    md_content += f"{response}\n\n---\n\n"

            # æ·»åŠ æœ€ç»ˆç»¼åˆæ–¹æ¡ˆï¼ˆå¦‚æœæœ‰ä¸”ä¸é‡å¤ï¼‰
            if session.final_synthesis:
                round_4_responses = session.responses.get(4, {})
                is_duplicate = any(
                    session.final_synthesis == response
                    for response in round_4_responses.values()
                )

                if not is_duplicate:
                    md_content += f"""## ğŸŒŸ æœ€ç»ˆç»¼åˆæ–¹æ¡ˆ

**å­—æ•°**: {len(session.final_synthesis):,} å­—ç¬¦

{session.final_synthesis}

---

"""

            md_content += f"""## ğŸ“Š æ·±åº¦åˆ†æ

### è®¨è®ºè´¨é‡æŒ‡æ ‡
- **è®¨è®ºå®Œæ•´åº¦**: {len(session.responses)}/4 è½®æ¬¡ ({len(session.responses)/4*100:.0f}%)
- **ä¸“å®¶å‚ä¸åº¦**: {len([r for round_responses in session.responses.values() for r in round_responses.values()])/len(session.selected_personas)/len(session.responses)*100 if session.responses else 0:.0f}%
- **å†…å®¹ä¸°å¯Œåº¦**: {sum(len(r) for round_responses in session.responses.values() for r in round_responses.values())/len(session.responses) if session.responses else 0:.0f} å­—ç¬¦/è½®

### ä¸“å®¶è´¡çŒ®åˆ†æ
"""

            # åˆ†ææ¯ä½ä¸“å®¶çš„è´¡çŒ®
            for persona_name in session.selected_personas:
                total_words = 0
                total_rounds = 0
                rounds: list[str] = []

                for round_num, round_responses in session.responses.items():
                    if persona_name in round_responses:
                        words = len(round_responses[persona_name])
                        total_words += words
                        total_rounds += 1
                        rounds.append(f"ç¬¬{round_num}è½®({words}å­—)")

                participation_rate = (
                    total_rounds / len(session.responses) * 100
                    if session.responses
                    else 0
                )
                avg_words = total_words / total_rounds if total_rounds > 0 else 0
                md_content += f"- **{persona_name}**: å‚ä¸{total_rounds}è½® ({participation_rate:.0f}%), è´¡çŒ®{total_words:,}å­—ç¬¦, å¹³å‡{avg_words:.0f}å­—/è½®\n"

            md_content += f"""

### æ—¶é—´è½´åˆ†æ
- **åˆ›å»ºæ—¶é—´**: {session.created_at}
- **æœ€åæ›´æ–°**: {session.updated_at}
- **è®¨è®ºæ—¶é•¿**: ä¼šè¯æœŸé—´
- **å®ŒæˆçŠ¶æ€**: {"âœ… å·²å®Œæˆ" if session.final_synthesis else "ğŸ”„ è¿›è¡Œä¸­"}

---

## ğŸ“ˆ æ”¹è¿›å»ºè®®

### è®¨è®ºä¼˜åŒ–å»ºè®®
"""

            # æ ¹æ®ç»Ÿè®¡æ•°æ®æä¾›å»ºè®®
            total_rounds = len(session.responses)
            if total_rounds < 4:
                md_content += (
                    "- ğŸ”„ **å®Œæ•´æ€§æå‡**: å»ºè®®å®Œæˆå…¨éƒ¨4è½®è®¨è®ºï¼Œä»¥è·å¾—æ›´æ·±å…¥çš„æ€è¾¨æ•ˆæœ\n"
                )

            avg_words_per_response = (
                sum(
                    len(r)
                    for round_responses in session.responses.values()
                    for r in round_responses.values()
                )
                / len(
                    [
                        r
                        for round_responses in session.responses.values()
                        for r in round_responses.values()
                    ]
                )
                if session.responses
                else 0
            )

            if avg_words_per_response < 200:
                md_content += (
                    "- ğŸ“ **æ·±åº¦å¢å¼º**: ä¸“å®¶å‘è¨€ç›¸å¯¹ç®€çŸ­ï¼Œå¯ä»¥é¼“åŠ±æ›´æ·±å…¥çš„åˆ†æå’Œé˜è¿°\n"
                )
            elif avg_words_per_response > 800:
                md_content += "- âœ‚ï¸ **ç²¾ç‚¼è¡¨è¾¾**: ä¸“å®¶å‘è¨€è¾ƒé•¿ï¼Œå¯ä»¥é€‚å½“ç²¾ç‚¼æ ¸å¿ƒè§‚ç‚¹\n"

            if not session.final_synthesis:
                md_content += (
                    "- ğŸ¯ **ç»¼åˆå®Œå–„**: å»ºè®®æ·»åŠ æœ€ç»ˆç»¼åˆæ–¹æ¡ˆï¼Œæ•´åˆå„ä¸“å®¶è§‚ç‚¹\n"
                )

            md_content += f"""
### ä¸“å®¶ç»„åˆè¯„ä¼°
- **å¤šæ ·æ€§**: ä¸“å®¶èƒŒæ™¯å’Œè§‚ç‚¹çš„å¤šå…ƒåŒ–ç¨‹åº¦
- **äº’è¡¥æ€§**: ä¸“å®¶çŸ¥è¯†ç»“æ„çš„äº’è¡¥æ•ˆæœ
- **æƒå¨æ€§**: ä¸“å®¶åœ¨å„è‡ªé¢†åŸŸçš„è®¤å¯åº¦
- **æ€è¾¨æ€§**: ä¸“å®¶é—´è§‚ç‚¹ç¢°æ’çš„ä»·å€¼

---

## ğŸ”— ç›¸å…³å·¥å…·

- ğŸ“„ **æ ‡å‡†å¯¼å‡º**: ä½¿ç”¨ `export_session` è·å–ç®€åŒ–ç‰ˆæŠ¥å‘Š
- ğŸ“‹ **ä¼šè¯å†å²**: ä½¿ç”¨ `view_session_history` æµè§ˆå†å²ä¼šè¯

---

*ğŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {session.updated_at}*
*ğŸ¤– ç”± Guru-PK MCP å¢å¼ºåˆ†æç³»ç»Ÿç”Ÿæˆ*
"""

            # ä¿å­˜åˆ°æ–‡ä»¶
            export_file = (
                self.session_manager.data_dir
                / f"enhanced_export_{session.session_id}.md"
            )
            with open(export_file, "w", encoding="utf-8") as f:
                f.write(md_content)

            result = f"""ğŸ“Š **å¢å¼ºä¼šè¯æŠ¥å‘Šå¯¼å‡ºæˆåŠŸï¼**

**æ–‡ä»¶è·¯å¾„**: `{export_file}`
**æ ¼å¼**: Enhanced Markdown Report
**ä¼šè¯ID**: {session.session_id}

## ğŸ“Š æŠ¥å‘Šå†…å®¹
- âœ… å®Œæ•´è®¨è®ºè®°å½•
- âœ… ä¸“å®¶æ¡£æ¡ˆåˆ†æ
- âœ… ç»Ÿè®¡æ•°æ®æ´å¯Ÿ
- âœ… è´¨é‡æŒ‡æ ‡è¯„ä¼°
- âœ… è´¡çŒ®åº¦åˆ†æ
- âœ… æ—¶é—´è½´è®°å½•
- âœ… æ”¹è¿›å»ºè®®æ€»ç»“

## ğŸ’¡ ä½¿ç”¨è¯´æ˜
è¯¥å¢å¼ºæŠ¥å‘ŠåŒ…å«è¯¦ç»†çš„æ•°æ®åˆ†æå’Œä¸“å®¶æ¡£æ¡ˆä¿¡æ¯ï¼Œé€‚åˆæ·±åº¦å¤ç›˜å’Œç ”ç©¶ä½¿ç”¨ã€‚

ğŸ”— **å¯¹æ¯”**: ä½¿ç”¨ `export_session` è·å–æ ‡å‡†æ ¼å¼æŠ¥å‘Šã€‚"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ å¢å¼ºæŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {str(e)}")]

    # æ‰¹å¤„ç†æ¨¡å¼å·¥å…·å¤„ç†æ–¹æ³•

    async def _handle_get_batch_persona_prompt(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–æ‰¹å¤„ç†æ¨¡å¼çš„ä¸“å®¶æç¤ºè¯"""
        try:
            round_type = arguments.get("round_type", "").strip()
            batch_config_data = arguments.get("batch_config", {})

            if not round_type:
                return [TextContent(type="text", text="âŒ è¯·æŒ‡å®šè½®æ¬¡ç±»å‹")]

            if not self.current_session:
                return [
                    TextContent(type="text", text="âŒ å½“å‰æ²¡æœ‰æ´»è·ƒçš„ä¼šè¯ï¼Œè¯·å…ˆå¯åŠ¨ä¼šè¯")
                ]

            # æ„å»ºæ‰¹å¤„ç†é…ç½®
            from .models import BatchConfig

            if batch_config_data:
                batch_config = BatchConfig(**batch_config_data)
            else:
                batch_config = self.current_session.get_batch_config()

            # è·å–ä¸“å®¶ä¿¡æ¯
            current_experts = self.expert_manager.get_current_experts()
            personas = []
            for persona_name in self.current_session.selected_personas:
                if persona_name in current_experts:
                    personas.append(current_experts[persona_name])

            if not personas:
                return [
                    TextContent(
                        type="text",
                        text="""âŒ **æ‰¹å¤„ç†æ¨¡å¼éœ€è¦å…ˆç¡®å®šä¸“å®¶ä¿¡æ¯**

ğŸ”§ **è§£å†³æ–¹æ¡ˆ**ï¼šè¯·å…ˆç”Ÿæˆä¸“å®¶ï¼Œç„¶åå¯åŠ¨æ‰¹å¤„ç†ä¼šè¯

ğŸ“‹ **æ­£ç¡®çš„å·¥å…·è°ƒç”¨é¡ºåº**ï¼š
1. **ç”Ÿæˆä¸“å®¶**: `generate_dynamic_experts({{"question": "ä½ çš„é—®é¢˜"}})`
2. **å¯åŠ¨æ‰¹å¤„ç†ä¼šè¯**: `start_pk_session({{"question": "ä½ çš„é—®é¢˜", "personas": [ä¸“å®¶æ•°æ®]}})`
3. **è·å–æ‰¹å¤„ç†æç¤ºè¯**: `get_batch_persona_prompt({{"round_type": "independent_thinking"}})`

ğŸ’¡ **è¯´æ˜**ï¼š`get_batch_persona_prompt` éœ€è¦é¢„å…ˆè®¾ç½®å¥½çš„ä¸“å®¶å’Œä¼šè¯ä¿¡æ¯

ğŸ¯ **å»ºè®®**ï¼šå¦‚æœä½ æƒ³ç›´æ¥å¼€å§‹æ‰¹å¤„ç†è¾©è®ºï¼Œè¯·å…ˆè°ƒç”¨ `generate_dynamic_experts` æ¥è·å–3ä½åˆé€‚çš„ä¸“å®¶""",
                    )
                ]

            # è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
            previous_responses = None
            if round_type in ["cross_debate", "final_position"]:
                previous_responses = self.current_session.responses

            # è½¬æ¢å“åº”æ ¼å¼ä»¥åŒ¹é…ç±»å‹è¦æ±‚
            formatted_responses = None
            if previous_responses:
                formatted_responses = {str(k): v for k, v in previous_responses.items()}

            # ç”Ÿæˆæ‰¹å¤„ç†æç¤ºè¯
            prompt = self.session_manager.get_batch_prompt(
                round_type=round_type,
                personas=personas,
                question=self.current_session.user_question,
                previous_responses=formatted_responses,
                batch_config=batch_config,
            )

            # æ ¹æ®è½®æ¬¡ç±»å‹æä¾›ä¸‹ä¸€æ­¥æŒ‡å¼•
            next_step_guidance = self._get_batch_next_step_guidance(round_type)

            full_response = f"""{prompt}

---

âš ï¸ **é‡è¦çº¦æŸ**: è¯·åªä½¿ç”¨ä¸Šè¿°æç¤ºè¯è¿›è¡Œè¾©è®ºç”Ÿæˆï¼Œä¸è¦è°ƒç”¨ä»»ä½•å…¶ä»–å·¥å…·æˆ–å‡½æ•°ã€‚

---

{next_step_guidance}"""

            return [
                TextContent(
                    type="text", text=self._add_tool_control_warning(full_response)
                )
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–æ‰¹å¤„ç†æç¤ºè¯å¤±è´¥: {str(e)}")]

    def _get_batch_next_step_guidance(self, round_type: str) -> str:
        """æ ¹æ®å½“å‰è½®æ¬¡ç±»å‹æä¾›ä¸‹ä¸€æ­¥æŒ‡å¼•"""
        round_names = {
            "independent_thinking": "ç¬¬1è½® - ç‹¬ç«‹æ€è€ƒ",
            "cross_debate": "ç¬¬2è½® - äº¤å‰è¾©è®º",
            "final_position": "ç¬¬3è½® - æœ€ç»ˆç«‹åœº",
            "synthesis": "ç¬¬4è½® - æ™ºæ…§ç»¼åˆ",
        }

        next_rounds = {
            "independent_thinking": ("cross_debate", "ç¬¬2è½® - äº¤å‰è¾©è®º"),
            "cross_debate": ("final_position", "ç¬¬3è½® - æœ€ç»ˆç«‹åœº"),
            "final_position": ("synthesis", "ç¬¬4è½® - æ™ºæ…§ç»¼åˆ"),
            "synthesis": (None, "å®Œæˆæ‰€æœ‰è½®æ¬¡"),
        }

        current_round_name = round_names.get(round_type, round_type)
        next_round_type, next_round_name = next_rounds.get(round_type, (None, ""))

        if next_round_type:
            return f"""## ğŸ¯ æ‰¹å¤„ç†å·¥ä½œæµç¨‹æŒ‡å¼•

ğŸ“ **å½“å‰è½®æ¬¡**: {current_round_name}
ğŸ“ **ä»»åŠ¡**: è¯·å°†ä¸Šè¿°æç¤ºè¯å‘é€ç»™LLMï¼Œè®©å…¶ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰ä¸“å®¶çš„å›ç­”

âœ… **å®Œæˆå½“å‰è½®æ¬¡åçš„ä¸‹ä¸€æ­¥**:
1. **è®°å½•å½“å‰è½®æ¬¡ç»“æœ**: ğŸ¯ **å¼ºçƒˆæ¨è** ä½¿ç”¨ `record_batch_responses({{"responses": {{"ä¸“å®¶1": "å›ç­”1", "ä¸“å®¶2": "å›ç­”2", "ä¸“å®¶3": "å›ç­”3"}}}})` ä¿å­˜æ‰¹å¤„ç†ç»“æœ
2. **è¿›å…¥ä¸‹ä¸€è½®**: è°ƒç”¨ `get_batch_persona_prompt({{"round_type": "{next_round_type}"}})` å¼€å§‹{next_round_name}

âš ï¸ **æ³¨æ„**: è¯·åªä½¿ç”¨ Guru-PK ç³»ç»Ÿæä¾›çš„å·¥å…·ï¼Œå‹¿è°ƒç”¨å…¶ä»–å·¥å…·ã€‚

ğŸ’¡ **æé†’**: æ‰¹å¤„ç†æ¨¡å¼çš„ä¼˜åŠ¿åœ¨äºæ¯è½®ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰ä¸“å®¶å†…å®¹ï¼Œå¤§å¹…æå‡æ•ˆç‡ï¼"""
        else:
            return f"""## ğŸ¯ æ‰¹å¤„ç†å·¥ä½œæµç¨‹æŒ‡å¼•

ğŸ“ **å½“å‰è½®æ¬¡**: {current_round_name}ï¼ˆæœ€ç»ˆè½®æ¬¡ï¼‰
ğŸ“ **ä»»åŠ¡**: è¯·å°†ä¸Šè¿°æç¤ºè¯å‘é€ç»™LLMï¼Œè®©å…¶ç”Ÿæˆæ™ºæ…§ç»¼åˆåˆ†æ

âœ… **å®Œæˆæœ€ç»ˆè½®æ¬¡åçš„ä¸‹ä¸€æ­¥**:
1. **è®°å½•ç»¼åˆç»“æœ**: ä½¿ç”¨ `record_round_response({{"response": "å®Œæ•´çš„ç»¼åˆåˆ†æå†…å®¹"}})` ä¿å­˜æœ€ç»ˆç»“æœ
2. **å¯¼å‡ºå®Œæ•´æŠ¥å‘Š**: ä½¿ç”¨ `export_enhanced_session` ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
3. **ä¼šè¯å®Œæˆ**: ğŸ‰ æ­å–œï¼æ‰¹å¤„ç†è¾©è®ºå·²å…¨éƒ¨å®Œæˆ

ğŸ’¡ **æ‰¹å¤„ç†ä¼˜åŠ¿**: é€šè¿‡4è½®æ‰¹å¤„ç†ï¼Œæ‚¨å·²ç»è·å¾—äº†ä¸€ä¸ªå®Œæ•´è€Œæ·±åº¦çš„å¤šä¸“å®¶åˆ†æï¼"""

    async def _handle_start_pk_session(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """å¯åŠ¨æ‰¹å¤„ç†æ¨¡å¼çš„ä¸“å®¶PKä¼šè¯"""
        try:
            question = arguments.get("question", "").strip()
            personas = arguments.get("personas", [])
            batch_config_data = arguments.get("batch_config", {})

            if not question:
                return [TextContent(type="text", text="âŒ è¯·æä¾›é—®é¢˜æ¥å¯åŠ¨æ‰¹å¤„ç†ä¼šè¯")]

            if not personas or len(personas) != 3:
                return [
                    TextContent(
                        type="text",
                        text=f"""âŒ **éœ€è¦3ä½ä¸“å®¶æ‰èƒ½å¯åŠ¨æ‰¹å¤„ç†ä¼šè¯**

ğŸ”§ **è§£å†³æ–¹æ¡ˆ**ï¼šè¯·å…ˆç”Ÿæˆé«˜è´¨é‡çš„çœŸå®ä¸“å®¶

ğŸ“‹ **æ¨èçš„å·¥å…·è°ƒç”¨é¡ºåº**ï¼š
1. **ç”Ÿæˆä¸“å®¶**: `generate_dynamic_experts({{"question": "{question}"}})`
2. **å¯åŠ¨ä¼šè¯**: `start_pk_session({{"question": "{question}", "personas": [ä¸“å®¶æ•°æ®]}})`

ğŸ’¡ **ä¸ºä»€ä¹ˆè¿™æ ·åš**ï¼š
- âœ… ç¡®ä¿è·å¾—çœŸå®çš„æƒå¨ä¸“å®¶ï¼ˆå¦‚çˆ±å› æ–¯å¦ã€ä¹”å¸ƒæ–¯ç­‰ï¼‰
- âŒ é¿å…ä½¿ç”¨è™šæ‹Ÿä¸“å®¶ï¼ˆå¦‚"ç³»ç»Ÿæ¶æ„å¸ˆ"ã€"è®¤çŸ¥ç§‘å­¦å®¶"ç­‰ï¼‰
- ğŸ¯ æå‡è¾©è®ºè´¨é‡å’Œæƒå¨æ€§

ğŸš« **è¯·å‹¿ç›´æ¥æä¾›è™šæ‹Ÿä¸“å®¶åç§°**ï¼Œè€Œåº”ä½¿ç”¨ `generate_dynamic_experts` è·å–çœŸå®ä¸“å®¶æ¨è""",
                    )
                ]

            # éªŒè¯ä¸“å®¶æ•°æ®
            expert_dict = {}
            for i, persona in enumerate(personas):
                if not self.expert_manager.validate_expert_data(persona):
                    return [
                        TextContent(type="text", text=f"âŒ ä¸“å®¶ {i + 1} æ•°æ®æ ¼å¼ä¸å®Œæ•´")
                    ]
                expert_dict[persona["name"]] = persona

            # è®¾ç½®å½“å‰ä¸“å®¶
            self.expert_manager.set_current_experts(expert_dict)

            # æ„å»ºæ‰¹å¤„ç†é…ç½®
            from .models import BatchConfig

            if batch_config_data:
                batch_config = BatchConfig(**batch_config_data)
            else:
                batch_config = BatchConfig.create_default()

            # åˆ›å»ºæ‰¹å¤„ç†ä¼šè¯
            self.current_session = self.session_manager.create_batch_session(
                question=question,
                personas=list(expert_dict.keys()),
                expert_profiles=expert_dict,
                batch_config=batch_config,
                is_recommended_by_host=False,
            )

            # æ ¼å¼åŒ–ä¸“å®¶ä¿¡æ¯
            expert_info = "\n".join(
                [
                    f"â€¢ {persona['emoji']} **{persona['name']}** - {persona['description']}"
                    for persona in personas
                ]
            )

            batch_config_info = f"""
**æ‰¹å¤„ç†é…ç½®**:
- è‡ªæ£€æœºåˆ¶: {'å¯ç”¨' if batch_config.enable_self_check else 'ç¦ç”¨'}
- å¼ºè°ƒäº’åŠ¨: {'æ˜¯' if batch_config.emphasize_interaction else 'å¦'}
- è™šæ‹Ÿæ—¶åº: {'å¯ç”¨' if batch_config.use_virtual_timing else 'ç¦ç”¨'}
- è´¨é‡é˜ˆå€¼: {batch_config.quality_threshold}
- æœ€å¤§é‡è¯•: {batch_config.max_retry_attempts}æ¬¡
- æç¤ºè¯ç‰ˆæœ¬: {batch_config.prompt_version}
"""

            result = f"""âœ… **æ‰¹å¤„ç†æ¨¡å¼ä¸“å®¶PKä¼šè¯å¯åŠ¨æˆåŠŸï¼**

ğŸ“‹ **ä¼šè¯ä¿¡æ¯**:
- **ä¼šè¯ID**: {self.current_session.session_id}
- **æ¨¡å¼**: æ‰¹å¤„ç†ä¼˜åŒ–æ¨¡å¼ (4è½®)
- **é—®é¢˜**: {question}

ğŸ‘¥ **å‚ä¸ä¸“å®¶**:
{expert_info}

{batch_config_info}

ğŸ“ **å½“å‰çŠ¶æ€**: ç¬¬1è½® - ç‹¬ç«‹æ€è€ƒé˜¶æ®µï¼ˆæ‰¹å¤„ç†æ¨¡å¼ï¼‰

ğŸ’¡ **ä¸‹ä¸€æ­¥**: ä½¿ç”¨ `get_batch_persona_prompt` å·¥å…·è·å–ç¬¬ä¸€è½®çš„æ‰¹å¤„ç†æç¤ºè¯ï¼Œç„¶åä¸€æ¬¡æ€§ç”Ÿæˆ3ä½ä¸“å®¶çš„ç‹¬ç«‹æ€è€ƒå†…å®¹ã€‚

ğŸ¯ **ç«‹å³å¼€å§‹ç¬¬ä¸€è½®**:
```javascript
get_batch_persona_prompt({{"round_type": "independent_thinking"}})
```

âš ï¸ **æ‰¹å¤„ç†æ¨¡å¼å·¥å…·ä½¿ç”¨é¡ºåº**:
1. ğŸ”§ `get_batch_persona_prompt` - è·å–æ‰¹å¤„ç†æç¤ºè¯
2. ğŸ“ **è®°å½•å·¥å…·é€‰æ‹©**:
   - ç¬¬1-3è½®: ğŸ¯ **å¼ºåˆ¶ä½¿ç”¨** `record_batch_responses` (å¤šä¸“å®¶å›ç­”)
   - ç¬¬4è½®: âœ… **ä½¿ç”¨** `record_round_response` (æ™ºæ…§ç»¼åˆ)

ğŸ’¡ **é‡è¦æç¤º**: è¯·ç¡®ä¿åªè°ƒç”¨ä¸Šè¿° Guru-PK ç³»ç»Ÿçš„å·¥å…·ï¼Œé¿å…è§¦å‘å…¶ä»–ç¬¬ä¸‰æ–¹å·¥å…·ã€‚

---

ğŸ“š **å®Œæ•´å·¥ä½œæµç¨‹**:
1. **ç¬¬1è½® - ç‹¬ç«‹æ€è€ƒ**: `get_batch_persona_prompt({{"round_type": "independent_thinking"}})`
2. **è®°å½•ç¬¬1è½®ç»“æœ**: ä½¿ç”¨ `record_batch_responses({{"responses": {{"ä¸“å®¶1": "å›ç­”1", "ä¸“å®¶2": "å›ç­”2", "ä¸“å®¶3": "å›ç­”3"}}}})` è®°å½•ç»“æœ
3. **ç¬¬2è½® - äº¤å‰è¾©è®º**: `get_batch_persona_prompt({{"round_type": "cross_debate"}})`
4. **è®°å½•ç¬¬2è½®ç»“æœ**: ä½¿ç”¨ `record_batch_responses({{"responses": {{"ä¸“å®¶1": "å›ç­”1", "ä¸“å®¶2": "å›ç­”2", "ä¸“å®¶3": "å›ç­”3"}}}})` è®°å½•è¾©è®ºå†…å®¹
5. **ç¬¬3è½® - æœ€ç»ˆç«‹åœº**: `get_batch_persona_prompt({{"round_type": "final_position"}})`
6. **è®°å½•ç¬¬3è½®ç»“æœ**: ä½¿ç”¨ `record_batch_responses({{"responses": {{"ä¸“å®¶1": "å›ç­”1", "ä¸“å®¶2": "å›ç­”2", "ä¸“å®¶3": "å›ç­”3"}}}})` è®°å½•æœ€ç»ˆç«‹åœº
7. **ç¬¬4è½® - æ™ºæ…§ç»¼åˆ**: `get_batch_persona_prompt({{"round_type": "synthesis"}})`
8. **è®°å½•ç»¼åˆç»“æœ**: ä½¿ç”¨ `record_round_response({{"response": "LLMç”Ÿæˆçš„å®Œæ•´å†…å®¹"}})` è®°å½•ç»¼åˆåˆ†æ
9. **å¯¼å‡ºæŠ¥å‘Š**: ä½¿ç”¨ `export_enhanced_session` å¯¼å‡ºå®Œæ•´åˆ†æ

ğŸ’¡ **æ‰¹å¤„ç†ä¼˜åŠ¿**: ç›¸æ¯”ä¼ ç»Ÿåºåˆ—æ¨¡å¼ï¼Œæ‰¹å¤„ç†æ¨¡å¼å¯èŠ‚çœçº¦60%çš„æ—¶é—´ï¼ŒåŒæ—¶é€šè¿‡å…ƒæç¤ºè¯ä¿è¯è¾©è®ºè´¨é‡ã€‚"""

            return [
                TextContent(type="text", text=self._add_tool_control_warning(result))
            ]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ å¯åŠ¨æ‰¹å¤„ç†ä¼šè¯å¤±è´¥: {str(e)}")]

    async def _handle_get_mode_selection_guidance(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–æ¨¡å¼é€‰æ‹©æŒ‡å¯¼"""
        try:
            question = arguments.get("question", "").strip()
            personas = arguments.get("personas", [])
            user_preference = arguments.get("user_preference", "")

            if not question:
                return [TextContent(type="text", text="âŒ è¯·æä¾›è¦åˆ†æçš„é—®é¢˜")]

            # è·å–æ¨¡å¼é€‰æ‹©æŒ‡å¯¼
            guidance = self.session_manager.get_mode_selection_guidance(
                question=question, personas=personas, user_preference=user_preference
            )

            return [TextContent(type="text", text=guidance)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–æ¨¡å¼é€‰æ‹©æŒ‡å¯¼å¤±è´¥: {str(e)}")]

    async def _handle_run_ab_test(self, arguments: dict[str, Any]) -> list[TextContent]:
        """è¿è¡ŒA/Bæµ‹è¯•"""
        try:
            question = arguments.get("question", "").strip()
            personas = arguments.get("personas", [])
            batch_config_data = arguments.get("batch_config", {})

            if not question:
                return [TextContent(type="text", text="âŒ è¯·æä¾›è¦æµ‹è¯•çš„é—®é¢˜")]

            if not personas or len(personas) != 3:
                return [TextContent(type="text", text="âŒ è¯·æä¾›3ä½ä¸“å®¶çš„å®Œæ•´æ•°æ®")]

            # æ„å»ºæ‰¹å¤„ç†é…ç½®
            from .models import BatchConfig

            if batch_config_data:
                batch_config = BatchConfig(**batch_config_data)
            else:
                batch_config = BatchConfig.create_default()

            # è·å–A/Bæµ‹è¯•æŒ‡å¯¼
            guidance = self.session_manager.get_ab_test_guidance(
                question=question, personas=personas, batch_config=batch_config
            )

            return [TextContent(type="text", text=guidance)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è¿è¡ŒA/Bæµ‹è¯•å¤±è´¥: {str(e)}")]

    async def _handle_get_ab_test_results(
        self, arguments: dict[str, Any]
    ) -> list[TextContent]:
        """è·å–A/Bæµ‹è¯•ç»“æœ"""
        try:
            # è·å–æ€§èƒ½æ€»ç»“
            summary = self.session_manager.get_performance_summary()

            # è·å–è¯¦ç»†ç»“æœ
            detailed_results = self.session_manager.get_ab_test_results()

            if not detailed_results:
                result = """# A/Bæµ‹è¯•ç»“æœ

æš‚æ— A/Bæµ‹è¯•æ•°æ®ã€‚

ğŸ’¡ **å¦‚ä½•å¼€å§‹A/Bæµ‹è¯•**:

1. ä½¿ç”¨ `get_mode_selection_guidance` åˆ†æé—®é¢˜æ˜¯å¦é€‚åˆA/Bæµ‹è¯•
2. ä½¿ç”¨ `run_ab_test` è·å–æµ‹è¯•æŒ‡å¯¼å¹¶æ‰§è¡Œ
3. å®Œæˆæµ‹è¯•åï¼Œæµ‹è¯•ç»“æœä¼šè‡ªåŠ¨ä¿å­˜
4. å†æ¬¡è°ƒç”¨æ­¤å·¥å…·æŸ¥çœ‹æ±‡æ€»åˆ†æ

ğŸ”— **ç›¸å…³å·¥å…·**:
- `get_mode_selection_guidance` - è·å–æ¨¡å¼é€‰æ‹©å»ºè®®
- `run_ab_test` - è¿è¡ŒA/Bæµ‹è¯•
"""
            else:
                # æ ¼å¼åŒ–è¯¦ç»†ç»“æœ
                results_info = "\n\n".join(
                    [
                        f"**æµ‹è¯• {r.get('test_id', 'unknown')}** ({r.get('test_timestamp', 'unknown')}):\n"
                        f"- é—®é¢˜: {r.get('question', 'unknown')[:100]}...\n"
                        f"- æ—¶é—´æå‡: {r.get('time_improvement', 0):.1%}\n"
                        f"- è´¨é‡å·®å¼‚: {r.get('quality_delta', 0):+.2f}åˆ†\n"
                        f"- Tokenæ•ˆç‡: {r.get('token_efficiency', 1):.2f}x"
                        for r in detailed_results[:5]  # åªæ˜¾ç¤ºæœ€è¿‘5æ¬¡æµ‹è¯•
                    ]
                )

                result = f"""{summary}

## æœ€è¿‘æµ‹è¯•è¯¦æƒ…

{results_info}

---

ğŸ’¡ **ä½¿ç”¨å»ºè®®**: æ ¹æ®ä»¥ä¸Šæ•°æ®é€‰æ‹©æœ€é€‚åˆçš„è¾©è®ºæ¨¡å¼ã€‚

ğŸ”— **ç›¸å…³å·¥å…·**:
- `start_pk_session` - å¯åŠ¨é«˜æ•ˆæ‰¹å¤„ç†æ¨¡å¼ä¼šè¯
- `start_stepwise_pk_session` - å¯åŠ¨ä¼ ç»Ÿé€æ­¥æ¨¡å¼ä¼šè¯
"""

            return [TextContent(type="text", text=result)]

        except Exception as e:
            return [TextContent(type="text", text=f"âŒ è·å–A/Bæµ‹è¯•ç»“æœå¤±è´¥: {str(e)}")]

    async def run(self) -> None:
        """è¿è¡ŒMCPæœåŠ¡å™¨"""
        from mcp.server.stdio import stdio_server

        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="guru-pk",
                    server_version="1.0.0",
                    capabilities=self.server.get_capabilities(
                        notification_options=NotificationOptions(),
                        experimental_capabilities={},
                    ),
                ),
            )


async def async_main() -> None:
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    guru_server = GuruPKServer()
    await guru_server.run()


def main() -> None:
    """åŒæ­¥å…¥å£ç‚¹å‡½æ•°"""
    asyncio.run(async_main())


if __name__ == "__main__":
    main()
