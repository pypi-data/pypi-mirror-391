"""æç¤ºè¯å¢å¼ºæ¨¡å— - ç¡®ä¿AIä½¿ç”¨çœŸå®æ•°æ®è€Œéç”Ÿæˆç¤ºä¾‹"""


class PromptEnhancer:
    """æç¤ºè¯å¢å¼ºå™¨ï¼Œç”¨äºæ”¹è¿›AIå¯¹çœŸå®æ•°æ®çš„å¤„ç†"""
    
    @staticmethod
    def enhance_for_real_data(base_prompt: str, context_data: str = None) -> str:
        """
        å¢å¼ºæç¤ºè¯ï¼Œç¡®ä¿AIä½¿ç”¨çœŸå®æ•°æ®
        
        Args:
            base_prompt: åŸºç¡€æç¤ºè¯
            context_data: ä¸Šä¸‹æ–‡æ•°æ®å†…å®¹
            
        Returns:
            å¢å¼ºåçš„æç¤ºè¯
        """
        if not context_data:
            return base_prompt
            
        # åˆ†ææ•°æ®ç±»å‹
        data_type = PromptEnhancer._analyze_data_type(context_data)
        
        # æ ¹æ®æ•°æ®ç±»å‹ç”Ÿæˆç‰¹å®šçš„æŒ‡ä»¤
        specific_instructions = PromptEnhancer._get_specific_instructions(data_type, context_data)
        
        enhanced = f"""
{base_prompt}

ã€ğŸ”´ æå…¶é‡è¦çš„æ•°æ®ä½¿ç”¨è§„åˆ™ ğŸ”´ã€‘
=====================================
ä»¥ä¸‹æ˜¯å¿…é¡»ä¸¥æ ¼éµå®ˆçš„æ•°æ®ä½¿ç”¨è§„åˆ™ï¼š

1. ã€æ•°æ®æ¥æºã€‘ä¸‹é¢æä¾›çš„æ˜¯çœŸå®çš„ä¸šåŠ¡æ•°æ®ï¼Œä¸æ˜¯ç¤ºä¾‹æˆ–æ¨¡æ¿
2. ã€ä½¿ç”¨è¦æ±‚ã€‘å¿…é¡»100%ä½¿ç”¨è¿™äº›æ•°æ®ï¼Œä¸å¾—ä¿®æ”¹ã€çœç•¥æˆ–è™šæ„
3. ã€ç¦æ­¢è¡Œä¸ºã€‘ä¸¥ç¦ç”Ÿæˆä»¥ä¸‹è™šæ„å†…å®¹ï¼š
   - âŒ è™šæ„çš„å®¢æˆ·è¯„ä»·ï¼ˆå¦‚"è®¾è®¡è´¨æ„Ÿä¸è½¬åŒ–ç‡æå‡æ˜æ˜¾"ï¼‰
   - âŒ è™šæ„çš„å®šä»·æ–¹æ¡ˆï¼ˆå¦‚"Â¥9,999èµ·æ­¥å¥—é¤"ï¼‰
   - âŒ è™šæ„çš„æœåŠ¡å†…å®¹ï¼ˆå¦‚"å“ç‰Œå‡çº§ä¸é‡æ„"ï¼‰
   - âŒ å ä½ç¬¦å†…å®¹ï¼ˆå¦‚"Lorem ipsum"æˆ–"ç¤ºä¾‹æ–‡æœ¬"ï¼‰
   
4. ã€æ­£ç¡®åšæ³•ã€‘ï¼š
   - âœ… å®Œæ•´å±•ç¤ºæ‰€æœ‰æä¾›çš„æ•°æ®é¡¹
   - âœ… ä¿æŒæ•°æ®çš„åŸå§‹æ ¼å¼å’Œå†…å®¹
   - âœ… ä½¿ç”¨åˆé€‚çš„å¸ƒå±€å±•ç¤ºï¼ˆå¡ç‰‡ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰
   - âœ… å¯ä»¥æ·»åŠ å¯¼èˆªã€æ ·å¼ï¼Œä½†å†…å®¹å¿…é¡»æ˜¯æä¾›çš„çœŸå®æ•°æ®

ã€å¿…é¡»ä½¿ç”¨çš„çœŸå®æ•°æ®ã€‘
=====================================
{context_data}
=====================================

{specific_instructions}

ã€å·¥å…·è°ƒç”¨è¦æ±‚ã€‘
=====================================
åœ¨è°ƒç”¨ä»¥ä¸‹å·¥å…·æ—¶ï¼Œå¿…é¡»åŒ…å«çœŸå®æ•°æ®ï¼š
- create_html_file: contentå‚æ•°å¿…é¡»åŒ…å«ä¸Šè¿°çœŸå®æ•°æ®
- add_content_section: å¿…é¡»ä½¿ç”¨çœŸå®æ•°æ®å¡«å……å†…å®¹
- create_text_content: æ–‡æœ¬å†…å®¹å¿…é¡»æ¥è‡ªä¸Šè¿°æ•°æ®
- add_hero_section: æ ‡é¢˜å’Œæè¿°è¦åæ˜ çœŸå®ä¸šåŠ¡
- create_card_grid: å¡ç‰‡å†…å®¹å¿…é¡»æ˜¯çœŸå®æ•°æ®é¡¹

ã€éªŒè¯è¦æ±‚ã€‘
=====================================
ç”Ÿæˆçš„æ¯ä¸ªHTMLæ–‡ä»¶éƒ½å¿…é¡»åŒ…å«ï¼š
1. å®Œæ•´çš„æ•°æ®åˆ—è¡¨ï¼ˆä¸å¾—é—æ¼ä»»ä½•ä¸€é¡¹ï¼‰
2. å‡†ç¡®çš„åç§°å’Œåœ°å€ä¿¡æ¯
3. æ­£ç¡®çš„æ•°æ®å±•ç¤ºæ ¼å¼

è®°ä½ï¼šè¿™æ˜¯ä¸€ä¸ªæ•°æ®å±•ç¤ºä»»åŠ¡ï¼Œä¸æ˜¯åˆ›æ„å†™ä½œä»»åŠ¡ï¼
"""
        return enhanced
    
    @staticmethod
    def _analyze_data_type(context_data: str) -> str:
        """
        åˆ†ææ•°æ®ç±»å‹
        
        Args:
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            æ•°æ®ç±»å‹æ ‡è¯†
        """
        lower_data = context_data.lower()
        
        # æ£€æµ‹ä¸åŒç±»å‹çš„æ•°æ®
        if "å’–å•¡" in context_data or "coffee" in lower_data or "åº—" in context_data:
            if "åœ°å€" in context_data or "address" in lower_data:
                return "store_list"
                
        if "äº§å“" in context_data or "product" in lower_data:
            return "product_list"
            
        if "èœå•" in context_data or "menu" in lower_data:
            return "menu_list"
            
        if "ä»·æ ¼" in context_data or "price" in lower_data:
            return "pricing_list"
            
        if "è”ç³»" in context_data or "contact" in lower_data:
            return "contact_info"
            
        return "general_list"
    
    @staticmethod
    def _get_specific_instructions(data_type: str, context_data: str) -> str:
        """
        æ ¹æ®æ•°æ®ç±»å‹ç”Ÿæˆç‰¹å®šæŒ‡ä»¤
        
        Args:
            data_type: æ•°æ®ç±»å‹
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            ç‰¹å®šçš„æŒ‡ä»¤
        """
        # è®¡ç®—æ•°æ®é¡¹æ•°é‡
        item_count = context_data.count('\n1.') + context_data.count('\n2.') + \
                     context_data.count('\n3.') + context_data.count('\n-')
        
        if data_type == "store_list":
            return f"""
ã€é’ˆå¯¹åº—é“ºåˆ—è¡¨çš„ç‰¹å®šè¦æ±‚ã€‘
- å¿…é¡»å±•ç¤ºæ‰€æœ‰{item_count}ä¸ªåº—é“º
- æ¯ä¸ªåº—é“ºå¿…é¡»åŒ…å«ï¼šåç§°ã€åœ°å€
- ä½¿ç”¨å¡ç‰‡å¸ƒå±€ï¼Œæ¯è¡Œ2-3ä¸ª
- å¯ä»¥æ·»åŠ åœ°å›¾é“¾æ¥æŒ‰é’®
- å¯ä»¥æŒ‰åŒºåŸŸæˆ–å“ç‰Œåˆ†ç»„å±•ç¤º
"""
        
        elif data_type == "product_list":
            return f"""
ã€é’ˆå¯¹äº§å“åˆ—è¡¨çš„ç‰¹å®šè¦æ±‚ã€‘
- å¿…é¡»å±•ç¤ºæ‰€æœ‰äº§å“ä¿¡æ¯
- ä¿æŒåŸå§‹çš„äº§å“åç§°å’Œæè¿°
- ä½¿ç”¨äº§å“å¡ç‰‡æˆ–å±•ç¤ºç½‘æ ¼
- å¯ä»¥æ·»åŠ äº§å“å›¾ç‰‡å ä½ç¬¦
"""
        
        elif data_type == "menu_list":
            return f"""
ã€é’ˆå¯¹èœå•çš„ç‰¹å®šè¦æ±‚ã€‘
- å¿…é¡»å±•ç¤ºå®Œæ•´èœå•
- ä¿æŒåŸå§‹çš„èœå“åç§°å’Œä»·æ ¼
- å¯ä»¥æŒ‰ç±»åˆ«åˆ†ç»„
- ä½¿ç”¨æ¸…æ™°çš„è¡¨æ ¼æˆ–åˆ—è¡¨æ ¼å¼
"""
        
        else:
            return f"""
ã€é€šç”¨æ•°æ®å±•ç¤ºè¦æ±‚ã€‘
- å¿…é¡»å±•ç¤ºæ‰€æœ‰æ•°æ®é¡¹ï¼ˆå…±çº¦{item_count}é¡¹ï¼‰
- ä¿æŒæ•°æ®çš„åŸå§‹æ ¼å¼
- ä½¿ç”¨é€‚åˆçš„å¸ƒå±€å±•ç¤º
- ä¸å¾—æ·»åŠ è™šæ„å†…å®¹
"""
    
    @staticmethod
    def validate_content_usage(generated_content: str, original_data: str) -> dict:
        """
        éªŒè¯ç”Ÿæˆçš„å†…å®¹æ˜¯å¦æ­£ç¡®ä½¿ç”¨äº†åŸå§‹æ•°æ®
        
        Args:
            generated_content: ç”Ÿæˆçš„å†…å®¹
            original_data: åŸå§‹æ•°æ®
            
        Returns:
            éªŒè¯ç»“æœ
        """
        # æå–åŸå§‹æ•°æ®ä¸­çš„å…³é”®é¡¹
        key_items = []
        lines = original_data.split('\n')
        for line in lines:
            line = line.strip()
            # æå–åº—åæˆ–å…³é”®ä¿¡æ¯
            if '. ' in line and line[0].isdigit():
                item = line.split('. ', 1)[1] if '. ' in line else line
                if '(' in item:
                    item = item.split('(')[0].strip()
                key_items.append(item)
            elif '- åœ°å€ï¼š' in line:
                address = line.replace('- åœ°å€ï¼š', '').strip()
                key_items.append(address)
        
        # æ£€æŸ¥æ¯ä¸ªå…³é”®é¡¹æ˜¯å¦åœ¨ç”Ÿæˆçš„å†…å®¹ä¸­
        missing_items = []
        found_items = []
        
        for item in key_items:
            if item in generated_content:
                found_items.append(item)
            else:
                missing_items.append(item)
        
        # æ£€æµ‹è™šæ„å†…å®¹çš„ç‰¹å¾
        fake_content_patterns = [
            "è½¬åŒ–ç‡æå‡",
            "å“ç‰Œå½¢è±¡",
            "Â¥9,999",
            "Â¥29,999",
            "Â¥59,999",
            "èµ·æ­¥å¥—é¤",
            "ä¸“ä¸šå¥—é¤",
            "æ——èˆ°å¥—é¤",
            "Alex Chen",
            "Liang Wu",
            "Yvonne Zhao",
            "è®¾è®¡è´¨æ„Ÿ",
            "äº¤ä»˜è´¨é‡",
            "Lorem ipsum",
            "ç¤ºä¾‹æ–‡æœ¬"
        ]
        
        detected_fake = [pattern for pattern in fake_content_patterns 
                        if pattern in generated_content]
        
        return {
            "valid": len(missing_items) == 0 and len(detected_fake) == 0,
            "found_items": found_items,
            "missing_items": missing_items,
            "detected_fake_content": detected_fake,
            "coverage_rate": len(found_items) / len(key_items) if key_items else 0,
            "has_fake_content": len(detected_fake) > 0
        }


# å¯¼å‡ºä¾¿æ·å‡½æ•°
def enhance_prompt_for_real_data(prompt: str, context: str = None) -> str:
    """å¢å¼ºæç¤ºè¯ä»¥ä½¿ç”¨çœŸå®æ•°æ®"""
    enhancer = PromptEnhancer()
    return enhancer.enhance_for_real_data(prompt, context)


def validate_data_usage(content: str, original: str) -> dict:
    """éªŒè¯æ•°æ®ä½¿ç”¨æƒ…å†µ"""
    enhancer = PromptEnhancer()
    return enhancer.validate_content_usage(content, original)