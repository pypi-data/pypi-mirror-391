# Promptron LLM Configuration
# Copy this file to .env and update with your settings
# Or create an LLMConfig class and read from .env in your code

# LLM Provider (currently only 'ollama' is supported)
PROMPTRON_PROVIDER=ollama

# Model name (for Ollama: e.g., llama3:latest, llama3.2:latest)
PROMPTRON_MODEL=llama3:latest

# Ollama base URL
PROMPTRON_BASE_URL=http://localhost:11434

# Future providers will support:
# PROMPTRON_API_KEY=your_api_key_here  # For OpenAI, Anthropic, etc.
