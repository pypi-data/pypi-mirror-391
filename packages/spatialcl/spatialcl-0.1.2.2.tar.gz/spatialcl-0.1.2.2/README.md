## ğŸ§­ Overview

**SpatialCL** is a *plug-and-play contrastive learning framework* designed for spatially structured modalities, including **RGB**, **thermal**, **RGB-D** data etc.
It robustly handles *intra-* and *inter-class variability*, enabling consistent embeddings across challenging datasets.

ğŸ§ª As a demonstration of its capabilities, **SpatialCL** has been applied in **[DiSCO ğŸ”—](https://github.com/Olemou/SpatialCL)** â€” *Detection of Spills in Indoor environments using weakly supervised contrastive learning* â€” showcasing its practical impact in real-world spill detection scenarios.

âš™ï¸ While the framework is **modality-agnostic** and can be extended to other dense spatial tasks, extending **SpatialCL** to sparse, graph-structured data such as **skeletons** represents an exciting direction for future work.

## Framework Architecture
  <p align="center">
  <img src="assets/framework/framework.png" alt="SpatialCL Architecture" width="850"/>
</p>

**figure 1:** *Through the encoder, feature embeddings are extracted to obtain zij , which are subsequently normalized*. *From these embeddings, the cohesion*
*score cij is computed, representing how likely samples xi and xj remain compact within the same* *co-cluster. A binomial opinion is modeled as a Beta*
*probability density function (PDF), under the assumption of a bijective mapping between both representations. The uncertainty uij is then computed to*
*measure the confidence that xi and xj can be close within a cluster, enabling the model to avoid forcing samples of the same class together despite strong*
*visual differences. To ensure stable and gradual learning, a curriculum function  is introduced to guide progressive training and to*
*compute the adaptive weight wij , addressing intra-class variability. For inter-class modeling, the parameter Î² is computed as described in the schema above*,
*allowing the model to focus on hard negatives and enhance class separation. All these components are integrated into the final loss function Lij .*

## ğŸ¯ Why DISCO Submodule of SpatialCL?
DISCO (Detection of Indoor Spills with Contrastive learning) addresses one of the most persistent challenges in computer vision: uncertainty under weak supervision. Traditional vision systems are typically designed and optimized for perception tasks involving rigid, well-structured objects with distinct geometric cues. However, these systems often fail when faced with visually ambiguous targets such as indoor liquid spills, whose irregular shapes, diffuse boundaries, and variable textures defy conventional object representations.

- âœ¨ *The difficulty arises from several intertwined factors:*
- âœ¨ *The absence of clear contours or well-defined shapes;*
- âœ¨ *Extreme intra-class variability in appearance and scale;*
- âœ¨ *Weak or inconsistent edge and texture cues;*
- âœ¨ *Frequent occlusion and foregroundâ€“background blending;*
- âœ¨ *A scarcity of reliable labeled examples; and*
- âœ¨ *environmental disturbances such as illumination changes, surface reflections, and sensor noise*.

## Key Features
- âœ… Handles **ambiguous and irregular objects** that standard vision models struggle with
- âœ… Supports: **RGB, thermal, depth, etc.**
- âœ… **Memory-optimized** contrastive learning for faster training
- âœ… Produces **highly discriminative embeddings** for downstream tasks
- âœ… Handles **class imbalance**
- âœ… Easy integration into existing PyTorch pipelines

## ğŸ“¦Installation

# ğŸ… Local Environment Setup

- ***1ï¸âƒ£*** <b>Clone the repository</b>
<div align="left" style="margin-left:10%; height:30%;">
<pre>
<code>
git clone https://github.com/Olemou/SpatialCL.git
cd SpatialCL
</code>
</pre>
</div>
<!-- Setup Python virtual environment -->

- ***2ï¸âƒ£*** <b>Setup a Python Virtual Environment (optional):</b>
<div align="left" style="margin-left:10%;">
<pre>
<code>

 ***1. Create virtual environment***
     python -m venv venv
***2. Activate the virtual environment***

***On Linux/macOS***
source venv/bin/activate

***On Windows (PowerShell)***
venv\Scripts\Activate.ps1

***On Windows (CMD)***
venv\Scripts\activate.bat
</code>
</pre>
</div>

 - ***3ï¸âƒ£*** <b>Install dependencie:</b>
<div align="left" style="max-width:50%; margin-left:10%;">
<pre>
<code class="language-python">
pip install --upgrade pip
pip install -r requirements.txt
</code>
</pre>
</div>

 - ***4ï¸âƒ£*** <b>Install local package in editable mode:</b>
<div align="left" style="max-width:50%; margin-left:10%;">
<pre>
<code class="language-python">
pip install -e .
</code>
</pre>
</div>

# ğŸ…‘ Usage of SpatialCL 

-  ### 1ï¸âƒ£ PypI Installation ###
<div align="left" style="margin-left:10%; height:30%;">
<pre>
<code>
pip install -i https://test.pypi.org/simple/ spatialcl
</code>
</pre>
</div>
*After installing SpatialCL via ***pip***, you can leverage its comprehensive functionalities.*

- ### 2ï¸âƒ£ Thermal Augmentation
Let's suppose the image is loaded and readable.

- <b>ğŸ§© Occlusion </b>
<div align="left" style="max-width:50%; margin-left:10%;">
<pre>
<code class="language-python">
     from Spatialcl.thermal import occlusion
     aug_img = occlusion( img=image,mask_width_ratio=0.6,mask_height_ratio=0.2,max_attempts=5)
</code>
</pre>
</div>

- <b>ğŸ›ï¸ Contrast </b>
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
     from Spatialcl.thermal import contrast
     aug_img = contrast(img = image, alpha = 0.8)
</code>
</pre>
</div>

- <b>â˜€ï¸ Mixed Brightness & Contrast<b>
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
     from Spatialcl.thermal import brightness_contrast
     aug_img = brightness_contrast(mg = image,brightness = 1, contrast = 0.6)
</code>
</pre>
</div>

- <b>ğŸŒ€ Elastic Transfrormation </b>
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
     from Spatialcl.thermal import elastic
     aug_img = elastic(img = image,alpha = 1, sigma = 0.8)
</code>
</pre>
</div>

### ğŸš€ Compute Learning Mechanism

- ***ğŸ”¸ uncertainty weight under weak supervision***
 *We computed uncertainty weights for  intra-class variability and class imbalance handling*
 <div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
from Spatialcl.uncertainty import co_cluster_uncertainty
z = torch.randn(4, 8)
img_id = torch.tensor([0, 1, 2, 3]) (img_id: augmented views of same image ids)
labels = torch.tensor([0, 1, 0, 1])
prior_weight = 2
uncertainy = co_cluster_uncertainty(z, labels, img_id)
</code>
</pre>
</div>

- ***ğŸ”¸Curriculum learning mechanism***
 *The initially computed uncertainty weights are dynamically reweighted to guide the model through a progressive learning process, allowing it to first focus on easier examples and gradually incorporate harder, more ambiguous cases.*
 <div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
from Spatialcl.uncertainty import compute_weights_from_uncertainty
progressive_reweighting = compute_weights_from_uncertainty( 
     uncertainty=uncertainty_matrix, epoch=0 ,
     T = 100)
</code>
</pre>
</div>

- ***ğŸ”¸Global Loss function in the learning process***
In this part, we compute the global learning mechanism in a single step, without intermediate stages. This approach simultaneously addresses challenges such as class imbalance, intra-class variability, and low inter-class similarity. It allows multiple modalities thermal, RGB, and RGB-D etc. to capture and reason about uncertainty effectively. By applying this mechanism to the spill dataset, which encompasses the full complexity of the data, the model is exposed to realistic challenges, highlighting the difficulties described earlier.
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
from Spatialcl.uncertainty import build_uwcl
img_id = torch.tensor([0, 1, 2, 1])
label = torch.tensor([0, 1, 0, 1])
z = torch.randn(4, 8)
output = build_uwcl(z=z, img_ids=img_id, labels=label, epoch=0, device="cpu")
</code>
</pre>
</div>

# ğŸ…’ Training & Evalidation (DISCO)

### ğŸ¯ Single-GPU (Non-Distributed) Training
***root: stands for your data folder path*** 
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
python train.py --batch_size 32 --num_workers 4 --root ./data --vit_variant base --temperatue 0.1 --num_epochs 50 ---dataset_class None --modality '{"rgb": False,"thermal": True}'
</code>
</pre>
</div>

### ğŸ¯ Distributed Training One Node
***root: stands for your data folder path*** 
<div align="left" style="margin-left:10%;">
<pre>
<code class="language-python">
torchrun \
 --nnodes=1 \
  --nproc_per_node= 1 \
  --master_addr="127.0.0.1" \
  --master_port=29500 \
  train.py \
  --is_distributed \
  --batch_size 32
  --root ./data \ 
  --vit_variant base \ 
  --temperatue 0.1 \ 
  --num_epochs 50 \
  ---dataset_class None \
  --modality '{"rgb": False,"thermal": True}'
</code>
</pre>
</div>

# ğŸ…“ Results (DISCO)
### 1ï¸âƒ£ <b> Pretrained customize Vit-base </b>
<table>
  <tr>
    <!-- Column 1 -->
    <td>
      <h3 align="center">ğŸ§  Pretrained Customized ViT-Base</h3>
    </td>
    <td style="text-align: center;">
      <a href="https://github.com/Olemou/SpatialCL/releases/tag/SpatialCl_(DISCO)" download>
        <button style="padding: 10px 20px; font-size: 16px; cursor: pointer;">
          Download Weights
        </button>
      </a>
    </td>
  </tr>
</table>

### 2ï¸âƒ£  <b> Downstream Task</b>
<table align="center">
  <tr>
    <td align="center"><b>Classification Metrics</b></td>
  </tr>
  <tr>
    <td align="center"><img src="assets/disco/disco.png" alt="Hot Water" width="800"/></td>
  </tr>
</table>


# ğŸ…” Visualization (DISCO)
### 1ï¸âƒ£ <b> Original vs Attention-Map </b>
<table align="center">
  <tr>
    <td align="center"><b>Hot Water</b></td>
    <td align="center"><b>Last Block</b></td>
    <td align="center"><b>Attention Rollout</b></td>
  </tr>
  <tr>
    <td align="center"><img src="assets/disco/hot_water.png" alt="Hot Water" width="300"/></td>
    <td align="center"><img src="assets/disco/hot_last_block.png" alt="Last Block" width="250"/></td>
    <td align="center"><img src="assets/disco/hot_attention_rollout.png" alt="Attention Rollout" width="250"/></td>
  </tr>
</table>

# ğŸ…• Beyond DISCO / SpatialCL applied to Anomaly Detection 
## key  features
- âœ… Handle  **class level variability** for downstream tasks
- âœ… Handles **class imbalance**
- <h3>âœ… Dataset</h3>
    <p>
      <a href="https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads" target="_blank" style="text-decoration:none;">
        <span style="
          display:inline-block;
          background-color:#0078D7;
          color:white;
          padding:10px 20px;
          border-radius:8px;
          font-size:16px;
          font-weight:bold;
          cursor:pointer;">
          â¬‡ï¸ Download MVTec AD Dataset
        </span>
      </a>
    </p>

  
  ### 1ï¸âƒ£ <b>Anomaly detection in wood construction materials</b>
  - <b> Original Vs Attention-Map</b>
<table align="center">
  <tr>
    <th align="center">Original</th>
    <th align="center">Last Block Attn</th>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/wood/color.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/wood/color_attn.png" width="200"></td>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/wood/combine.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/wood/combine_attn.png" width="200"></td>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/wood/hole.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/wood/hole_attn.png" width="200"></td>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/wood/scratch.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/wood/scratch_attn.png" width="200"></td>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/wood/water.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/wood/floor_attn.png" width="200"></td>
  </tr>
</table>

 ### 2ï¸âƒ£ <b> Transistor (electronic)</b>
   - <b> Original Vs Attention-Map</b>
<table align="center">
  <tr>
    <th align="center">Original</th>
    <th align="center">Last Block Attn</th>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/transitor/original_damage.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/transitor/attn_damage.png" width="200"></td>
  </tr>

  <tr>
    <td align="center"><img src="assets/anomaly/transitor/bend_original.png" width="200"></td>
    <td align="center"><img src="assets/anomaly/transitor/bend_attn.png" width="200"></td>
  </tr>

</table>
  


