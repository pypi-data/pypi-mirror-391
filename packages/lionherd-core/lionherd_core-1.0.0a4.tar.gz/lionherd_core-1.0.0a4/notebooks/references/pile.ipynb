{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pile - Thread-Safe Typed Collection\n",
    "\n",
    "**Pile** is lionherd's foundational collection for managing Element instances with:\n",
    "- **Thread safety**: RLock-based synchronization\n",
    "- **Type validation**: Flexible constraints with Union support\n",
    "- **Rich queries**: Type-dispatched `__getitem__` interface\n",
    "- **Progression order**: Insertion order preserved\n",
    "\n",
    "This notebook demonstrates core patterns for working with Pile collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from lionherd_core.base import Element, Pile, Progression\n",
    "\n",
    "\n",
    "# Create test elements\n",
    "class Task(Element):\n",
    "    \"\"\"Simple task element.\"\"\"\n",
    "\n",
    "    title: str = \"Untitled\"\n",
    "    priority: int = 0\n",
    "\n",
    "\n",
    "class Event(Element):\n",
    "    \"\"\"Event element.\"\"\"\n",
    "\n",
    "    event_type: str = \"info\"\n",
    "    severity: int = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construction with Type Validation\n",
    "\n",
    "Pile supports flexible type constraints:\n",
    "- **No constraint** (default): Any Element subclass\n",
    "- **Single type**: Enforce specific Element type\n",
    "- **Union types**: Multi-type collections\n",
    "- **Strict mode**: Exact type match (no subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed pile: 2 items\n",
      "Task pile: 1 items\n",
      "Union pile: 2 items, types: {<class '__main__.Event'>, <class '__main__.Task'>}\n"
     ]
    }
   ],
   "source": [
    "# No type constraint - accepts any Element subclass\n",
    "pile_any = Pile()\n",
    "pile_any.add(Task(title=\"Review PR\", priority=1))\n",
    "pile_any.add(Event(event_type=\"alert\", severity=3))\n",
    "print(f\"Mixed pile: {len(pile_any)} items\")\n",
    "\n",
    "# Single type constraint\n",
    "tasks = Pile(item_type=Task)\n",
    "tasks.add(Task(title=\"Write tests\", priority=2))\n",
    "# tasks.add(Event(...))  # Would raise TypeError\n",
    "print(f\"Task pile: {len(tasks)} items\")\n",
    "\n",
    "# Union type - multiple allowed types\n",
    "pile_union = Pile(item_type=Union[Task, Event])\n",
    "pile_union.add(Task(title=\"Deploy\", priority=3))\n",
    "pile_union.add(Event(event_type=\"success\", severity=1))\n",
    "print(f\"Union pile: {len(pile_union)} items, types: {pile_union.item_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Operations: Add, Remove, Get\n",
    "\n",
    "Basic CRUD operations with type safety and thread-safety guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 items\n",
      "Retrieved: Implement feature\n",
      "Contains task1: True\n",
      "Contains task2: True\n",
      "Removed: Implement feature\n",
      "Remaining: 1 items\n",
      "Included (was new): True\n",
      "Included again (idempotent): False\n"
     ]
    }
   ],
   "source": [
    "pile = Pile()\n",
    "\n",
    "# Add items\n",
    "task1 = Task(title=\"Implement feature\", priority=2)\n",
    "task2 = Task(title=\"Fix bug\", priority=3)\n",
    "pile.add(task1)\n",
    "pile.add(task2)\n",
    "print(f\"Added {len(pile)} items\")\n",
    "\n",
    "# Get by UUID\n",
    "retrieved = pile.get(task1.id)\n",
    "print(f\"Retrieved: {retrieved.title}\")\n",
    "\n",
    "# Check membership\n",
    "print(f\"Contains task1: {task1.id in pile}\")\n",
    "print(f\"Contains task2: {task2 in pile}\")\n",
    "\n",
    "# Remove item\n",
    "removed = pile.remove(task1.id)\n",
    "print(f\"Removed: {removed.title}\")\n",
    "print(f\"Remaining: {len(pile)} items\")\n",
    "\n",
    "# Include/exclude (idempotent set operations)\n",
    "added = pile.include(task1)  # Add if not present\n",
    "print(f\"Included (was new): {added}\")\n",
    "added_again = pile.include(task1)  # No-op if present\n",
    "print(f\"Included again (idempotent): {added_again}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rich Query Interface: Type-Dispatched `__getitem__`\n",
    "\n",
    "Pile's `__getitem__` supports multiple query modes:\n",
    "- **UUID/str**: Get single item by ID\n",
    "- **int**: Get by index (progression order)\n",
    "- **slice**: Get multiple items\n",
    "- **callable**: Filter by predicate (returns new Pile)\n",
    "- **Progression**: Filter by custom order (returns new Pile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By UUID: Task A\n",
      "By index - First: Task A, Last: Task E\n",
      "By slice: ['Task B', 'Task C']\n",
      "High priority tasks: 2 items\n",
      "  - Task B (priority=3)\n",
      "  - Task D (priority=3)\n",
      "\n",
      "By progression: 2 items\n",
      "  - Task B\n",
      "  - Task D\n"
     ]
    }
   ],
   "source": [
    "# Create pile with tasks\n",
    "tasks = Pile(\n",
    "    [\n",
    "        Task(title=\"Task A\", priority=1),\n",
    "        Task(title=\"Task B\", priority=3),\n",
    "        Task(title=\"Task C\", priority=2),\n",
    "        Task(title=\"Task D\", priority=3),\n",
    "        Task(title=\"Task E\", priority=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query by UUID\n",
    "task = tasks[next(iter(tasks.keys()))]\n",
    "print(f\"By UUID: {task.title}\")\n",
    "\n",
    "# Query by index\n",
    "first = tasks[0]\n",
    "last = tasks[-1]\n",
    "print(f\"By index - First: {first.title}, Last: {last.title}\")\n",
    "\n",
    "# Query by slice (returns list)\n",
    "middle = tasks[1:3]\n",
    "print(f\"By slice: {[t.title for t in middle]}\")\n",
    "\n",
    "# Query by callable (returns new Pile)\n",
    "high_priority = tasks[lambda t: t.priority >= 3]\n",
    "print(f\"High priority tasks: {len(high_priority)} items\")\n",
    "for task in high_priority:\n",
    "    print(f\"  - {task.title} (priority={task.priority})\")\n",
    "\n",
    "# Query by Progression (custom order)\n",
    "custom_order = [tasks[1].id, tasks[3].id]  # Select specific items\n",
    "prog = Progression(order=custom_order)\n",
    "filtered = tasks[prog]\n",
    "print(f\"\\nBy progression: {len(filtered)} items\")\n",
    "for task in filtered:\n",
    "    print(f\"  - {task.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Iteration and Collection Methods\n",
    "\n",
    "Pile provides Python collection protocols for natural iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:\n",
      "  Task 1\n",
      "  Task 2\n",
      "  Task 3\n",
      "\n",
      "UUIDs: [UUID('a8bc8a5e-6c52-4bdd-a979-399640e1381f'), UUID('e155f455-bdad-41d6-a13e-e1507f492217')]...\n",
      "Values: ['Task 1', 'Task 2', 'Task 3']\n",
      "As list: 3 items\n",
      "\n",
      "Len: 3\n",
      "Size: 3\n",
      "Empty: False\n"
     ]
    }
   ],
   "source": [
    "tasks = Pile(\n",
    "    [\n",
    "        Task(title=\"Task 1\", priority=1),\n",
    "        Task(title=\"Task 2\", priority=2),\n",
    "        Task(title=\"Task 3\", priority=3),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Iterate (progression order)\n",
    "print(\"Iteration:\")\n",
    "for task in tasks:\n",
    "    print(f\"  {task.title}\")\n",
    "\n",
    "# Keys (UUIDs)\n",
    "print(f\"\\nUUIDs: {list(tasks.keys())[:2]}...\")  # Show first 2\n",
    "\n",
    "# Values (items)\n",
    "print(f\"Values: {[t.title for t in tasks.values()]}\")\n",
    "\n",
    "# List conversion\n",
    "tasks_list = tasks.to_list()\n",
    "print(f\"As list: {len(tasks_list)} items\")\n",
    "\n",
    "# Size checks\n",
    "print(f\"\\nLen: {len(tasks)}\")\n",
    "print(f\"Size: {tasks.size()}\")\n",
    "print(f\"Empty: {tasks.is_empty()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concurrency: Thread Safety and Async\n",
    "\n",
    "Pile supports both synchronous multi-threading and asynchronous operations:\n",
    "- **Thread safety**: RLock synchronization for concurrent threads\n",
    "- **Async operations**: Separate async lock for coroutine-based concurrency\n",
    "\n",
    "### Synchronous Multi-Threading\n",
    "\n",
    "Thread-safe operations using Python's threading module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items after concurrent adds: 50\n",
      "All items added successfully without race conditions\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# Create pile for concurrent access\n",
    "pile_sync = Pile()\n",
    "\n",
    "\n",
    "# Worker function that adds items\n",
    "def worker(worker_id):\n",
    "    for i in range(5):\n",
    "        task = Task(title=f\"Worker-{worker_id} Task-{i}\", priority=worker_id)\n",
    "        pile_sync.add(task)\n",
    "\n",
    "\n",
    "# Spawn 10 threads concurrently adding items\n",
    "threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]\n",
    "\n",
    "# Start all threads\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"Total items after concurrent adds: {len(pile_sync)}\")  # 50 (thread-safe)\n",
    "print(\"All items added successfully without race conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Operations\n",
    "\n",
    "Async operations use a separate async lock for coroutine-based concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items after concurrent adds: 50\n",
      "Sample tasks: ['Task from worker 1-0', 'Task from worker 1-1', 'Task from worker 1-2']\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# Create pile for concurrent access\n",
    "pile = Pile()\n",
    "\n",
    "\n",
    "# Worker function that adds items\n",
    "def worker(worker_id):\n",
    "    for i in range(5):\n",
    "        task = Task(title=f\"Task from worker {worker_id}-{i}\", priority=worker_id)\n",
    "        pile.add(task)\n",
    "\n",
    "\n",
    "# Spawn 10 threads concurrently adding items\n",
    "threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]\n",
    "\n",
    "# Start all threads\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"Total items after concurrent adds: {len(pile)}\")  # 50 (thread-safe)\n",
    "print(f\"Sample tasks: {[pile[i].title for i in range(3)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 items concurrently\n",
      "Retrieved: ['Task 0', 'Task 1', 'Task 2']\n",
      "Inside context: 5 items\n",
      "Final pile size: 5\n"
     ]
    }
   ],
   "source": [
    "from lionherd_core.libs.concurrency import gather\n",
    "\n",
    "\n",
    "async def demo_async():\n",
    "    pile = Pile()\n",
    "\n",
    "    # Create tasks\n",
    "    tasks = [Task(title=f\"Task {i}\", priority=i) for i in range(5)]\n",
    "\n",
    "    # Concurrent add operations\n",
    "    await gather(*[pile.add_async(task) for task in tasks])\n",
    "    print(f\"Added {len(pile)} items concurrently\")\n",
    "\n",
    "    # Concurrent get operations\n",
    "    results = await gather(*[pile.get_async(task.id) for task in tasks[:3]])\n",
    "    print(f\"Retrieved: {[r.title for r in results]}\")\n",
    "\n",
    "    # Async context manager (manual lock control)\n",
    "    async with pile as p:\n",
    "        # Lock held during context\n",
    "        print(f\"Inside context: {len(p._items)} items\")\n",
    "\n",
    "    return pile\n",
    "\n",
    "\n",
    "# Run async demo\n",
    "pile = await demo_async()\n",
    "print(f\"Final pile size: {len(pile)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Serialization: to_dict / from_dict\n",
    "\n",
    "Pile preserves progression order and type constraints through serialization.\n",
    "\n",
    "**Modes**:\n",
    "- `python`: Python objects (UUID, datetime)\n",
    "- `json`: JSON-safe strings\n",
    "- `db`: Database column naming (metadata → node_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized data:\n",
      "  ID (str): f91264db...\n",
      "  Items: 2\n",
      "  Item type: ['__main__.Task']\n",
      "  Strict: False\n",
      "\n",
      "Restored:\n",
      "  Length: 2\n",
      "  Type constraint: {<class '__main__.Task'>}\n",
      "  Strict mode: False\n",
      "  Tasks: ['Task A', 'Task B']\n",
      "\n",
      "Round-trip checks:\n",
      "  Length preserved: True\n",
      "  Type constraint preserved: True\n",
      "  Order preserved: True\n"
     ]
    }
   ],
   "source": [
    "# Create pile with type constraint\n",
    "original = Pile(\n",
    "    items=[Task(title=\"Task A\", priority=1), Task(title=\"Task B\", priority=2)],\n",
    "    item_type=Task,\n",
    "    strict_type=False,\n",
    ")\n",
    "\n",
    "# Serialize to JSON mode\n",
    "data = original.to_dict(mode=\"json\")\n",
    "print(\"Serialized data:\")\n",
    "print(f\"  ID (str): {data['id'][:8]}...\")\n",
    "print(f\"  Items: {len(data['items'])}\")\n",
    "print(f\"  Item type: {data['item_type']}\")\n",
    "print(f\"  Strict: {data['strict_type']}\")\n",
    "\n",
    "# Deserialize\n",
    "restored = Pile.from_dict(data)\n",
    "print(\"\\nRestored:\")\n",
    "print(f\"  Length: {len(restored)}\")\n",
    "print(f\"  Type constraint: {restored.item_type}\")\n",
    "print(f\"  Strict mode: {restored.strict_type}\")\n",
    "print(f\"  Tasks: {[t.title for t in restored]}\")\n",
    "\n",
    "# Verify round-trip preservation\n",
    "print(\"\\nRound-trip checks:\")\n",
    "print(f\"  Length preserved: {len(original) == len(restored)}\")\n",
    "print(f\"  Type constraint preserved: {original.item_type == restored.item_type}\")\n",
    "print(f\"  Order preserved: {[t.title for t in original] == [t.title for t in restored]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Type Filtering and Validation\n",
    "\n",
    "Filter heterogeneous collections by type and control validation strictness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "Learn from common mistakes when working with Pile collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitfall 1: Mutating Read-Only Properties\n",
      "\n",
      "  ❌ Error: 'mappingproxy' object does not support item assign...\n",
      "  ❌ progression.append() modified copy (original len: 1, still 1)\n",
      "  ✓ Used pile.add() correctly (now 2 items)\n",
      "\n",
      "Pitfall 2: Type Validation with Subclasses\n",
      "\n",
      "  ⚠️  Default mode allowed subclass (strict_type=False)\n",
      "  ✓ strict_type=True correctly rejected subclass\n",
      "\n",
      "Pitfall 3: Concurrent include() Not Atomic\n",
      "\n",
      "  ⚠️  Without external lock: 1 thread(s) reported 'added'\n",
      "     (Race condition possible - check-then-act not atomic)\n",
      "  ✓ With external lock: exactly 1 thread reported 'added' (atomic)\n"
     ]
    }
   ],
   "source": [
    "# Pitfall 1: Attempting to mutate read-only properties\n",
    "print(\"Pitfall 1: Mutating Read-Only Properties\\n\")\n",
    "\n",
    "pile_test = Pile()\n",
    "task = Task(title=\"Test task\", priority=1)\n",
    "pile_test.add(task)\n",
    "\n",
    "# ❌ WRONG: Try to modify items directly\n",
    "try:\n",
    "    pile_test.items[task.id] = task  # MappingProxyType is read-only\n",
    "    print(\"  ❌ Modified items directly (should have failed)\")\n",
    "except TypeError as e:\n",
    "    print(f\"  ❌ Error: {str(e)[:50]}...\")\n",
    "\n",
    "# ❌ WRONG: Try to modify progression directly\n",
    "original_len = len(pile_test._progression.order)\n",
    "pile_test.progression.append(task.id)  # Modifies copy, not original\n",
    "print(\n",
    "    f\"  ❌ progression.append() modified copy (original len: {original_len}, still {len(pile_test._progression.order)})\"\n",
    ")\n",
    "\n",
    "# ✓ CORRECT: Use Pile methods\n",
    "pile_test.add(Task(title=\"Another task\", priority=2))\n",
    "print(f\"  ✓ Used pile.add() correctly (now {len(pile_test)} items)\\n\")\n",
    "\n",
    "\n",
    "# Pitfall 2: Type validation confusion with subclasses\n",
    "print(\"Pitfall 2: Type Validation with Subclasses\\n\")\n",
    "\n",
    "\n",
    "class UrgentTask(Task):\n",
    "    urgent: bool = True\n",
    "\n",
    "\n",
    "# ❌ POTENTIAL ISSUE: Default allows subclasses\n",
    "permissive_pile = Pile(item_type=Task)  # strict_type=False by default\n",
    "permissive_pile.add(UrgentTask(title=\"Urgent\", urgent=True))\n",
    "print(\"  ⚠️  Default mode allowed subclass (strict_type=False)\")\n",
    "\n",
    "# ✓ CORRECT: Use strict_type=True for exact type matching\n",
    "strict_pile = Pile(item_type=Task, strict_type=True)\n",
    "strict_pile.add(Task(title=\"Normal task\"))\n",
    "try:\n",
    "    strict_pile.add(UrgentTask(title=\"Urgent\", urgent=True))\n",
    "    print(\"  ❌ strict_type=True should have rejected subclass\")\n",
    "except TypeError:\n",
    "    print(\"  ✓ strict_type=True correctly rejected subclass\\n\")\n",
    "\n",
    "\n",
    "# Pitfall 3: Concurrent include() not atomic (check-then-act race)\n",
    "print(\"Pitfall 3: Concurrent include() Not Atomic\\n\")\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "race_pile = Pile()\n",
    "shared_task = Task(title=\"Shared task\", priority=1)\n",
    "results = []\n",
    "\n",
    "\n",
    "def try_include(worker_id):\n",
    "    time.sleep(0.001)  # Small delay to increase race window\n",
    "    result = race_pile.include(shared_task)\n",
    "    results.append((worker_id, result))\n",
    "\n",
    "\n",
    "# ❌ POTENTIAL RACE: Both threads might see \"not present\" and add\n",
    "results.clear()\n",
    "threads = [threading.Thread(target=try_include, args=(i,)) for i in range(2)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"  ⚠️  Without external lock: {len([r for r in results if r[1]])} thread(s) reported 'added'\")\n",
    "print(\"     (Race condition possible - check-then-act not atomic)\")\n",
    "\n",
    "# ✓ CORRECT: Use external lock for concurrent include/exclude\n",
    "protected_pile = Pile()\n",
    "lock = threading.Lock()\n",
    "results.clear()\n",
    "\n",
    "\n",
    "def safe_include(worker_id):\n",
    "    with lock:\n",
    "        result = protected_pile.include(shared_task)\n",
    "    results.append((worker_id, result))\n",
    "\n",
    "\n",
    "threads = [threading.Thread(target=safe_include, args=(i,)) for i in range(2)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"  ✓ With external lock: exactly 1 thread reported 'added' (atomic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed pile: 4 items\n",
      "\n",
      "Filtered by type:\n",
      "  Tasks: 2 items\n",
      "    - Task 1\n",
      "    - Task 2\n",
      "  Events: 2 items\n",
      "    - warning\n",
      "    - error\n",
      "\n",
      "Permissive pile: 2 items (allows subclasses)\n",
      "Strict pile rejected subclass: Item type <class '__main__.HighPriorityTask'> not ...\n"
     ]
    }
   ],
   "source": [
    "# Create mixed pile\n",
    "mixed = Pile(item_type={Task, Event})\n",
    "mixed.add(Task(title=\"Task 1\", priority=1))\n",
    "mixed.add(Event(event_type=\"warning\", severity=2))\n",
    "mixed.add(Task(title=\"Task 2\", priority=3))\n",
    "mixed.add(Event(event_type=\"error\", severity=3))\n",
    "\n",
    "print(f\"Mixed pile: {len(mixed)} items\")\n",
    "\n",
    "# Filter by type (returns new Pile)\n",
    "tasks_only = mixed.filter_by_type(Task)\n",
    "events_only = mixed.filter_by_type(Event)\n",
    "\n",
    "print(\"\\nFiltered by type:\")\n",
    "print(f\"  Tasks: {len(tasks_only)} items\")\n",
    "for task in tasks_only:\n",
    "    print(f\"    - {task.title}\")\n",
    "\n",
    "print(f\"  Events: {len(events_only)} items\")\n",
    "for event in events_only:\n",
    "    print(f\"    - {event.event_type}\")\n",
    "\n",
    "\n",
    "# Strict vs permissive validation\n",
    "class HighPriorityTask(Task):\n",
    "    \"\"\"Task subclass.\"\"\"\n",
    "\n",
    "    urgent: bool = True\n",
    "\n",
    "\n",
    "# Permissive mode (allows subclasses)\n",
    "permissive = Pile(item_type=Task, strict_type=False)\n",
    "permissive.add(Task(title=\"Normal task\"))\n",
    "permissive.add(HighPriorityTask(title=\"Urgent task\"))  # Subclass allowed\n",
    "print(f\"\\nPermissive pile: {len(permissive)} items (allows subclasses)\")\n",
    "\n",
    "# Strict mode (exact type only)\n",
    "strict = Pile(item_type=Task, strict_type=True)\n",
    "strict.add(Task(title=\"Normal task\"))\n",
    "try:\n",
    "    strict.add(HighPriorityTask(title=\"Urgent task\"))  # Rejected\n",
    "except TypeError as e:\n",
    "    print(f\"Strict pile rejected subclass: {str(e)[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Pile** provides a powerful foundation for managing Element collections:\n",
    "\n",
    "**Key Features**:\n",
    "- Thread-safe operations with RLock synchronization\n",
    "- Flexible type validation (single/Union/strict modes)\n",
    "- Rich query interface via type-dispatched `__getitem__`\n",
    "- Async support with independent lock\n",
    "- Progression order preservation\n",
    "- Full serialization/deserialization support\n",
    "\n",
    "**Common Patterns**:\n",
    "- `pile[lambda x: condition]` - Filter by predicate\n",
    "- `pile[progression]` - Custom ordering\n",
    "- `pile.filter_by_type(T)` - Type-based filtering\n",
    "- `pile.include(item)` - Idempotent add\n",
    "- `Pile(item_type=Union[A, B])` - Multi-type collections\n",
    "\n",
    "**Performance**:\n",
    "- O(1) add, get, contains\n",
    "- O(n) remove (progression linear scan)\n",
    "- O(1) index access (progression optimization)\n",
    "- Thread-safe with minimal contention\n",
    "\n",
    "See `src/lionherd_core/base/pile.py` for full implementation details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
