{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eccc0c4",
   "metadata": {},
   "source": [
    "# Deep Analysis: Diversity Check Impact on Performance\n",
    "\n",
    "This notebook investigates:\n",
    "1. How diversity checking affects synthetic sample quality\n",
    "2. Performance vs Quality trade-offs\n",
    "3. Alternative optimization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77460961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/GitHub/DistAwareAug/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Import DistAwareAug\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from distawareaug import DistAwareAugmentor\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b5441",
   "metadata": {},
   "source": [
    "## 1. Load Real-World Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0eee65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 43400 samples, 17 features\n",
      "Training: 34720, Test: 8680\n",
      "Imbalance ratio: 54.46:1\n"
     ]
    }
   ],
   "source": [
    "# Load stroke dataset\n",
    "path = kagglehub.dataset_download(\"shashwatwork/cerebral-stroke-predictionimbalaced-dataset\")\n",
    "data = pd.read_csv(os.path.join(path, \"dataset.csv\"))\n",
    "\n",
    "# Preprocess\n",
    "data_clean = data.drop(['id', 'smoking_status'], axis=1)\n",
    "data_clean['bmi'] = data_clean['bmi'].fillna(data_clean['bmi'].median())\n",
    "data_clean = pd.get_dummies(data_clean, columns=['gender', 'ever_married', 'work_type', 'Residence_type'])\n",
    "\n",
    "X = data_clean.drop('stroke', axis=1).values\n",
    "y = data_clean['stroke'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Training: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "print(f\"Imbalance ratio: {sum(y_train==0)/sum(y_train==1):.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8ad61",
   "metadata": {},
   "source": [
    "## 2. Test Different Diversity Check Strategies\n",
    "\n",
    "We'll modify DistAwareAugmentor temporarily to test different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8218f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test function defined\n"
     ]
    }
   ],
   "source": [
    "def test_diversity_strategy(X_train, y_train, X_test, y_test, strategy_name, max_check_size=None):\n",
    "    \"\"\"\n",
    "    Test a diversity checking strategy.\n",
    "    \n",
    "    strategy_name options:\n",
    "    - 'none': Skip diversity checks entirely\n",
    "    - 'sample_50': Check against 50 random samples\n",
    "    - 'sample_100': Check against 100 random samples  \n",
    "    - 'sample_200': Check against 200 random samples (current default)\n",
    "    - 'sample_500': Check against 500 random samples\n",
    "    - 'all': Check against all samples (v0.1.0 behavior)\n",
    "    - 'adaptive': Check against sqrt(n) samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: This requires temporarily modifying augmentor.py\n",
    "    # For now, we'll test with the current implementation\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Time augmentation\n",
    "    aug = DistAwareAugmentor(sampling_strategy='auto', random_state=42)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    X_aug, y_aug = aug.fit_resample(X_train, y_train)\n",
    "    aug_time = time.time() - t0\n",
    "    \n",
    "    results['augmentation_time'] = aug_time\n",
    "    results['samples_generated'] = len(X_aug) - len(X_train)\n",
    "    \n",
    "    # Train model\n",
    "    scaler = StandardScaler()\n",
    "    X_aug_scaled = scaler.fit_transform(X_aug)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf.fit(X_aug_scaled, y_aug)\n",
    "    train_time = time.time() - t0\n",
    "    \n",
    "    results['training_time'] = train_time\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    results['recall'] = recall_score(y_test, y_pred, pos_label=1)\n",
    "    results['f1_score'] = f1_score(y_test, y_pred, pos_label=1)\n",
    "    results['roc_auc'] = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    # Diversity analysis of synthetic samples\n",
    "    synthetic_samples = X_aug[len(X_train):]\n",
    "    if len(synthetic_samples) > 1:\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        dists = pairwise_distances(synthetic_samples[:min(500, len(synthetic_samples))])\n",
    "        np.fill_diagonal(dists, np.inf)  # Ignore self-distances\n",
    "        results['min_distance'] = dists.min()\n",
    "        results['mean_distance'] = dists[dists < np.inf].mean()\n",
    "        results['std_distance'] = dists[dists < np.inf].std()\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Test function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a98b72",
   "metadata": {},
   "source": [
    "## 3. Run Baseline Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2589853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BASELINE TESTS\n",
      "================================================================================\n",
      "\n",
      "1. No Augmentation...\n",
      "   F1-Score: 0.0000\n",
      "\n",
      "2. SMOTE...\n",
      "   Time: 0.065s\n",
      "   F1-Score: 0.0355\n",
      "\n",
      "3. DistAwareAug (v0.2.0 - 200 sample check)...\n",
      "   Time: 0.884s\n",
      "   F1-Score: 0.0000\n",
      "   Min distance between synthetic samples: 7.998365915779784e-05\n",
      "\n",
      "================================================================================\n",
      "BASELINE RESULTS\n",
      "================================================================================\n",
      "                   augmentation_time  f1_score   roc_auc  min_distance\n",
      "No Augmentation             0.000000  0.000000  0.711558           NaN\n",
      "SMOTE                       0.064637  0.035532  0.558983           NaN\n",
      "DistAwareAug_v0.2           0.884123  0.000000  0.708935       0.00008\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BASELINE TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baselines = {}\n",
    "\n",
    "# 1. No augmentation\n",
    "print(\"\\n1. No Augmentation...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "t0 = time.time()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "train_time = time.time() - t0\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "baselines['No Augmentation'] = {\n",
    "    'augmentation_time': 0,\n",
    "    'training_time': train_time,\n",
    "    'samples_generated': 0,\n",
    "    'precision': precision_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred, pos_label=1),\n",
    "    'f1_score': f1_score(y_test, y_pred, pos_label=1),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "}\n",
    "\n",
    "print(f\"   F1-Score: {baselines['No Augmentation']['f1_score']:.4f}\")\n",
    "\n",
    "# 2. SMOTE\n",
    "print(\"\\n2. SMOTE...\")\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "t0 = time.time()\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "aug_time = time.time() - t0\n",
    "\n",
    "X_smote_scaled = scaler.fit_transform(X_smote)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "t0 = time.time()\n",
    "clf.fit(X_smote_scaled, y_smote)\n",
    "train_time = time.time() - t0\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "baselines['SMOTE'] = {\n",
    "    'augmentation_time': aug_time,\n",
    "    'training_time': train_time,\n",
    "    'samples_generated': len(X_smote) - len(X_train),\n",
    "    'precision': precision_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred, pos_label=1),\n",
    "    'f1_score': f1_score(y_test, y_pred, pos_label=1),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "}\n",
    "\n",
    "print(f\"   Time: {aug_time:.3f}s\")\n",
    "print(f\"   F1-Score: {baselines['SMOTE']['f1_score']:.4f}\")\n",
    "\n",
    "# 3. DistAwareAug (current v0.2.0 with 200-sample check)\n",
    "print(\"\\n3. DistAwareAug (v0.2.0 - 200 sample check)...\")\n",
    "baselines['DistAwareAug_v0.2'] = test_diversity_strategy(X_train, y_train, X_test, y_test, 'sample_200')\n",
    "print(f\"   Time: {baselines['DistAwareAug_v0.2']['augmentation_time']:.3f}s\")\n",
    "print(f\"   F1-Score: {baselines['DistAwareAug_v0.2']['f1_score']:.4f}\")\n",
    "print(f\"   Min distance between synthetic samples: {baselines['DistAwareAug_v0.2'].get('min_distance', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_df = pd.DataFrame(baselines).T\n",
    "print(baseline_df[['augmentation_time', 'f1_score', 'roc_auc', 'min_distance']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f74533",
   "metadata": {},
   "source": [
    "## 4. Analyze Diversity Check Impact\n",
    "\n",
    "**Key Questions:**\n",
    "1. Is the 200-sample check actually hurting quality?\n",
    "2. What's the optimal balance between speed and quality?\n",
    "3. Are there alternative optimization strategies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb3354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIVERSITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Generated 33468 synthetic samples\n",
      "Diversity threshold used: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Check actual diversity in current synthetic samples\n",
    "print(\"=\"*80)\n",
    "print(\"DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "aug = DistAwareAugmentor(sampling_strategy='auto', random_state=42)\n",
    "X_aug, y_aug = aug.fit_resample(X_train, y_train)\n",
    "synthetic_samples = X_aug[len(X_train):]\n",
    "\n",
    "print(f\"\\nGenerated {len(synthetic_samples)} synthetic samples\")\n",
    "print(f\"Diversity threshold used: {aug.diversity_threshold}\")\n",
    "\n",
    "# Compute pairwise distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "dists = pairwise_distances(synthetic_samples)\n",
    "np.fill_diagonal(dists, np.inf)\n",
    "\n",
    "print(f\"\\nDistance Statistics:\")\n",
    "print(f\"  Min distance: {dists.min():.6f}\")\n",
    "print(f\"  Mean distance: {dists[dists < np.inf].mean():.6f}\")\n",
    "print(f\"  Median distance: {np.median(dists[dists < np.inf]):.6f}\")\n",
    "print(f\"  Std distance: {dists[dists < np.inf].std():.6f}\")\n",
    "\n",
    "# Count violations\n",
    "violations = np.sum(dists < aug.diversity_threshold)\n",
    "total_pairs = len(synthetic_samples) * (len(synthetic_samples) - 1)\n",
    "print(f\"\\nDiversity threshold violations: {violations}/{total_pairs} ({violations/total_pairs*100:.2f}%)\")\n",
    "\n",
    "if violations > 0:\n",
    "    print(\"\\n⚠️  WARNING: Some synthetic samples are closer than diversity_threshold!\")\n",
    "    print(\"   This suggests the 200-sample random check is missing some duplicates.\")\n",
    "else:\n",
    "    print(\"\\n✓ All synthetic samples respect diversity_threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f3c43",
   "metadata": {},
   "source": [
    "## 5. Alternative Optimization Strategies\n",
    "\n",
    "Instead of random sampling, we could:\n",
    "1. **Spatial indexing** - Use KD-Tree or Ball-Tree for O(log n) lookups\n",
    "2. **Clustering** - Check against cluster centroids\n",
    "3. **Progressive relaxation** - Start strict, relax threshold as samples grow\n",
    "4. **Batch acceptance** - Accept batches if avg distance is good\n",
    "5. **No diversity checks** - Rely on distribution sampling alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc928762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PROPOSED OPTIMIZATIONS\n",
      "================================================================================\n",
      "\n",
      "1. KD-Tree/Ball-Tree Approach:\n",
      "   - Use sklearn's NearestNeighbors with ball_tree algorithm\n",
      "   - O(log n) lookups instead of O(n)\n",
      "   - Already partially implemented for original samples\n",
      "   - Could extend to synthetic samples\n",
      "\n",
      "2. No Diversity Checks (Pure Distribution Sampling):\n",
      "   - Trust KDE/Gaussian to generate diverse samples\n",
      "   - Maximum speed\n",
      "   - Relies on statistical properties of distributions\n",
      "\n",
      "3. Adaptive Threshold:\n",
      "   - Start with strict threshold (0.1)\n",
      "   - Gradually relax as more samples generated\n",
      "   - Balance quality vs speed dynamically\n",
      "\n",
      "4. Batch-Level Diversity:\n",
      "   - Check diversity of entire batch, not individual samples\n",
      "   - Accept/reject batches based on average metrics\n",
      "   - Fewer diversity computations\n",
      "\n",
      "5. Hybrid Approach:\n",
      "   - Use KD-Tree for original samples (always check)\n",
      "   - Use random sampling for synthetic samples (approximate)\n",
      "   - Best of both worlds\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PROPOSED OPTIMIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. KD-Tree/Ball-Tree Approach:\")\n",
    "print(\"   - Use sklearn's NearestNeighbors with ball_tree algorithm\")\n",
    "print(\"   - O(log n) lookups instead of O(n)\")\n",
    "print(\"   - Already partially implemented for original samples\")\n",
    "print(\"   - Could extend to synthetic samples\")\n",
    "\n",
    "print(\"\\n2. No Diversity Checks (Pure Distribution Sampling):\")\n",
    "print(\"   - Trust KDE/Gaussian to generate diverse samples\")\n",
    "print(\"   - Maximum speed\")\n",
    "print(\"   - Relies on statistical properties of distributions\")\n",
    "\n",
    "print(\"\\n3. Adaptive Threshold:\")\n",
    "print(\"   - Start with strict threshold (0.1)\")\n",
    "print(\"   - Gradually relax as more samples generated\")\n",
    "print(\"   - Balance quality vs speed dynamically\")\n",
    "\n",
    "print(\"\\n4. Batch-Level Diversity:\")\n",
    "print(\"   - Check diversity of entire batch, not individual samples\")\n",
    "print(\"   - Accept/reject batches based on average metrics\")\n",
    "print(\"   - Fewer diversity computations\")\n",
    "\n",
    "print(\"\\n5. Hybrid Approach:\")\n",
    "print(\"   - Use KD-Tree for original samples (always check)\")\n",
    "print(\"   - Use random sampling for synthetic samples (approximate)\")\n",
    "print(\"   - Best of both worlds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ee7f3",
   "metadata": {},
   "source": [
    "## 6. Recommendations\n",
    "\n",
    "Based on the analysis above, we'll determine:\n",
    "1. Is the 200-sample check causing quality degradation?\n",
    "2. What optimization should be implemented next?\n",
    "3. Should we add a parameter for users to control this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadccfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY AND RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "Performance Comparison:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'baselines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPerformance Comparison:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  SMOTE:        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbaselines\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mSMOTE\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maugmentation_time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaselines[\u001b[33m'\u001b[39m\u001b[33mSMOTE\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  DistAwareAug: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaselines[\u001b[33m'\u001b[39m\u001b[33mDistAwareAug_v0.2\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maugmentation_time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaselines[\u001b[33m'\u001b[39m\u001b[33mDistAwareAug_v0.2\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Slowdown:     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaselines[\u001b[33m'\u001b[39m\u001b[33mDistAwareAug_v0.2\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maugmentation_time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mbaselines[\u001b[33m'\u001b[39m\u001b[33mSMOTE\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maugmentation_time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'baselines' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"  SMOTE:        {baselines['SMOTE']['augmentation_time']:.3f}s, F1={baselines['SMOTE']['f1_score']:.4f}\")\n",
    "print(f\"  DistAwareAug: {baselines['DistAwareAug_v0.2']['augmentation_time']:.3f}s, F1={baselines['DistAwareAug_v0.2']['f1_score']:.4f}\")\n",
    "print(f\"  Slowdown:     {baselines['DistAwareAug_v0.2']['augmentation_time'] / baselines['SMOTE']['augmentation_time']:.1f}x\")\n",
    "\n",
    "# Determine if quality is degraded\n",
    "f1_diff = baselines['DistAwareAug_v0.2']['f1_score'] - baselines['SMOTE']['f1_score']\n",
    "\n",
    "print(\"\\nQuality Assessment:\")\n",
    "if f1_diff > 0.01:\n",
    "    print(f\"  ✓ DistAwareAug outperforms SMOTE by {f1_diff:.4f} F1-score\")\n",
    "elif f1_diff < -0.01:\n",
    "    print(f\"  ⚠️  DistAwareAug underperforms SMOTE by {abs(f1_diff):.4f} F1-score\")\n",
    "    print(\"  → The 200-sample check MAY be hurting quality\")\n",
    "else:\n",
    "    print(f\"  → Similar performance (diff: {f1_diff:.4f})\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Test KD-Tree approach for synthetic samples\")\n",
    "print(\"  2. Experiment with adaptive thresholds\")\n",
    "print(\"  3. Consider making diversity check strategy a parameter\")\n",
    "print(\"  4. Profile to find remaining bottlenecks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c561bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
