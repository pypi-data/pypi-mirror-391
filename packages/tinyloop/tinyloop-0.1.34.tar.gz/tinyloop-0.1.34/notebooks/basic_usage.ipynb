{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e7eb5",
   "metadata": {},
   "source": [
    "### Basic LLM call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdec61d",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383941ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "\n",
    "llm = LLM(model=\"openai/gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "response = llm(prompt=\"Hello, how are you?\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e746825",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ce22e",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "\n",
    "llm = LLM(model=\"openai/gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "response = await llm.acall(prompt=\"Hello, how are you?\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b49802",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7391a",
   "metadata": {},
   "source": [
    "### Streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebefc5",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d269276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m, \u001b[33mresponse\u001b[0m=\u001b[32m'Hello'\u001b[0m, \u001b[33mchunk\u001b[0m=\u001b[32m'Hello'\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello!'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'!'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m, \u001b[33mresponse\u001b[0m=\u001b[32m'Hello!'\u001b[0m, \u001b[33mchunk\u001b[0m=\u001b[32m'!'\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hello! I'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' I'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m, \u001b[33mresponse\u001b[0m=\u001b[32m'Hello! I'\u001b[0m, \u001b[33mchunk\u001b[0m=\u001b[32m' I'\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"'m\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m, \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm\"\u001b[0m, \u001b[33mchunk\u001b[0m=\u001b[32m\"'m\"\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' just'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' just'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' a'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' computer'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' computer'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' program'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' program'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program,\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program,\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m','\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' so'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' so'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' I'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' I'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' don'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' don'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"'t\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m\"'t\"\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' have'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' have'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' feelings'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' feelings'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings,\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">','</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings,\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m','\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' but'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' but'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' I'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' I'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"'m\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m\"'m\"\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' here'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' here'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' and'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' and'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' ready'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' ready'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' to'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' to'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' help'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' help'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' you'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' you'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' with'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you \u001b[0m\n",
       "\u001b[32mwith\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' with'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' anything'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' anything'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' you'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' you'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' need'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' need'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need.\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m'.'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' How'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' How'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' can'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' can'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' I'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' I'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' assist'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' assist'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' you'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' you'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you today\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' today'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you today\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m' today'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you today?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'?'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you today?\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[32m'?'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you today?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you today?\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMStreamingResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you today?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chunk</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMStreamingResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-CatkMZrCuAtygKyyHMQUp47NBIu3h'\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you today?\"\u001b[0m,\n",
       "    \u001b[33mchunk\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tloop_final_cost=0.000062\n",
      "captured_cost: 6.2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"Hello! I...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything you need. How can I assist you today?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">raw_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">message_history</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hello, how are you?'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">help you with anything you need. How can I assist you today?\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">cost</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.2e-05</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hidden_fields</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\u001b[0m\n",
       "\u001b[32manything you need. How can I assist you today?\"\u001b[0m,\n",
       "    \u001b[33mraw_response\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmessage_history\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Hello, how are you?'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to \u001b[0m\n",
       "\u001b[32mhelp you with anything you need. How can I assist you today?\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcost\u001b[0m=\u001b[1;36m6\u001b[0m\u001b[1;36m.2e-05\u001b[0m,\n",
       "    \u001b[33mhidden_fields\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 494, in request\n",
      "    self.endheaders()\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 325, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x138405d50>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /api/public/otel/v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x138405d50>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 147, in _export\n",
      "    resp = self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 677, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /api/public/otel/v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x138405d50>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 494, in request\n",
      "    self.endheaders()\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/fernandomeira/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 325, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x1384196d0>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /api/public/otel/v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1384196d0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/opentelemetry/sdk/_shared_internal/__init__.py\", line 155, in _export\n",
      "    self._exporter.export(\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 172, in export\n",
      "    resp = self._export(serialized_data, deadline_sec - time())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 155, in _export\n",
      "    resp = self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fernandomeira/projects/tinyloop/.venv/lib/python3.11/site-packages/requests/adapters.py\", line 677, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /api/public/otel/v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1384196d0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from rich import print as rprint\n",
    "\n",
    "llm = LLM(model=\"openai/gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "response = await llm.acall(prompt=\"Hello, how are you?\", stream=True)\n",
    "async for chunk in response:\n",
    "    rprint(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5174a4",
   "metadata": {},
   "source": [
    "### Structured outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7ecff",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from pydantic import BaseModel\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/qwen/qwen-2.5-72b-instruct\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "\n",
    "class EventsList(BaseModel):\n",
    "    events: list[CalendarEvent]\n",
    "\n",
    "\n",
    "response = llm(\n",
    "    prompt=\"List 5 important events in the XIX century\", response_format=EventsList\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ece61",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "\n",
    "llm = LLM(model=\"openai/gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "response = await llm.acall(prompt=\"Hello, how are you?\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from pydantic import BaseModel\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-3-5-haiku-20241022\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "\n",
    "class EventsList(BaseModel):\n",
    "    events: list[CalendarEvent]\n",
    "\n",
    "\n",
    "response = await llm.acall(\n",
    "    prompt=\"List 5 important events in the XIX century\", response_format=EventsList\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59206b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from pydantic import BaseModel\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/google/gemini-2.5-flash\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "\n",
    "class EventsList(BaseModel):\n",
    "    events: list[CalendarEvent]\n",
    "\n",
    "\n",
    "response = await llm.acall(\n",
    "    prompt=\"List 5 important events in the XIX century\", response_format=EventsList\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23d4e7",
   "metadata": {},
   "source": [
    "### Vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6f33f",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc700dde",
   "metadata": {},
   "source": [
    "##### From PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# Read a local JPG file as PIL image\n",
    "pil_image = PILImage.open(\"sutton.jpg\")\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "image = Image.from_PIL(pil_image)\n",
    "\n",
    "\n",
    "response = llm(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4714c5a",
   "metadata": {},
   "source": [
    "##### From File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-3-7-sonnet-20250219\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "image = Image.from_file(\"sutton.jpg\")\n",
    "\n",
    "\n",
    "response = llm(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001134d",
   "metadata": {},
   "source": [
    "##### From URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "import litellm\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/google/gemini-2.5-pro\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "litellm._turn_on_debug()\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "url = \"https://images.ctfassets.net/cnu0m8re1exe/2xdqQSvfebktASbHvILYH5/fcc91130ad1ff329765595b669549d8d/Meet-Jumping-Spider-Adorable-Arachnid.jpg?fm=jpg&fl=progressive&w=660&h=433&fit=fill\"\n",
    "image = Image.from_url(url)\n",
    "\n",
    "\n",
    "response = llm(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f943b",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbde200",
   "metadata": {},
   "source": [
    "##### From PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "from rich import print as rprint\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/google/gemini-2.5-flash\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# Read a local JPG file as PIL image\n",
    "pil_image = PILImage.open(\"sutton.jpg\")\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "image = Image.from_PIL(pil_image)\n",
    "\n",
    "\n",
    "response = await llm.acall(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cb9d9",
   "metadata": {},
   "source": [
    "##### From File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "image = Image.from_file(\"sutton.jpg\")\n",
    "\n",
    "\n",
    "response = await llm.acall(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0d65c",
   "metadata": {},
   "source": [
    "##### From URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from PIL import Image as PILImage\n",
    "from tinyloop.features.vision import Image\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-3-7-sonnet-20250219\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# Create tinyloop Image from PIL image\n",
    "url = \"https://images.ctfassets.net/cnu0m8re1exe/2xdqQSvfebktASbHvILYH5/fcc91130ad1ff329765595b669549d8d/Meet-Jumping-Spider-Adorable-Arachnid.jpg?fm=jpg&fl=progressive&w=660&h=433&fit=fill\"\n",
    "image = Image.from_url(url)\n",
    "\n",
    "\n",
    "response = await llm.acall(prompt=\"Describe the image\", images=[image])\n",
    "\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf31ddd",
   "metadata": {},
   "source": [
    "### Function calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533e504",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "import json\n",
    "from tinyloop.features.function_calling import Tool\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = llm(\n",
    "    prompt=\"What is the weather in Boston, MA?\",\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "\n",
    "for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    print(f\"Tool: {tool_name}\")\n",
    "    print(f\"Args: {tool_args}\")\n",
    "    print(weather_tool(**tool_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca18f9",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "import json\n",
    "from tinyloop.features.function_calling import Tool\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/google/gemini-2.5-flash\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = await llm.ainvoke(\n",
    "    prompt=\"What is the weather in Boston, MA (in fahrenheit)?\",\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "\n",
    "for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    print(f\"Tool: {tool_name}\")\n",
    "    print(f\"Args: {tool_args}\")\n",
    "    print(weather_tool(**tool_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270746f",
   "metadata": {},
   "source": [
    "#### Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from rich import print as rprint\n",
    "from tinyloop.features.function_calling import Tool\n",
    "import litellm\n",
    "\n",
    "\n",
    "# def track_cost_callback(kwargs, completion_response, start_time, end_time):\n",
    "#     cost = kwargs[\"response_cost\"]\n",
    "#     print(f\"tloop_final_cost={cost:.6f}\")\n",
    "\n",
    "\n",
    "# litellm.success_callback = [track_cost_callback]\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-sonnet-4-20250514\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = await llm.ainvoke(\n",
    "    prompt=\"What is the weather in Boston, MA (in fahrenheit)?\",\n",
    "    tools=[weather_tool],\n",
    "    stream=True,\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "async for chunk in inference:\n",
    "    rprint(chunk)\n",
    "\n",
    "# for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "#     tool_name = tool_call.function.name\n",
    "#     tool_args = json.loads(tool_call.function.arguments)\n",
    "#     print(f\"Tool: {tool_name}\")\n",
    "#     print(f\"Args: {tool_args}\")\n",
    "#     print(weather_tool(**tool_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23009357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from rich import print as rprint\n",
    "from tinyloop.features.function_calling import Tool\n",
    "import litellm\n",
    "\n",
    "\n",
    "# def track_cost_callback(kwargs, completion_response, start_time, end_time):\n",
    "#     cost = kwargs[\"response_cost\"]\n",
    "#     print(f\"tloop_final_cost={cost:.6f}\")\n",
    "\n",
    "\n",
    "# litellm.success_callback = [track_cost_callback]\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = await llm.ainvoke(\n",
    "    prompt=\"What is the weather in Boston, MA (in fahrenheit)?\",\n",
    "    tools=[weather_tool],\n",
    "    stream=True,\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "async for chunk in inference:\n",
    "    rprint(chunk)\n",
    "\n",
    "# for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "#     tool_name = tool_call.function.name\n",
    "#     tool_args = json.loads(tool_call.function.arguments)\n",
    "#     print(f\"Tool: {tool_name}\")\n",
    "#     print(f\"Args: {tool_args}\")\n",
    "#     print(weather_tool(**tool_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from rich import print as rprint\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from litellm import acompletion\n",
    "\n",
    "\n",
    "# def track_cost_callback(kwargs, completion_response, start_time, end_time):\n",
    "#     cost = kwargs[\"response_cost\"]\n",
    "#     print(f\"tloop_final_cost={cost:.6f}\")\n",
    "\n",
    "\n",
    "# litellm.success_callback = [track_cost_callback]\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-sonnet-4-20250514\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = await acompletion(\n",
    "    model=\"anthropic/claude-sonnet-4-20250514\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in Boston, MA (in fahrenheit)?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=[weather_tool.definition],\n",
    "    stream=True,\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "async for chunk in inference:\n",
    "    print(chunk)\n",
    "\n",
    "# for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "#     tool_name = tool_call.function.name\n",
    "#     tool_args = json.loads(tool_call.function.arguments)\n",
    "#     print(f\"Tool: {tool_name}\")\n",
    "#     print(f\"Args: {tool_args}\")\n",
    "#     print(weather_tool(**tool_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54506cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.inference.litellm import LLM\n",
    "from rich import print as rprint\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from litellm import acompletion\n",
    "\n",
    "\n",
    "# def track_cost_callback(kwargs, completion_response, start_time, end_time):\n",
    "#     cost = kwargs[\"response_cost\"]\n",
    "#     print(f\"tloop_final_cost={cost:.6f}\")\n",
    "\n",
    "\n",
    "# litellm.success_callback = [track_cost_callback]\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"Get the current weather in a given location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : str {'celsius', 'fahrenheit'}\n",
    "        Temperature unit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        a sentence indicating the weather\n",
    "    \"\"\"\n",
    "    if location == \"Boston, MA\":\n",
    "        return \"The weather is 12F\"\n",
    "    return f\"Weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"anthropic/claude-sonnet-4-20250514\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "weather_tool = Tool(get_current_weather)\n",
    "\n",
    "inference = await acompletion(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in Boston, MA (in fahrenheit)?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=[weather_tool.definition],\n",
    "    stream=True,\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "async for chunk in inference:\n",
    "    print(chunk)\n",
    "\n",
    "# for tool_call in inference.raw_response.choices[0].message.tool_calls:\n",
    "#     tool_name = tool_call.function.name\n",
    "#     tool_args = json.loads(tool_call.function.arguments)\n",
    "#     print(f\"Tool: {tool_name}\")\n",
    "#     print(f\"Args: {tool_args}\")\n",
    "#     print(weather_tool(**tool_args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
