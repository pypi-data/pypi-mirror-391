#!/usr/bin/env python3
"""
agentype - App Agent MCP Server
Author: cuilei
Version: 1.0
"""

import sys
import asyncio
import json
import os
from typing import Optional, Dict, Any
from pathlib import Path
from datetime import datetime

# å¯¼å…¥é¡¹ç›®æ¨¡å—

# å¯¼å…¥å›½é™…åŒ–æ”¯æŒ
try:
    from agentype.appagent.utils.i18n import _
except ImportError:
    # å¦‚æœå›½é™…åŒ–æ¨¡å—ä¸å­˜åœ¨ï¼Œæä¾›ç®€å•çš„å ä½ç¬¦
    def _(key, **kwargs):
        return key.format(**kwargs) if kwargs else key

# å¯¼å…¥ç»Ÿä¸€é…ç½®ç³»ç»Ÿçš„session_idå‡½æ•°
try:
    from agentype.config import get_session_id_for_filename
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›å¤‡ç”¨å®ç°
    def get_session_id_for_filename():
        from datetime import datetime
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

try:
    from mcp.server.fastmcp import FastMCP
    # å¯¼å…¥ç°æœ‰çš„å·¥å…·å‡½æ•°
    from agentype.appagent.tools.celldex_info_tool import get_celldex_projects_info
    from agentype.appagent.tools.celldex_download_tool import download_celldex_dataset
    from agentype.appagent.tools.singleR_simple import singleR_annotate
    from agentype.appagent.tools.get_sctype_tissues import get_sctype_tissues
    from agentype.appagent.tools.sctype_simple import sctype_annotate
    from agentype.appagent.tools.get_celltypist_models import get_celltypist_models
    from agentype.appagent.tools.celltypist_simple import celltypist_annotate
    
    # å¯¼å…¥æ–°çš„ç‰©ç§æ£€æµ‹å’Œæ–‡ä»¶éªŒè¯å·¥å…·
    from agentype.appagent.tools.species_detection import (
        detect_species_from_h5ad, 
        detect_species_from_rds, 
        detect_species_from_marker_json
    )
    from agentype.appagent.tools.file_validators import validate_marker_json

    # å¯¼å…¥è·¯å¾„ç®¡ç†å·¥å…·
    from agentype.mainagent.tools.file_paths_tools import (
        save_file_paths_bundle as _save_file_paths_bundle,
        load_file_paths_bundle as _load_file_paths_bundle,
        load_and_validate_bundle as _load_and_validate_bundle
    )

except ImportError as e:
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    current_file = Path(__file__).resolve()
    # project_root ä¸å†éœ€è¦

    print(f"å¯¼å…¥ä¾èµ–å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥MCPåŒ…å®‰è£…ï¼špip install mcp")
    print(f"å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
    #
    print(f"Pythonè·¯å¾„: {sys.path[:3]}")
    sys.exit(1)

# ç¼“å­˜ç›®å½•ï¼ˆå°†åœ¨ __main__ å—ä¸­åˆå§‹åŒ–ï¼Œä½¿ç”¨ ConfigManager æä¾›çš„è·¯å¾„ï¼‰
cache_dir = None

# å¯¼å…¥è·¯å¾„ç®¡ç†å™¨
try:
    from agentype.appagent.utils.path_manager import normalize_path
except ImportError:
    # ç®€å•çš„å¤‡ç”¨å®ç°
    def normalize_path(file_path):
        return str(Path(file_path).resolve()) if file_path else ""
    def get_absolute_paths(**kwargs):
        return {k: normalize_path(v) for k, v in kwargs.items()}

# åˆå§‹åŒ–FastMCPæœåŠ¡å™¨
mcp = FastMCP("celltype-app-agent", log_level="INFO")

# ç¼“å­˜ç›®å½•é…ç½®ï¼ˆåœ¨ __main__ å—ä¸­åˆå§‹åŒ–ï¼‰
CACHE_DIR = None

# é…ç½®å¯¹è±¡ï¼ˆåœ¨ __main__ å—ä¸­åˆå§‹åŒ–ï¼‰
_CONFIG = None

def ensure_cache_dir() -> str:
    """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
    os.makedirs(CACHE_DIR, exist_ok=True)
    return CACHE_DIR

# ============ SingleR ç›¸å…³å·¥å…· ============

@mcp.tool()
async def get_celldex_projects_info_tool(language: str = "zh") -> str:
    """
    è·å–celldexæ‰€æœ‰å‚è€ƒæ•°æ®é›†ä¿¡æ¯
    
    Args:
        language: è¾“å‡ºè¯­è¨€ï¼Œ"zh"ä¸ºä¸­æ–‡ï¼Œ"en"ä¸ºè‹±æ–‡
    
    Returns:
        åŒ…å«æ‰€æœ‰celldexæ•°æ®é›†ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, get_celldex_projects_info, language
        )
        
        return json.dumps({
            "success": True,
            "data": result,
            "message": "æˆåŠŸè·å–celldexæ•°æ®é›†ä¿¡æ¯",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"è·å–celldexæ•°æ®é›†ä¿¡æ¯æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def download_celldex_dataset_tool(dataset_name: str, cache_dir: str = "~/.cache/agentype") -> str:
    """
    ä¸‹è½½celldexå‚è€ƒæ•°æ®é›†
    
    Args:
        dataset_name: æ•°æ®é›†åç§°ï¼Œæ”¯æŒå®Œæ•´åç§°æˆ–ç®€å†™
        cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
    
    Returns:
        ä¸‹è½½ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, download_celldex_dataset, dataset_name, cache_dir
        )
        
        return json.dumps({
            "success": True,
            "data": result,
            "message": f"celldexæ•°æ®é›† {dataset_name} å¤„ç†å®Œæˆ",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"ä¸‹è½½celldexæ•°æ®é›† {dataset_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def singleR_annotate_tool(
    reference_path: str,
    rds_path: Optional[str] = None,
    cluster_column: str = "seurat_clusters",
) -> str:
    """
    ä½¿ç”¨SingleRè¿›è¡Œç»†èƒç±»å‹æ³¨é‡Šï¼ˆè‡ªåŠ¨åŒ–ç‰ˆæœ¬ï¼‰

    æ­¤å·¥å…·å®Œå…¨è‡ªåŠ¨åŒ–å¤„ç†SingleRæ³¨é‡Šæµç¨‹ï¼š
    1. è‡ªåŠ¨ä»bundleè¯»å–Seuratæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆrds_fileï¼Œé™çº§h5_fileï¼‰
    2. è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨session_idå‘½å
    3. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜singler_resultè·¯å¾„

    Args:
        reference_path: å‚è€ƒæ•°æ®åº“RDSæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼Œå¤–éƒ¨æ•°æ®ï¼‰
        rds_path: Seuratå¯¹è±¡çš„RDSæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨ä»bundleè¯»å–ï¼‰
        output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
        cluster_column: èšç±»åˆ—åï¼Œé»˜è®¤"seurat_clusters"

    Returns:
        æ³¨é‡Šç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        # 1. ä½¿ç”¨æ™ºèƒ½fallbackè‡ªåŠ¨è·å–Seuratæ–‡ä»¶è·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_get_input_path
            rds_path = auto_get_input_path(
                manual_path=rds_path,
                bundle_keys=['rds_file', 'sce_h5', 'scanpy_h5', 'h5_file'],
                tool_name='singleR_annotate_tool'
            )
        except Exception as e:
            return json.dumps({
                "success": False,
                "error": f"è‡ªåŠ¨è·å–Seuratè·¯å¾„å¤±è´¥: {e}"
            }, ensure_ascii=False, indent=2)

        # MCPå±‚è‡ªåŠ¨ç”Ÿæˆoutput_pathï¼ˆä½¿ç”¨ _CONFIG çš„ results_dirï¼‰
        ts = get_session_id_for_filename() or datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = _CONFIG.get_results_dir()
        output_path = str(results_dir / f'singleR_annotation_result_{ts}.json')

        # ğŸ”¬ æ‰§è¡ŒSingleRæ³¨é‡Šï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰

        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, singleR_annotate, rds_path, reference_path, output_path, cluster_column
        )

        # ç»Ÿä¸€æå–è¾“å‡ºè·¯å¾„
        resolved_output = output_path
        if isinstance(result, dict) and result.get("output_file"):
            resolved_output = result.get("output_file")

        # 2. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜singler_resultè·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_update_bundle
            auto_update_bundle('singler_result', resolved_output)
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°bundleå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        return json.dumps({
            "success": True,
            "data": result,
            "input_file": rds_path,
            "reference_file": reference_path,
            "output_file": resolved_output,
            "cluster_column": cluster_column,
            "message": "SingleRæ³¨é‡Šå®Œæˆ",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"SingleRæ³¨é‡Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

# ============ scType ç›¸å…³å·¥å…· ============

@mcp.tool()
async def get_sctype_tissues_tool() -> str:
    """
    è·å–scTypeæ”¯æŒçš„æ‰€æœ‰ç»„ç»‡ç±»å‹
    
    Returns:
        åŒ…å«ç»„ç»‡ç±»å‹åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, get_sctype_tissues
        )
        
        return json.dumps({
            "success": True,
            "data": result,
            "message": "æˆåŠŸè·å–scTypeç»„ç»‡ç±»å‹",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"è·å–scTypeç»„ç»‡ç±»å‹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def sctype_annotate_tool(
    tissue_type: str = "Immune system",
    rds_path: Optional[str] = None,
    cluster_column: str = "seurat_clusters",
) -> str:
    """
    ä½¿ç”¨scTypeè¿›è¡Œç»†èƒç±»å‹æ³¨é‡Šï¼ˆè‡ªåŠ¨åŒ–ç‰ˆæœ¬ï¼‰

    æ­¤å·¥å…·å®Œå…¨è‡ªåŠ¨åŒ–å¤„ç†scTypeæ³¨é‡Šæµç¨‹ï¼š
    1. è‡ªåŠ¨ä»bundleè¯»å–Seuratæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆrds_fileï¼Œé™çº§h5_fileï¼‰
    2. è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨session_idå‘½å
    3. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜sctype_resultè·¯å¾„

    Args:
        tissue_type: ç»„ç»‡ç±»å‹ï¼Œé»˜è®¤"Immune system"
        rds_path: Seuratå¯¹è±¡çš„RDSæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨ä»bundleè¯»å–ï¼‰
        output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
        cluster_column: èšç±»åˆ—åï¼Œé»˜è®¤"seurat_clusters"

    Returns:
        æ³¨é‡Šç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        # 1. ä½¿ç”¨æ™ºèƒ½fallbackè‡ªåŠ¨è·å–Seuratæ–‡ä»¶è·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_get_input_path
            rds_path = auto_get_input_path(
                manual_path=rds_path,
                bundle_keys=['rds_file', 'sce_h5', 'scanpy_h5', 'h5_file'],
                tool_name='sctype_annotate_tool'
            )
        except Exception as e:
            return json.dumps({
                "success": False,
                "error": f"è‡ªåŠ¨è·å–Seuratè·¯å¾„å¤±è´¥: {e}"
            }, ensure_ascii=False, indent=2)

        # MCPå±‚è‡ªåŠ¨ç”Ÿæˆoutput_pathï¼ˆä½¿ç”¨ _CONFIG çš„ results_dirï¼‰
        ts = get_session_id_for_filename() or datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = _CONFIG.get_results_dir()
        output_path = str(results_dir / f'sctype_annotation_result_{ts}.json')

        # ğŸ”¬ æ‰§è¡ŒscTypeæ³¨é‡Šï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰

        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, sctype_annotate, rds_path, tissue_type, output_path, cluster_column
        )

        resolved_output = output_path
        if isinstance(result, dict) and result.get("output_file"):
            resolved_output = result.get("output_file")

        # 2. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜sctype_resultè·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_update_bundle
            auto_update_bundle('sctype_result', resolved_output)
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°bundleå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        return json.dumps({
            "success": True,
            "data": result,
            "input_file": rds_path,
            "tissue_type": tissue_type,
            "output_file": resolved_output,
            "cluster_column": cluster_column,
            "message": "scTypeæ³¨é‡Šå®Œæˆ",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"scTypeæ³¨é‡Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

# ============ CellTypist ç›¸å…³å·¥å…· ============

@mcp.tool()
async def get_celltypist_models_tool() -> str:
    """
    è·å–CellTypistæ‰€æœ‰å¯ç”¨æ¨¡å‹
    
    Returns:
        åŒ…å«æ¨¡å‹åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, get_celltypist_models
        )
        
        return json.dumps({
            "success": True,
            "data": result,
            "message": "æˆåŠŸè·å–CellTypistæ¨¡å‹",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"è·å–CellTypistæ¨¡å‹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def celltypist_annotate_tool(
    data_path: Optional[str] = None,
    model_name: Optional[str] = None,
    auto_detect_species: bool = True,
    cluster_column: Optional[str] = None,
) -> str:
    """
    ä½¿ç”¨CellTypistè¿›è¡Œç»†èƒç±»å‹æ³¨é‡Šï¼ˆè‡ªåŠ¨åŒ–ç‰ˆæœ¬ï¼‰

    æ­¤å·¥å…·å®Œå…¨è‡ªåŠ¨åŒ–å¤„ç†CellTypistæ³¨é‡Šæµç¨‹ï¼š
    1. è‡ªåŠ¨ä»bundleè¯»å–H5ADæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆh5ad_fileï¼Œé™çº§h5_fileï¼‰
    2. è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨session_idå‘½å
    3. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜celltypist_resultè·¯å¾„

    Args:
        data_path: H5ADæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨ä»bundleè¯»å–ï¼‰
        model_name: CellTypistæ¨¡å‹åç§°ï¼Œä¸ºNoneæ—¶æ ¹æ®ç‰©ç§è‡ªåŠ¨é€‰æ‹©
        output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
        auto_detect_species: æ˜¯å¦è‡ªåŠ¨æ£€æµ‹ç‰©ç§å¹¶é€‰æ‹©åˆé€‚æ¨¡å‹
        cluster_column: èšç±»åˆ—åï¼Œä¸ºNoneæ—¶è‡ªåŠ¨æœç´¢

    Returns:
        æ³¨é‡Šç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        # 1. ä½¿ç”¨æ™ºèƒ½fallbackè‡ªåŠ¨è·å–H5ADæ–‡ä»¶è·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_get_input_path
            data_path = auto_get_input_path(
                manual_path=data_path,
                bundle_keys=['h5ad_file', 'scanpy_h5', 'sce_h5', 'h5_file'],
                tool_name='celltypist_annotate_tool'
            )
        except Exception as e:
            return json.dumps({
                "success": False,
                "error": f"è‡ªåŠ¨è·å–H5ADè·¯å¾„å¤±è´¥: {e}"
            }, ensure_ascii=False, indent=2)

        # MCPå±‚è‡ªåŠ¨ç”Ÿæˆoutput_pathï¼ˆä¸æ¥å—å¤–éƒ¨è¾“å…¥ï¼‰
        ts = get_session_id_for_filename() or datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = _CONFIG.get_results_dir()
        output_path = str(results_dir / f'celltypist_annotation_result_{ts}.json')

        # ğŸ”¬ æ‰§è¡ŒCellTypistæ³¨é‡Šï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰

        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        result = await asyncio.get_event_loop().run_in_executor(
            None, celltypist_annotate, data_path, model_name, output_path, auto_detect_species, cluster_column
        )

        resolved_output = output_path
        if isinstance(result, dict) and result.get("output_file"):
            resolved_output = result.get("output_file")

        # 2. è‡ªåŠ¨æ›´æ–°bundleï¼Œä¿å­˜celltypist_resultè·¯å¾„
        try:
            from agentype.mainagent.tools.file_paths_tools import auto_update_bundle
            auto_update_bundle('celltypist_result', resolved_output)
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°bundleå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        return json.dumps({
            "success": True,
            "data": result,
            "input_file": data_path,
            "model_name": model_name,
            "output_file": resolved_output,
            "auto_detect_species": auto_detect_species,
            "cluster_column": cluster_column,
            "message": "CellTypistæ³¨é‡Šå®Œæˆ",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"CellTypistæ³¨é‡Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

# ============ ç‰©ç§æ£€æµ‹ç›¸å…³å·¥å…· ============

@mcp.tool()
async def detect_species_from_h5ad_tool(h5ad_file: str) -> str:
    """
    ä»H5ADæ–‡ä»¶æ£€æµ‹ç‰©ç§
    
    Args:
        h5ad_file: H5ADæ–‡ä»¶è·¯å¾„
    
    Returns:
        ç‰©ç§æ£€æµ‹ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ğŸ”¬ ä»H5ADæ–‡ä»¶æ£€æµ‹ç‰©ç§ï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        species, detection_info = await asyncio.get_event_loop().run_in_executor(
            None, detect_species_from_h5ad, h5ad_file
        )
        
        return json.dumps({
            "success": True,
            "detected_species": species,
            "detection_details": detection_info,
            "message": f"H5ADæ–‡ä»¶ç‰©ç§æ£€æµ‹å®Œæˆ: {species}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"H5ADæ–‡ä»¶ç‰©ç§æ£€æµ‹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "detected_species": "Human",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def detect_species_from_rds_tool(rds_file: str) -> str:
    """
    ä»RDSæ–‡ä»¶æ£€æµ‹ç‰©ç§
    
    Args:
        rds_file: RDSæ–‡ä»¶è·¯å¾„
    
    Returns:
        ç‰©ç§æ£€æµ‹ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()
        
        # ğŸ”¬ ä»RDSæ–‡ä»¶æ£€æµ‹ç‰©ç§ï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰
        
        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        species, detection_info = await asyncio.get_event_loop().run_in_executor(
            None, detect_species_from_rds, rds_file
        )
        
        return json.dumps({
            "success": True,
            "detected_species": species,
            "detection_details": detection_info,
            "message": f"RDSæ–‡ä»¶ç‰©ç§æ£€æµ‹å®Œæˆ: {species}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"RDSæ–‡ä»¶ç‰©ç§æ£€æµ‹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "detected_species": "Human",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def detect_species_from_marker_json_tool(marker_genes_json: str) -> str:
    """
    ä»markeråŸºå› JSONæ–‡ä»¶æ£€æµ‹ç‰©ç§

    Args:
        marker_genes_json: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„

    Returns:
        ç‰©ç§æ£€æµ‹ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()

        # ğŸ”¬ ä»JSONæ–‡ä»¶æ£€æµ‹ç‰©ç§ï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰

        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        species, detection_info = await asyncio.get_event_loop().run_in_executor(
            None, detect_species_from_marker_json, marker_genes_json
        )
        
        return json.dumps({
            "success": True,
            "detected_species": species,
            "detection_details": detection_info,
            "message": f"JSONæ–‡ä»¶ç‰©ç§æ£€æµ‹å®Œæˆ: {species}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"JSONæ–‡ä»¶ç‰©ç§æ£€æµ‹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "detected_species": "Human",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

# ============ æ–‡ä»¶éªŒè¯ç›¸å…³å·¥å…· ============

@mcp.tool()
async def validate_marker_json_tool(marker_genes_json: str) -> str:
    """
    éªŒè¯markeråŸºå› JSONæ–‡ä»¶æ ¼å¼

    Args:
        marker_genes_json: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„

    Returns:
        æ–‡ä»¶éªŒè¯ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        ensure_cache_dir()

        # ğŸ“‹ éªŒè¯markeråŸºå› JSONæ–‡ä»¶ï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰

        # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨è°ƒç”¨å¤„ç†å‡½æ•°
        validation_result = await asyncio.get_event_loop().run_in_executor(
            None, validate_marker_json, marker_genes_json
        )
        
        return json.dumps({
            "success": True,
            "validation_result": validation_result,
            "message": f"JSONæ–‡ä»¶éªŒè¯å®Œæˆ: {'æœ‰æ•ˆ' if validation_result.get('valid') else 'æ— æ•ˆ'}",
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"éªŒè¯JSONæ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
            "validation_result": {"valid": False, "errors": [str(e)]},
            "timestamp": get_session_id_for_filename()
        }, ensure_ascii=False, indent=2)

@mcp.tool()
async def get_token_stats() -> str:
    """è·å–AppAgentçš„tokenæ¶ˆè€—ç»Ÿè®¡ä¿¡æ¯

    Returns:
        str: JSONæ ¼å¼çš„tokenç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # ç”±äºMCPæœåŠ¡å™¨æ˜¯ç‹¬ç«‹è¿›ç¨‹ï¼Œè¿™é‡Œè¿”å›é»˜è®¤çš„ç©ºç»Ÿè®¡
        # å®é™…çš„tokenç»Ÿè®¡éœ€è¦é€šè¿‡agentå®ä¾‹è·å–
        from agentype.common.token_statistics import TokenStatistics

        # åˆ›å»ºä¸€ä¸ªç©ºçš„ç»Ÿè®¡å¯¹è±¡ä½œä¸ºå ä½ç¬¦
        # å®é™…åº”è¯¥é€šè¿‡æŸç§IPCæœºåˆ¶æˆ–å…±äº«å­˜å‚¨è·å–çœŸå®æ•°æ®
        stats = TokenStatistics(agent_name="AppAgent")

        return json.dumps({
            "success": True,
            "data": stats.to_dict(),
            "message": "AppAgent tokenç»Ÿè®¡ (MCPæœåŠ¡å™¨ç‹¬ç«‹è¿›ç¨‹)"
        }, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"è·å–tokenç»Ÿè®¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
        }, ensure_ascii=False, indent=2)


# ========== è·¯å¾„ç®¡ç†å·¥å…· ==========

@mcp.tool()
async def save_file_paths_bundle(
    rds_file: Optional[str] = None,
    h5ad_file: Optional[str] = None,
    h5_file: Optional[str] = None,
    marker_genes_json: Optional[str] = None,
    singler_result: Optional[str] = None,
    sctype_result: Optional[str] = None,
    celltypist_result: Optional[str] = None
) -> str:
    """ä¿å­˜æ‰€æœ‰7ä¸ªæ ¸å¿ƒæ–‡ä»¶è·¯å¾„åˆ°cacheç›®å½•ï¼ˆAppAgentç‰ˆæœ¬ï¼‰

    æ­¤å·¥å…·ç”¨äºåœ¨ç»†èƒæ³¨é‡Šå®Œæˆåä¿å­˜æ‰€æœ‰å…³é”®æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…æ‹¬æ•°æ®æ–‡ä»¶å’Œæ³¨é‡Šç»“æœæ–‡ä»¶ã€‚

    Args:
        rds_file: RDSæ–‡ä»¶è·¯å¾„
        h5ad_file: H5ADæ–‡ä»¶è·¯å¾„
        h5_file: H5æ–‡ä»¶è·¯å¾„ï¼ˆeasySCFæ ¼å¼ï¼‰
        marker_genes_json: MarkeråŸºå› JSONæ–‡ä»¶è·¯å¾„
        singler_result: SingleRæ³¨é‡Šç»“æœæ–‡ä»¶è·¯å¾„
        sctype_result: scTypeæ³¨é‡Šç»“æœæ–‡ä»¶è·¯å¾„
        celltypist_result: CellTypistæ³¨é‡Šç»“æœæ–‡ä»¶è·¯å¾„

    Returns:
        JSONæ ¼å¼çš„ä¿å­˜ç»“æœï¼ŒåŒ…å«æˆåŠŸçŠ¶æ€ã€session_idã€ä¿å­˜è·¯å¾„ç­‰ä¿¡æ¯

    ä½¿ç”¨åœºæ™¯ï¼š
        - åœ¨å®Œæˆç»†èƒç±»å‹æ³¨é‡Šåç«‹å³è°ƒç”¨ï¼Œä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        - ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®ï¼ˆç‰¹åˆ«æ³¨æ„ä¸­æ–‡è·¯å¾„çš„åˆ†éš”ç¬¦ï¼‰
        - å¦‚æœä¿å­˜å¤±è´¥ï¼Œæ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®æ­£è·¯å¾„åé‡è¯•
    """
    try:
        # marker_genes_json æ˜¯ AppAgent çš„å¿…éœ€è¾“å…¥
        if not marker_genes_json or marker_genes_json.strip() == "":
            return json.dumps({
                "success": False,
                "error": "âŒ marker_genes_json æ˜¯å¿…éœ€çš„ï¼AppAgent éœ€è¦ marker åŸºå›  JSON æ–‡ä»¶è¿›è¡Œç»†èƒç±»å‹æ³¨é‡Šã€‚",
                "action_required": "è¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š",
                "available_actions": [
                    "1. ä½¿ç”¨ load_file_paths_bundle å·¥å…·åŠ è½½ä¹‹å‰ DataAgent ä¿å­˜çš„è·¯å¾„",
                    "2. æ£€æŸ¥ DataAgent æ˜¯å¦æˆåŠŸå®Œæˆæ•°æ®å¤„ç†å¹¶ç”Ÿæˆäº† JSON æ–‡ä»¶",
                    "3. å¦‚æœ JSON æ–‡ä»¶ç¡®å®ç¼ºå¤±ï¼Œè¯·é€šçŸ¥ MainAgent é‡æ–°è¿è¡Œ DataAgent æ­¥éª¤"
                ]
            }, ensure_ascii=False, indent=2)

        # æ„å»º metadataï¼ˆè‡ªåŠ¨æ·»åŠ  AppAgent æ ‡è®°ï¼‰
        metadata_dict = {
            "agent": "AppAgent",
            "stage": "annotation"
        }

        # è°ƒç”¨æ ¸å¿ƒå‡½æ•°ï¼ˆsession_id ç”±åº•å±‚å‡½æ•°è‡ªåŠ¨è·å–ï¼Œä½¿ç”¨é»˜è®¤è¿‡æœŸæ—¶é—´ï¼‰
        result = _save_file_paths_bundle(
            rds_file=rds_file,
            h5ad_file=h5ad_file,
            h5_file=h5_file,
            marker_genes_json=marker_genes_json,
            singler_result=singler_result,
            sctype_result=sctype_result,
            celltypist_result=celltypist_result,
            metadata=metadata_dict
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"ä¿å­˜æ–‡ä»¶è·¯å¾„åŒ…å¼‚å¸¸: {e}"
        }, ensure_ascii=False, indent=2)


@mcp.tool()
async def load_file_paths_bundle() -> str:
    """ä»cacheç›®å½•åŠ è½½å½“å‰ä¼šè¯çš„æ–‡ä»¶è·¯å¾„

    æ­¤å·¥å…·ç”¨äºåŠ è½½ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ•°æ®æ–‡ä»¶å’Œæ³¨é‡Šç»“æœæ–‡ä»¶ã€‚

    Returns:
        JSONæ ¼å¼çš„è·¯å¾„ä¿¡æ¯ï¼ŒåŒ…å« rds_file, h5ad_file, h5_file, marker_genes_json,
        singler_result, sctype_result, celltypist_result ç­‰

    ä½¿ç”¨åœºæ™¯ï¼š
        - å½“éœ€è¦è·å–ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶è·¯å¾„æ—¶
        - è·¨æ­¥éª¤ä¼ é€’æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    """
    try:
        result = _load_and_validate_bundle()  # ä½¿ç”¨éªŒè¯ç‰ˆæœ¬æ›´å®‰å…¨
        return json.dumps(result, ensure_ascii=False, indent=2)
    except Exception as e:
        return json.dumps({
            "success": False,
            "error": f"åŠ è½½æ–‡ä»¶è·¯å¾„åŒ…å¼‚å¸¸: {e}"
        }, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    """
    å¯åŠ¨ AppAgent MCP æœåŠ¡å™¨

    é…ç½®é€šè¿‡æ··åˆæ–¹æ¡ˆä¼ é€’ï¼š
    - æ•æ„Ÿä¿¡æ¯ï¼ˆAPI Keyï¼‰é€šè¿‡ç¯å¢ƒå˜é‡ OPENAI_API_KEY
    - éæ•æ„Ÿé…ç½®é€šè¿‡å‘½ä»¤è¡Œå‚æ•°
    """
    import argparse
    import os
    import sys
    from pathlib import Path
    from agentype.mainagent.config.session_config import set_session_id

    # 1. è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='CellType AppAgent MCP Server')
    parser.add_argument('--api-base', type=str, help='LLM API Base URL (required)')
    parser.add_argument('--model', type=str, default='gpt-4o', help='LLM Model name')
    parser.add_argument('--output-dir', type=str, required=True, help='Output directory (required)')
    parser.add_argument('--language', type=str, default='zh', choices=['zh', 'en'], help='Language')
    parser.add_argument('--enable-streaming', type=str, default='true', help='Enable streaming output')
    parser.add_argument('--enable-thinking', type=str, default='false', help='Enable thinking output')
    parser.add_argument('--session-id', type=str, help='Session ID for tracking')
    args = parser.parse_args()

    # 2. ä»ç¯å¢ƒå˜é‡è¯»å– API Keyï¼ˆå®‰å…¨ï¼‰
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡", file=sys.stderr)
        print("   AppAgent MCP Server éœ€è¦ API Key æ‰èƒ½è¿è¡Œ", file=sys.stderr)
        sys.exit(1)

    # 3. éªŒè¯å¿…éœ€çš„å‘½ä»¤è¡Œå‚æ•°
    if not args.api_base:
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€å‚æ•° --api-base", file=sys.stderr)
        sys.exit(1)

    # 4. åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir).resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # 4.5. åˆ›å»ºConfigManagerå¹¶è®¾ç½®ä¸ºæ¨¡å—çº§é…ç½®å¯¹è±¡
    from agentype.appagent.config.settings import ConfigManager

    enable_thinking = args.enable_thinking.lower() in ('true', '1', 'yes')

    _CONFIG = ConfigManager(
        openai_api_base=args.api_base,
        openai_api_key=api_key,
        openai_model=args.model,
        output_dir=str(output_dir),  # ä¼ é€’output_dirï¼Œè®©ConfigManagerè‡ªåŠ¨æ´¾ç”Ÿcache_dir
        enable_thinking=enable_thinking
    )

    # æ›´æ–°å…¨å±€ CACHE_DIRï¼ˆä» _CONFIG è·å–ï¼‰
    CACHE_DIR = _CONFIG.cache_dir

    print(f"âœ… AppAgent ConfigManager å·²åˆå§‹åŒ–:", file=sys.stderr)
    print(f"   Output Dir: {_CONFIG.output_dir}", file=sys.stderr)
    print(f"   Results Dir: {_CONFIG.results_dir}", file=sys.stderr)
    print(f"   Cache Dir: {_CONFIG.cache_dir}", file=sys.stderr)

    # åˆå§‹åŒ–ç¼“å­˜ï¼ˆä½¿ç”¨ ConfigManagerï¼‰
    from agentype.appagent.config.cache_config import init_cache
    cache_dir = init_cache(config=_CONFIG)

    # è®¾ç½®å·¥å…·æ¨¡å—çš„å…¨å±€é…ç½®ï¼ˆç”¨äº file_paths_toolsï¼‰
    from agentype.mainagent.tools.file_paths_tools import set_global_config
    set_global_config(_CONFIG)

    # 5. è®¾ç½® session_id
    if args.session_id:
        set_session_id(args.session_id)
        print(f"âœ… AppAgent MCP Server ä½¿ç”¨ session_id: {args.session_id}", file=sys.stderr)

    # 6. æ‰“å°é…ç½®ä¿¡æ¯
    print(f"âœ… AppAgent MCP Server é…ç½®:", file=sys.stderr)
    print(f"   API Base: {args.api_base}", file=sys.stderr)
    print(f"   Model: {args.model}", file=sys.stderr)
    
    # å¯åŠ¨MCPæœåŠ¡å™¨ (æ ‡å‡†stdioä¼ è¾“)
    # ğŸš€ å¯åŠ¨CellType App Agent MCPæœåŠ¡å™¨ï¼ˆé™é»˜æ¨¡å¼ï¼‰
    # ğŸ“‹ åè®®: Model Context Protocol (MCP)
    # ğŸ”§ å¯ç”¨å·¥å…·: 15ä¸ª
    # ğŸ“Š æ ¸å¿ƒå·¥å…·ï¼ˆé™é»˜æ¨¡å¼ï¼Œé¿å…æ±¡æŸ“ MCP stdoutï¼‰
    # 1ï¸âƒ£  get_celldex_projects_info_tool - è·å–celldexæ•°æ®é›†ä¿¡æ¯
    # 2ï¸âƒ£  download_celldex_dataset_tool - ä¸‹è½½celldexæ•°æ®é›†
    # 3ï¸âƒ£  singleR_annotate_tool - SingleRç»†èƒç±»å‹æ³¨é‡Š
    # 4ï¸âƒ£  get_sctype_tissues_tool - è·å–scTypeç»„ç»‡ç±»å‹
    # 5ï¸âƒ£  sctype_annotate_tool - scTypeç»†èƒç±»å‹æ³¨é‡Š
    # 6ï¸âƒ£  get_celltypist_models_tool - è·å–CellTypistæ¨¡å‹
    # 7ï¸âƒ£  celltypist_annotate_tool - CellTypistç»†èƒç±»å‹æ³¨é‡Š
    # 8ï¸âƒ£  celltype_annotation_pipeline - ç»Ÿä¸€æ³¨é‡Šæµæ°´çº¿
    # 9ï¸âƒ£  detect_species_from_h5ad_tool - ä»H5ADæ–‡ä»¶æ£€æµ‹ç‰©ç§
    # ğŸ”Ÿ  detect_species_from_rds_tool - ä»RDSæ–‡ä»¶æ£€æµ‹ç‰©ç§
    # 1ï¸âƒ£1ï¸âƒ£ detect_species_from_marker_json_tool - ä»JSONæ–‡ä»¶æ£€æµ‹ç‰©ç§
    # 1ï¸âƒ£2ï¸âƒ£ validate_marker_json_tool - éªŒè¯markeråŸºå› JSONæ–‡ä»¶
    # 1ï¸âƒ£3ï¸âƒ£ get_token_stats - è·å–tokenç»Ÿè®¡ä¿¡æ¯
    # 1ï¸âƒ£4ï¸âƒ£ save_file_paths_bundle - ä¿å­˜æ–‡ä»¶è·¯å¾„åˆ°cache
    # 1ï¸âƒ£5ï¸âƒ£ load_file_paths_bundle - ä»cacheåŠ è½½æ–‡ä»¶è·¯å¾„
    # MCP æœåŠ¡å™¨å¯åŠ¨å®Œæˆï¼ˆé™é»˜æ¨¡å¼ï¼‰
    mcp.run(transport='stdio')
