#!/usr/bin/env python3
"""
agentype - ç°‡ç›¸å…³å·¥å…·é›†åˆ
Author: cuilei
Version: 1.0
"""

from __future__ import annotations

import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, Optional, Iterable, List, Union

# å¯¼å…¥é¡¹ç›®æ¨¡å—

# å¯¼å…¥ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
from agentype.config import get_session_id_for_filename
from agentype.prompts import get_prompt_manager

# å¯¼å…¥ä¼šè¯é…ç½®
try:
    from agentype.mainagent.config.session_config import get_session_id
    USE_SESSION_ISOLATION = True
except ImportError:
    USE_SESSION_ISOLATION = False
    def get_session_id():
        """å›é€€å‡½æ•°ï¼šå¦‚æœä¼šè¯é…ç½®ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å€¼"""
        return "default"


# ========== å…±ç”¨è¾…åŠ©å‡½æ•° ==========

def _auto_load_file_path(path_key: str) -> Optional[str]:
    """è‡ªåŠ¨åŠ è½½å½“å‰ session çš„æ–‡ä»¶è·¯å¾„

    Args:
        path_key: è·¯å¾„é”®åï¼Œå¦‚ 'marker_genes_json', 'singler_result', 'sctype_result', 'celltypist_result'

    Returns:
        æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å› None
    """
    try:
        from agentype.mainagent.tools.file_paths_tools import load_file_paths_bundle
        bundle = load_file_paths_bundle()
        if bundle.get("success"):
            return bundle.get(path_key)
    except Exception:
        pass
    return None

def _load_json(file_path: str) -> Optional[Dict[str, Any]]:
    """å®‰å…¨åœ°åŠ è½½ JSON æ–‡ä»¶ã€‚

    Args:
        file_path: JSON æ–‡ä»¶è·¯å¾„

    Returns:
        è§£æåçš„ JSON æ•°æ®ï¼Œå¦‚æœåŠ è½½å¤±è´¥åˆ™è¿”å› None
    """
    try:
        path = Path(file_path)
        if not path.exists():
            return None
        with path.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


def _normalize_cluster_key(keys: Iterable[str], cluster: str) -> Optional[str]:
    """æŸ¥æ‰¾æœ€åŒ¹é…çš„ç°‡é”®åã€‚

    æ¥å— "1", 1, "cluster1" ç­‰è¾“å…¥ï¼Œå°è¯•åŒ¹é… "cluster1" ç­‰é”®åã€‚

    Args:
        keys: å¯ç”¨çš„é”®åé›†åˆ
        cluster: è¦åŒ¹é…çš„ç°‡æ ‡è¯†ç¬¦

    Returns:
        åŒ¹é…çš„é”®åï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    s = str(cluster).strip()
    candidates = []

    if s.lower().startswith("cluster"):
        candidates.append(s)
        # ä¹Ÿå°è¯•æ•°å­—éƒ¨åˆ†
        tail = s[7:]
        if tail:
            candidates.append(tail)
    else:
        candidates.append(s)
        candidates.append(f"cluster{s}")

    key_set = {str(k) for k in keys}
    for cand in candidates:
        if cand in key_set:
            return cand

    # ä¸åŒºåˆ†å¤§å°å†™çš„åå¤‡åŒ¹é…
    lower_map = {str(k).lower(): str(k) for k in keys}
    for cand in candidates:
        if cand.lower() in lower_map:
            return lower_map[cand.lower()]

    return None


# ========== ç°‡æ³¨é‡Šä¿å­˜/åŠ è½½åŠŸèƒ½ï¼ˆåŸ cluster_saver.pyï¼‰==========

def _get_default_dir() -> str:
    """è·å–é»˜è®¤å­˜å‚¨ç›®å½•ï¼ˆä»å…¨å±€é…ç½®è·å–ï¼‰"""
    from pathlib import Path as _Path
    from agentype.mainagent.tools.file_paths_tools import _GLOBAL_CONFIG

    # ä¼˜å…ˆä½¿ç”¨å…¨å±€é…ç½®çš„ results_dir
    if _GLOBAL_CONFIG and hasattr(_GLOBAL_CONFIG, 'results_dir'):
        default_results_dir = _Path(_GLOBAL_CONFIG.results_dir)
        default_results_dir.mkdir(parents=True, exist_ok=True)
        return str(default_results_dir)
    else:
        # ä¸å†å›é€€ï¼ŒæŠ›å‡ºæ˜ç¡®é”™è¯¯
        raise RuntimeError(
            "å…¨å±€é…ç½®æœªåˆå§‹åŒ–ï¼cluster_tools éœ€è¦æœ‰æ•ˆçš„é…ç½®ã€‚\n"
            "è¯·ç¡®ä¿åœ¨ä½¿ç”¨æ­¤å·¥å…·å‰ï¼ŒMCP Server å·²æ­£ç¡®å¯åŠ¨å¹¶è°ƒç”¨äº† set_global_config()ã€‚"
        )

# ä¸å†åœ¨æ¨¡å—çº§è°ƒç”¨ï¼ˆå»¶è¿Ÿåˆ°ä½¿ç”¨æ—¶ï¼‰
DEFAULT_DIR = None


def save_cluster_type(
    cluster_id: Union[str, int],
    cell_type: Union[str, int],
) -> Dict[str, Any]:
    """ä¿å­˜å•ä¸ªclusterçš„æ³¨é‡Šåˆ°bundleï¼Œå¹¶è‡ªåŠ¨æ£€æµ‹å®Œæˆåº¦ã€‚

    å°†clusteræ˜ å°„ç›´æ¥ä¿å­˜åœ¨bundleæ–‡ä»¶ä¸­ï¼Œä¿å­˜åè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ç°‡çš„å®Œæˆåº¦ã€‚

    Args:
        cluster_id: ç°‡ID
        cell_type: ç»†èƒç±»å‹

    Returns:
        åŒ…å«ä¿å­˜çŠ¶æ€å’Œå®Œæˆåº¦ä¿¡æ¯çš„å­—å…¸ï¼š
        {
            "success": True,
            "cluster_id": "cluster0",
            "cell_type": "T cell",
            "completion_status": {
                "all_completed": False,
                "total_clusters": 15,
                "completed_clusters": 1,
                "completion_rate": 0.067,
                "incomplete_clusters": ["cluster1", "cluster2", ...]
            },
            "reminder": "ğŸ“Š å½“å‰è¿›åº¦ï¼šå·²å®Œæˆ 1/15 ä¸ªç°‡ (6.7%)ã€‚è¿˜æœ‰æœªå®Œæˆçš„ç°‡ï¼šcluster1, cluster2, cluster3, cluster4, cluster5 ç­‰å…±14ä¸ªã€‚è¯·ç»§ç»­å¤„ç†å‰©ä½™çš„ç°‡ã€‚"
        }

    Raises:
        IOError: ä¿å­˜å¤±è´¥æ—¶æŠ›å‡º
    """
    try:
        from agentype.mainagent.tools.file_paths_tools import save_cluster_mapping

        # 1. ä¿å­˜ç°‡æ˜ å°„
        result = save_cluster_mapping(str(cluster_id), str(cell_type))

        if not result.get("success"):
            raise IOError(f"ä¿å­˜cluster {cluster_id}={cell_type}å¤±è´¥: {result.get('error')}")

        # 2. è‡ªåŠ¨æ£€æµ‹å®Œæˆåº¦
        completion_status = check_cluster_completion()

        # 3. ç”Ÿæˆæ™ºèƒ½æé†’
        manager = get_prompt_manager()
        if completion_status.get("all_completed"):
            template = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_PROGRESS_COMPLETE_MESSAGE')
            next_action = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_PROGRESS_ACTION_PHASE5')
            reminder = template.format(
                total_clusters=completion_status['total_clusters'],
                next_action=next_action
            )
        else:
            # æœªå®Œæˆçš„æƒ…å†µ
            completed = completion_status["completed_clusters"]
            total = completion_status["total_clusters"]
            incomplete = completion_status["incomplete_clusters"]

            # ç”Ÿæˆæœªå®Œæˆç°‡çš„é¢„è§ˆï¼ˆæœ€å¤šæ˜¾ç¤º5ä¸ªï¼‰
            incomplete_preview = ", ".join(incomplete[:5])
            if len(incomplete) > 5:
                suffix_template = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_PROGRESS_INCOMPLETE_PREVIEW_SUFFIX')
                incomplete_preview += suffix_template.format(count=len(incomplete))

            template = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_PROGRESS_INCOMPLETE_MESSAGE')
            next_action = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_PROGRESS_ACTION_CONTINUE')
            reminder = template.format(
                completed=completed,
                total=total,
                completion_rate=completion_status["completion_rate"],
                incomplete_preview=incomplete_preview,
                next_action=next_action
            )

        # 4. è¿”å›å®Œæ•´ä¿¡æ¯
        return {
            "success": True,
            "cluster_id": str(cluster_id),
            "cell_type": str(cell_type),
            "completion_status": completion_status,
            "reminder": reminder
        }

    except Exception as e:
        import logging
        logging.error(f"ä¿å­˜cluster {cluster_id}={cell_type}æ—¶å‡ºé”™: {e}")
        raise IOError(f"ä¿å­˜clusterå¤±è´¥: {e}")


def load_cluster_types() -> Dict[str, str]:
    """ä»bundleåŠ è½½æ‰€æœ‰clusteræ˜ å°„æ•°æ®ã€‚

    ç›´æ¥ä»bundleæ–‡ä»¶çš„cluster_mappingå­—æ®µè¯»å–æ•°æ®ã€‚

    Returns:
        ç°‡IDåˆ°ç»†èƒç±»å‹çš„æ˜ å°„å­—å…¸
    """
    try:
        from agentype.mainagent.tools.file_paths_tools import load_cluster_mapping
        return load_cluster_mapping()
    except Exception:
        return {}


# ========== ç°‡ç»“æœè¯»å–åŠŸèƒ½ï¼ˆåŸ cluster_result_reader.pyï¼‰==========

def _extract_for_cluster(data: Dict[str, Any], cluster: str) -> Optional[Dict[str, Any]]:
    """ä»æ³¨é‡Šæ•°æ®ä¸­æå–æŒ‡å®šç°‡çš„ä¿¡æ¯ã€‚

    Args:
        data: æ³¨é‡Šç»“æœæ•°æ®
        cluster: ç°‡æ ‡è¯†ç¬¦

    Returns:
        æå–çš„ç°‡ä¿¡æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    if not data:
        return None
    annotations = data.get("cluster_annotations")
    if not isinstance(annotations, dict):
        return None
    match_key = _normalize_cluster_key(annotations.keys(), cluster)
    if match_key is None:
        return None
    entry = annotations.get(match_key)
    if not isinstance(entry, dict):
        return None
    # Return the most useful subset, present across tools
    result: Dict[str, Any] = {
        "celltype": entry.get("celltype"),
        "proportion": entry.get("proportion"),
    }
    # include confidence if available (SingleR/scType)
    if "confidence" in entry:
        result["confidence"] = entry.get("confidence")
    return result


def read_cluster_results(
    cluster: str,
    singler_result: Optional[str] = None,
    sctype_result: Optional[str] = None,
    celltypist_result: Optional[str] = None,
) -> Dict[str, Any]:
    """ä»ä¸‰ç§æ–¹æ³•çš„ç»“æœ JSON ä¸­è¯»å–æŒ‡å®šç°‡çš„åˆå¹¶ç»“æœã€‚

    Args:
        cluster: ç°‡IDï¼Œä¾‹å¦‚ "1" æˆ– "cluster1"
        singler_result: SingleR ç»“æœ JSON è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ç»“æœæ–‡ä»¶
        sctype_result: scType ç»“æœ JSON è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ç»“æœæ–‡ä»¶
        celltypist_result: CellTypist ç»“æœ JSON è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ç»“æœæ–‡ä»¶

    Returns:
        åŒ…å«å„æ–¹æ³•ç»“æœçš„åˆå¹¶å­—å…¸
    """
    # ğŸŒŸ è‡ªåŠ¨åŠ è½½å½“å‰ session çš„ç»“æœæ–‡ä»¶è·¯å¾„
    if singler_result is None or sctype_result is None or celltypist_result is None:
        try:
            from agentype.mainagent.tools.file_paths_tools import load_file_paths_bundle
            bundle = load_file_paths_bundle()
            if bundle.get("success"):
                if singler_result is None:
                    singler_result = bundle.get("singler_result") or ""
                if sctype_result is None:
                    sctype_result = bundle.get("sctype_result") or ""
                if celltypist_result is None:
                    celltypist_result = bundle.get("celltypist_result") or ""
        except Exception:
            # å¦‚æœè‡ªåŠ¨åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºåå¤‡
            if singler_result is None:
                singler_result = ""
            if sctype_result is None:
                sctype_result = ""
            if celltypist_result is None:
                celltypist_result = ""

    sr = _load_json(singler_result) if singler_result else None
    sc = _load_json(sctype_result) if sctype_result else None
    ct = _load_json(celltypist_result) if celltypist_result else None

    # Normalize cluster label in output (e.g., 1 -> cluster1, cluster1 -> cluster1)
    s = str(cluster).strip()
    out = {
        "cluster": f"cluster{s[7:]}" if s.lower().startswith("cluster") else f"cluster{s}",
        "files": {
            "singler": singler_result,
            "sctype": sctype_result,
            "celltypist": celltypist_result,
        },
        "results": {
            "SingleR": _extract_for_cluster(sr, cluster),
            "scType": _extract_for_cluster(sc, cluster),
            "CellTypist": _extract_for_cluster(ct, cluster),
        },
    }
    # success if at least one method found a result
    out["success"] = any(v is not None for v in out["results"].values())
    return out


# ========== åŸºå› æå–åŠŸèƒ½ï¼ˆåŸ cluster_gene_extractor.pyï¼‰==========

def extract_cluster_genes(cluster_name: str, gene_count: int = 50, marker_genes_json_path: Optional[str] = None) -> List[str]:
    """ä» JSON æ–‡ä»¶ä¸­æå–æŒ‡å®šç°‡çš„åŸºå› ã€‚

    Args:
        cluster_name: ç°‡åç§°ï¼ˆæ”¯æŒ "1", "cluster1" ç­‰æ ¼å¼ï¼‰
        gene_count: è¦æå–çš„åŸºå› æ•°é‡
        marker_genes_json_path: JSON æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        åŸºå› åç§°åˆ—è¡¨

    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: ç°‡ä¸å­˜åœ¨æˆ– gene_count æ— æ•ˆ
        Exception: JSON è§£æé”™è¯¯æˆ–å…¶ä»–é”™è¯¯
    """
    # å‚æ•°éªŒè¯
    if gene_count <= 0:
        raise ValueError("åŸºå› æ•°é‡å¿…é¡»å¤§äº 0")

    # ğŸŒŸ è‡ªåŠ¨åŠ è½½å½“å‰ session çš„ marker_genes_json è·¯å¾„
    if marker_genes_json_path is None:
        marker_genes_json_path = _auto_load_file_path("marker_genes_json")
        if marker_genes_json_path is None:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ°å½“å‰ session çš„ marker genes æ–‡ä»¶ã€‚"
                "è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆ marker genesï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š marker_genes_json_path å‚æ•°ã€‚"
            )

    # åŠ è½½ JSON æ–‡ä»¶
    data = _load_json(marker_genes_json_path)
    if data is None:
        if not Path(marker_genes_json_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {marker_genes_json_path}")
        else:
            raise Exception(f"æ— æ³•è§£æ JSON æ–‡ä»¶: {marker_genes_json_path}")

    # æŸ¥æ‰¾åŒ¹é…çš„ç°‡é”®
    cluster_key = _normalize_cluster_key(data.keys(), cluster_name)
    if cluster_key is None:
        available_clusters = list(data.keys())
        raise ValueError(f"ç°‡ '{cluster_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨çš„ç°‡: {available_clusters}")

    # è·å–åŸºå› åˆ—è¡¨
    genes = data.get(cluster_key)
    if not isinstance(genes, list):
        raise ValueError(f"ç°‡ '{cluster_key}' çš„æ•°æ®æ ¼å¼æ— æ•ˆï¼Œåº”ä¸ºåŸºå› åˆ—è¡¨")

    # æå–æŒ‡å®šæ•°é‡çš„åŸºå› 
    if gene_count >= len(genes):
        return genes.copy()
    else:
        return genes[:gene_count]


def get_all_cluster_ids(marker_genes_json_path: Optional[str] = None) -> List[str]:
    """è·å– JSON æ–‡ä»¶ä¸­æ‰€æœ‰ç°‡çš„ç¼–å·ã€‚

    Args:
        marker_genes_json_path: JSON æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        æ‰€æœ‰ç°‡ç¼–å·çš„åˆ—è¡¨

    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        Exception: JSON è§£æé”™è¯¯
    """
    # ğŸŒŸ è‡ªåŠ¨åŠ è½½å½“å‰ session çš„ marker_genes_json è·¯å¾„
    if marker_genes_json_path is None:
        marker_genes_json_path = _auto_load_file_path("marker_genes_json")
        if marker_genes_json_path is None:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ°å½“å‰ session çš„ marker genes æ–‡ä»¶ã€‚"
                "è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆ marker genesï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š marker_genes_json_path å‚æ•°ã€‚"
            )

    data = _load_json(marker_genes_json_path)
    if data is None:
        if not Path(marker_genes_json_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {marker_genes_json_path}")
        else:
            raise Exception(f"æ— æ³•è§£æ JSON æ–‡ä»¶: {marker_genes_json_path}")

    return list(data.keys())


def get_cluster_info(marker_genes_json_path: Optional[str] = None) -> Dict[str, int]:
    """è·å– JSON æ–‡ä»¶ä¸­æ‰€æœ‰ç°‡çš„åŸºå› æ•°é‡ä¿¡æ¯ã€‚

    Args:
        marker_genes_json_path: JSON æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        ç°‡åç§°åˆ°åŸºå› æ•°é‡çš„æ˜ å°„

    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        Exception: JSON è§£æé”™è¯¯
    """
    # ğŸŒŸ è‡ªåŠ¨åŠ è½½å½“å‰ session çš„ marker_genes_json è·¯å¾„
    if marker_genes_json_path is None:
        marker_genes_json_path = _auto_load_file_path("marker_genes_json")
        if marker_genes_json_path is None:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ°å½“å‰ session çš„ marker genes æ–‡ä»¶ã€‚"
                "è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆ marker genesï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š marker_genes_json_path å‚æ•°ã€‚"
            )

    data = _load_json(marker_genes_json_path)
    if data is None:
        if not Path(marker_genes_json_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {marker_genes_json_path}")
        else:
            raise Exception(f"æ— æ³•è§£æ JSON æ–‡ä»¶: {marker_genes_json_path}")

    info = {}
    for cluster_name, genes in data.items():
        if isinstance(genes, list):
            info[cluster_name] = len(genes)
        else:
            info[cluster_name] = 0

    return info


# ========== ç°‡å®Œæˆåº¦æ£€æŸ¥åŠŸèƒ½ ==========

def check_cluster_completion(
    marker_genes_path: Optional[str] = None
) -> Dict[str, Any]:
    """æ£€æŸ¥æ‰€æœ‰ç°‡æ˜¯å¦å·²å®Œæˆæ³¨é‡Šã€‚

    è‡ªåŠ¨ä½¿ç”¨å½“å‰ä¼šè¯IDæ£€æŸ¥å¯¹åº”ä¼šè¯çš„å®ŒæˆçŠ¶æ€ã€‚

    Args:
        marker_genes_path: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        åŒ…å«å®ŒæˆçŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
    try:
        # ğŸŒŸ è‡ªåŠ¨åŠ è½½å½“å‰ session çš„ marker_genes_path
        if marker_genes_path is None:
            marker_genes_path = _auto_load_file_path("marker_genes_json")
            if marker_genes_path is None:
                return {
                    "success": False,
                    "error": "æœªæ‰¾åˆ°å½“å‰ session çš„ marker genes æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç”Ÿæˆ marker genesï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š marker_genes_path å‚æ•°ã€‚",
                    "all_completed": False,
                    "total_clusters": 0,
                    "completed_clusters": 0,
                    "completion_rate": 0.0,
                    "incomplete_clusters": []
                }

        # åŠ è½½markeråŸºå› æ•°æ®è·å–æ‰€æœ‰ç°‡
        marker_data = _load_json(marker_genes_path)
        if marker_data is None:
            return {
                "success": False,
                "error": f"æ— æ³•åŠ è½½markeråŸºå› æ–‡ä»¶: {marker_genes_path}",
                "all_completed": False,
                "total_clusters": 0,
                "completed_clusters": 0,
                "completion_rate": 0.0,
                "incomplete_clusters": []
            }

        # è·å–æ‰€æœ‰ç°‡åç§°
        all_clusters = set(marker_data.keys())
        total_count = len(all_clusters)

        # åŠ è½½å½“å‰ä¼šè¯å·²æ³¨é‡Šçš„ç°‡
        annotated_clusters = load_cluster_types()

        # æ‰¾å‡ºå·²å®Œæˆæ³¨é‡Šçš„ç°‡ï¼ˆæ ‡å‡†åŒ–é”®åè¿›è¡ŒåŒ¹é…ï¼‰
        completed_clusters = set()
        for cluster in all_clusters:
            # å°è¯•å¤šç§é”®ååŒ¹é…
            cluster_variations = [
                cluster,  # åŸå§‹åç§°å¦‚"cluster0"
                cluster.replace("cluster", ""),  # æ•°å­—éƒ¨åˆ†å¦‚"0"
                f"cluster{cluster}" if not cluster.startswith("cluster") else cluster
            ]

            for variation in cluster_variations:
                if variation in annotated_clusters and annotated_clusters[variation].strip():
                    completed_clusters.add(cluster)
                    break

        # è®¡ç®—æœªå®Œæˆçš„ç°‡
        incomplete_clusters = list(all_clusters - completed_clusters)
        completed_count = len(completed_clusters)
        completion_rate = completed_count / total_count if total_count > 0 else 0.0

        return {
            "success": True,
            "all_completed": len(incomplete_clusters) == 0,
            "total_clusters": total_count,
            "completed_clusters": completed_count,
            "completion_rate": completion_rate,
            "incomplete_clusters": sorted(incomplete_clusters),
            "completed_cluster_list": sorted(list(completed_clusters))
        }

    except Exception as e:
        return {
            "success": False,
            "error": f"æ£€æŸ¥ç°‡å®Œæˆåº¦æ—¶å‡ºé”™: {e}",
            "all_completed": False,
            "total_clusters": 0,
            "completed_clusters": 0,
            "completion_rate": 0.0,
            "incomplete_clusters": []
        }


def get_incomplete_clusters(
    marker_genes_path: Optional[str] = None
) -> List[str]:
    """è·å–æœªå®Œæˆæ³¨é‡Šçš„ç°‡åˆ—è¡¨ã€‚

    Args:
        marker_genes_path: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        æœªå®Œæˆæ³¨é‡Šçš„ç°‡åç§°åˆ—è¡¨
    """
    result = check_cluster_completion(marker_genes_path)
    return result.get("incomplete_clusters", [])


def calculate_completion_rate(
    marker_genes_path: Optional[str] = None
) -> float:
    """è®¡ç®—ç°‡æ³¨é‡Šå®Œæˆç‡ã€‚

    Args:
        marker_genes_path: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        å®Œæˆç‡ï¼ˆ0.0-1.0ï¼‰
    """
    result = check_cluster_completion(marker_genes_path)
    return result.get("completion_rate", 0.0)


def format_completion_summary(
    marker_genes_path: Optional[str] = None
) -> str:
    """æ ¼å¼åŒ–ç°‡å®Œæˆåº¦æ‘˜è¦ä¿¡æ¯ã€‚

    Args:
        marker_genes_path: markeråŸºå› JSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨è¯»å–å½“å‰ session çš„ marker genes æ–‡ä»¶

    Returns:
        æ ¼å¼åŒ–çš„å®Œæˆåº¦æ‘˜è¦å­—ç¬¦ä¸²
    """
    result = check_cluster_completion(marker_genes_path)

    if not result["success"]:
        return f"âŒ æ£€æŸ¥å¤±è´¥: {result['error']}"

    manager = get_prompt_manager()
    summary_template = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_COMPLETION_SUMMARY_TEMPLATE')
    summary = summary_template.format(
        completed=result['completed_clusters'],
        total=result['total_clusters'],
        completion_rate=result['completion_rate']
    )

    if result["all_completed"]:
        suffix = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_COMPLETION_SUMMARY_ALL_DONE')
        summary += f"\n{suffix}"
    else:
        incomplete_clusters = result["incomplete_clusters"]
        incomplete_count = len(incomplete_clusters)
        incomplete_preview = ", ".join(incomplete_clusters[:5])
        if incomplete_count > 5:
            preview_suffix = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_COMPLETION_INCOMPLETE_PREVIEW_SUFFIX')
            incomplete_preview += preview_suffix.format(count=incomplete_count)

        suffix_template = manager.get_agent_specific_prompt('mainagent', 'CLUSTER_COMPLETION_SUMMARY_INCOMPLETE')
        summary += "\n" + suffix_template.format(
            incomplete_count=incomplete_count,
            incomplete_preview=incomplete_preview
        )

    return summary


# ========== ç»†èƒç±»å‹åç§°ç»Ÿä¸€åŒ–åŠŸèƒ½ ==========

def unify_cell_type_names(
    cluster_mapping_data: str,
    output_json_path: str
) -> Dict[str, Any]:
    """å°†ç»†èƒç±»å‹æ˜ å°„ä¿å­˜ä¸ºJSONæ–‡ä»¶ã€‚

    Args:
        cluster_mapping_data: æ˜ å°„æ•°æ®çš„JSONå­—ç¬¦ä¸²
        output_json_path: è¾“å‡ºjsonæ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«æˆåŠŸçŠ¶æ€çš„å­—å…¸ï¼Œå¤±è´¥æ—¶åŒ…å«é”™è¯¯ä¿¡æ¯
    """
    try:
        # è§£æJSONå­—ç¬¦ä¸²
        mapping_data = json.loads(cluster_mapping_data)

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = Path(output_json_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with output_path.open("w", encoding="utf-8") as f:
            json.dump(mapping_data, f, ensure_ascii=False, indent=2)

        return {"success": True}

    except json.JSONDecodeError as e:
        return {"success": False, "error": f"JSONè§£æå¤±è´¥: {e}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ========== ä¼šè¯ç®¡ç†åŠŸèƒ½ ==========

def list_all_sessions() -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰å†å²ä¼šè¯ã€‚

    ä»æ‰å¹³åŒ–çš„æ–‡ä»¶åä¸­æå–session_idã€‚

    Returns:
        ä¼šè¯IDåˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    """
    save_dir = DEFAULT_DIR if DEFAULT_DIR else _get_default_dir()
    d = Path(save_dir)
    if not d.exists():
        return []

    # ä»æ–‡ä»¶åä¸­æå–session_idï¼ˆæ ¼å¼ï¼šcluster_mapping_X_session_YYYYMMDD_HHMMSS_xxx.jsonï¼‰
    sessions = set()
    for p in d.glob("cluster_mapping_*_session_*.json"):
        # æå–æ–‡ä»¶åä¸­çš„session_idéƒ¨åˆ†
        parts = p.stem.split('_')
        # æ‰¾åˆ° 'session' å…³é”®è¯çš„ä½ç½®
        try:
            session_idx = parts.index('session')
            # session_id æ˜¯ä» 'session' å¼€å§‹åˆ°ç»“å°¾çš„æ‰€æœ‰éƒ¨åˆ†
            session_id = '_'.join(parts[session_idx:])
            sessions.add(session_id)
        except (ValueError, IndexError):
            continue

    # æŒ‰æ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    return sorted(list(sessions), reverse=True)


def load_cluster_types_by_session(
    session_id: str
) -> Dict[str, str]:
    """è¯»å–æŒ‡å®šä¼šè¯çš„æ‰€æœ‰ç°‡æ³¨é‡Šã€‚

    ç”¨äºæŸ¥çœ‹å†å²ä¼šè¯çš„æ³¨é‡Šç»“æœã€‚ä½¿ç”¨æ‰å¹³åŒ–æ–‡ä»¶å‘½åã€‚

    Args:
        session_id: ä¼šè¯ID

    Returns:
        ç°‡IDåˆ°ç»†èƒç±»å‹çš„æ˜ å°„
    """
    save_dir = DEFAULT_DIR if DEFAULT_DIR else _get_default_dir()
    base_dir = Path(save_dir)

    if not base_dir.exists():
        return {}

    # ä½¿ç”¨æ‰å¹³åŒ–æ–‡ä»¶åæ¨¡å¼ï¼šcluster_mapping_*_{session_id}.json
    result: Dict[str, str] = {}
    pattern = f"cluster_mapping_*_{session_id}.json"
    for p in sorted(base_dir.glob(pattern)):
        try:
            with p.open("r", encoding="utf-8") as f:
                item = json.load(f)
            c = str(item.get("cluster", "")).strip()
            t = str(item.get("type", "")).strip()
            if c:
                result[c] = t
        except Exception:
            continue
    return result


def get_session_summary() -> Dict[str, Any]:
    """è·å–æ‰€æœ‰ä¼šè¯çš„æ‘˜è¦ä¿¡æ¯ã€‚

    Returns:
        åŒ…å«æ‰€æœ‰ä¼šè¯æ‘˜è¦çš„å­—å…¸
    """
    sessions = list_all_sessions()
    current_session = get_session_id() if USE_SESSION_ISOLATION else "default"

    summary = {
        "current_session": current_session,
        "total_sessions": len(sessions),
        "sessions": []
    }

    for session_id in sessions:
        save_dir = DEFAULT_DIR if DEFAULT_DIR else _get_default_dir()
        base_dir = Path(save_dir)
        # ä½¿ç”¨æ‰å¹³åŒ–æ–‡ä»¶åæ¨¡å¼ç»Ÿè®¡clusteræ•°é‡
        pattern = f"cluster_mapping_*_{session_id}.json"
        cluster_count = len(list(base_dir.glob(pattern)))

        # å°è¯•ä»ä¼šè¯IDè§£ææ—¶é—´
        created_at = "Unknown"
        if session_id.startswith("session_"):
            try:
                from datetime import datetime
                timestamp_part = session_id.replace("session_", "")
                dt = datetime.strptime(timestamp_part, "%Y%m%d_%H%M%S")
                created_at = dt.strftime("%Y-%m-%d %H:%M:%S")
            except ValueError:
                pass

        summary["sessions"].append({
            "session_id": session_id,
            "created_at": created_at,
            "cluster_count": cluster_count,
            "is_current": session_id == current_session
        })

    return summary
