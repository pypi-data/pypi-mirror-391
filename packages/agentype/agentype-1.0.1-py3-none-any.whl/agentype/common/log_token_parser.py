#!/usr/bin/env python3
"""
agentype - LLM æ—¥å¿— Token ç»Ÿè®¡è§£æå™¨
Author: cuilei
Version: 1.0

ä» JSONL æ ¼å¼çš„ LLM æ—¥å¿—æ–‡ä»¶ä¸­æå–å’Œæ±‡æ€» token ä½¿ç”¨ç»Ÿè®¡ã€‚
"""

import json
from pathlib import Path
from typing import Dict, Optional, List
from datetime import datetime
import sys

from agentype.common.token_statistics import TokenStatistics


class LogTokenParser:
    """LLM æ—¥å¿— Token ç»Ÿè®¡è§£æå™¨

    ä»ä¿å­˜åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­çš„ JSONL æ ¼å¼æ—¥å¿—æ–‡ä»¶ä¸­è§£æ token ä½¿ç”¨ç»Ÿè®¡ã€‚
    æ”¯æŒè·¨è¿›ç¨‹çš„ token ç»Ÿè®¡æ”¶é›†ï¼Œè§£å†³ MCP æ¶æ„ä¸‹çš„ç»Ÿè®¡ä¸¢å¤±é—®é¢˜ã€‚
    """

    # Agent åç§°åˆ°æ—¥å¿—ç›®å½•çš„æ˜ å°„
    AGENT_LOG_DIRS = {
        "MainAgent": "main_agent",
        "SubAgent": "sub_agent",
        "DataAgent": "data_agent",
        "AppAgent": "app_agent"
    }

    def __init__(self, log_base_dir: str):
        """åˆå§‹åŒ–æ—¥å¿—è§£æå™¨

        Args:
            log_base_dir: æ—¥å¿—æ–‡ä»¶åŸºç¡€ç›®å½•è·¯å¾„
        """
        self.log_base_dir = Path(log_base_dir)
        if not self.log_base_dir.exists():
            print(f"âš ï¸  æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.log_base_dir}", file=sys.stderr)

    @staticmethod
    def _extract_api_base(url: str) -> str:
        """ä»å®Œæ•´ URL æå– API base URL

        Args:
            url: å®Œæ•´çš„ API URLï¼Œå¦‚ "https://api.deepseek.com/v1/chat/completions"

        Returns:
            API base URLï¼Œå¦‚ "https://api.deepseek.com/v1"
        """
        # ç§»é™¤å¸¸è§çš„ API endpoint è·¯å¾„
        endpoints = ['/chat/completions', '/completions', '/embeddings']
        for endpoint in endpoints:
            if url.endswith(endpoint):
                return url[:-len(endpoint)]
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›åŸURL
        return url

    def _find_log_file(self, agent_dir: str, session_id: str) -> Optional[Path]:
        """æŸ¥æ‰¾æŒ‡å®š Agent å’Œ session_id çš„æ—¥å¿—æ–‡ä»¶

        Args:
            agent_dir: Agent ç›®å½•å (å¦‚ "sub_agent")
            session_id: ä¼šè¯ ID

        Returns:
            æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        log_dir = self.log_base_dir / agent_dir
        if not log_dir.exists():
            return None

        # æ—¥å¿—æ–‡ä»¶å‘½åæ ¼å¼: llm_requests_{session_id}.jsonl
        # æ³¨æ„: session_id å·²åŒ…å« "session_" å‰ç¼€
        log_file = log_dir / f"llm_requests_{session_id}.jsonl"

        if log_file.exists():
            return log_file

        return None

    def _parse_log_file(self, log_file: Path, agent_name: str) -> TokenStatistics:
        """è§£æå•ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œæå– token ç»Ÿè®¡

        Args:
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            agent_name: Agent åç§° (ç”¨äºç»Ÿè®¡å¯¹è±¡)

        Returns:
            TokenStatistics å¯¹è±¡ï¼ŒåŒ…å«è¯¥æ—¥å¿—æ–‡ä»¶çš„æ‰€æœ‰ token ç»Ÿè®¡
        """
        stats = TokenStatistics(agent_name=agent_name)

        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue

                    try:
                        # è§£æ JSON è¡Œ
                        log_entry = json.loads(line)

                        # æå– usage æ•°æ®
                        extra_info = log_entry.get('extra_info', {})
                        usage_data = extra_info.get('usage', {})

                        if not usage_data:
                            # æ²¡æœ‰ usage æ•°æ®ï¼Œè·³è¿‡è¿™æ¡è®°å½•
                            continue

                        # æ·»åŠ åˆ°ç»Ÿè®¡
                        stats.add_usage(usage_data)

                        # æ›´æ–°æ¨¡å‹åç§°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è®¾ç½®ï¼‰
                        if not stats.model_name and 'model_used' in extra_info:
                            stats.model_name = extra_info['model_used']

                        # æå– API base URLï¼ˆå¦‚æœè¿˜æ²¡æœ‰è®¾ç½®ï¼‰
                        if not stats.api_base:
                            request_data = log_entry.get('request', {})
                            url = request_data.get('url', '')
                            if url:
                                # ä»å®Œæ•´ URL æå– base URL
                                # ä¾‹å¦‚: https://api.deepseek.com/v1/chat/completions -> https://api.deepseek.com/v1
                                stats.api_base = self._extract_api_base(url)

                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  è§£ææ—¥å¿—è¡Œå¤±è´¥ [{log_file.name}:{line_num}]: {e}", file=sys.stderr)
                        continue
                    except Exception as e:
                        print(f"âš ï¸  å¤„ç†æ—¥å¿—è¡Œæ—¶å‡ºé”™ [{log_file.name}:{line_num}]: {e}", file=sys.stderr)
                        continue

            return stats

        except FileNotFoundError:
            print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}", file=sys.stderr)
            return stats
        except Exception as e:
            print(f"âŒ è§£ææ—¥å¿—æ–‡ä»¶å¤±è´¥ [{log_file}]: {e}", file=sys.stderr)
            return stats

    def parse_agent_logs(self, agent_name: str, session_id: str) -> TokenStatistics:
        """è§£ææŒ‡å®š Agent çš„æ—¥å¿—æ–‡ä»¶

        Args:
            agent_name: Agent åç§° ("MainAgent", "SubAgent", "DataAgent", "AppAgent")
            session_id: ä¼šè¯ ID

        Returns:
            TokenStatistics å¯¹è±¡ï¼Œå¦‚æœæ—¥å¿—ä¸å­˜åœ¨åˆ™è¿”å›ç©ºç»Ÿè®¡
        """
        agent_dir = self.AGENT_LOG_DIRS.get(agent_name)
        if not agent_dir:
            print(f"âš ï¸  æœªçŸ¥çš„ Agent åç§°: {agent_name}", file=sys.stderr)
            return TokenStatistics(agent_name=agent_name)

        log_file = self._find_log_file(agent_dir, session_id)
        if not log_file:
            # æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œè¿”å›ç©ºç»Ÿè®¡
            return TokenStatistics(agent_name=agent_name)

        print(f"ğŸ“Š è§£æ {agent_name} æ—¥å¿—: {log_file}", file=sys.stderr)
        stats = self._parse_log_file(log_file, agent_name)

        if stats.total_tokens > 0:
            print(f"âœ… {agent_name} token ç»Ÿè®¡: {stats.total_tokens:,} tokens "
                  f"({stats.request_count} æ¬¡è¯·æ±‚)", file=sys.stderr)
        else:
            print(f"ğŸ“­ {agent_name} æš‚æ—  token æ¶ˆè€—", file=sys.stderr)

        return stats

    def parse_all_agents(self, session_id: str,
                        include_agents: Optional[List[str]] = None) -> Dict[str, TokenStatistics]:
        """è§£ææ‰€æœ‰ Agent çš„æ—¥å¿—æ–‡ä»¶

        Args:
            session_id: ä¼šè¯ ID
            include_agents: è¦åŒ…å«çš„ Agent åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰ Agent

        Returns:
            å­—å…¸ï¼Œé”®ä¸º Agent åç§°ï¼Œå€¼ä¸º TokenStatistics å¯¹è±¡
        """
        if include_agents is None:
            include_agents = list(self.AGENT_LOG_DIRS.keys())

        result = {}

        for agent_name in include_agents:
            stats = self.parse_agent_logs(agent_name, session_id)
            result[agent_name] = stats

        return result

    def get_log_file_info(self, session_id: str) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰ Agent çš„æ—¥å¿—æ–‡ä»¶ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            å­—å…¸ï¼ŒåŒ…å«æ¯ä¸ª Agent çš„æ—¥å¿—æ–‡ä»¶ä¿¡æ¯
        """
        info = {}

        for agent_name, agent_dir in self.AGENT_LOG_DIRS.items():
            log_file = self._find_log_file(agent_dir, session_id)

            if log_file and log_file.exists():
                stat = log_file.stat()
                info[agent_name] = {
                    "exists": True,
                    "path": str(log_file),
                    "size_bytes": stat.st_size,
                    "size_kb": round(stat.st_size / 1024, 2),
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat()
                }
            else:
                info[agent_name] = {
                    "exists": False,
                    "path": str(self.log_base_dir / agent_dir / f"llm_requests_session_{session_id}.jsonl")
                }

        return info


# ä¾¿æ·å‡½æ•°
def parse_logs_for_session(session_id: str,
                          log_base_dir: str = "/app/data/å…¬å…±æ•°æ®åº“/æ³¨é‡Š/outputs2/logs/llm",
                          include_agents: Optional[List[str]] = None) -> Dict[str, TokenStatistics]:
    """ä¾¿æ·å‡½æ•°ï¼šè§£ææŒ‡å®šä¼šè¯çš„æ‰€æœ‰ Agent æ—¥å¿—

    Args:
        session_id: ä¼šè¯ ID
        log_base_dir: æ—¥å¿—åŸºç¡€ç›®å½•
        include_agents: è¦åŒ…å«çš„ Agent åˆ—è¡¨

    Returns:
        Agent åç§°åˆ° TokenStatistics çš„å­—å…¸
    """
    parser = LogTokenParser(log_base_dir)
    return parser.parse_all_agents(session_id, include_agents)


def get_total_tokens_from_logs(session_id: str,
                               log_base_dir: str = "/app/data/å…¬å…±æ•°æ®åº“/æ³¨é‡Š/outputs2/logs/llm") -> int:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–æ‰€æœ‰ Agent çš„æ€» token æ•°

    Args:
        session_id: ä¼šè¯ ID
        log_base_dir: æ—¥å¿—åŸºç¡€ç›®å½•

    Returns:
        æ€» token æ•°
    """
    stats_dict = parse_logs_for_session(session_id, log_base_dir)
    total = sum(stats.total_tokens for stats in stats_dict.values())
    return total
