# AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
# This file is automatically generated from stream-event.json
# To regenerate, run: bash scripts/generate-python.sh


# generated by datamodel-codegen:
#   filename:  stream-event.json

from __future__ import annotations

from collections.abc import Mapping, Sequence
from enum import Enum
from typing import Annotated, Any, Literal

from pydantic import BaseModel, Field, RootModel, ConfigDict


class Messagechunk(BaseModel):
    """
    Text message chunk from the agent.
    """
    model_config = ConfigDict(populate_by_name=True)


    type: Annotated[Literal['message'], Field(title='Type')] = 'message'
    content: Annotated[str, Field(title='Content')]
    """
    Message content chunk
    """
    sequence: Annotated[int, Field(title='Sequence')]
    """
    Sequence number for ordering chunks
    """
    is_complete: Annotated[bool | None, Field(title='Is Complete')] = False
    """
    Whether this is the final chunk
    """
    message_id: Annotated[str, Field(title='Message Id')]
    """
    Unique identifier for this message
    """


class Thinkingchunk(BaseModel):
    """
    Agent thinking/reasoning step.
    """
    model_config = ConfigDict(populate_by_name=True)


    type: Annotated[Literal['thinking'], Field(title='Type')] = 'thinking'
    thought: Annotated[str, Field(title='Thought')]
    """
    The agent's current thought or reasoning
    """
    step: Annotated[int, Field(title='Step')]
    """
    Step number in the thinking process
    """
    total_steps: Annotated[int | None, Field(title='Total Steps')] = None
    """
    Total number of steps (if known)
    """


class Status(Enum):
    """
    Tool call status
    """

    started = 'started'
    completed = 'completed'
    error = 'error'


class Toolcallchunk(BaseModel):
    """
    Tool execution event.
    """
    model_config = ConfigDict(populate_by_name=True)


    type: Annotated[Literal['tool_call'], Field(title='Type')] = 'tool_call'
    tool_name: Annotated[str, Field(title='Tool Name')]
    """
    Name of the tool being called
    """
    tool_input: Annotated[Mapping[str, Any], Field(title='Tool Input')]
    """
    Input parameters for the tool
    """
    tool_output: Annotated[Mapping[str, Any] | None, Field(title='Tool Output')] = None
    """
    Output from the tool (if completed)
    """
    status: Annotated[Status, Field(title='Status')]
    """
    Tool call status
    """
    tool_call_id: Annotated[str, Field(title='Tool Call Id')]
    """
    Unique identifier for this tool call
    """


class Errorchunk(BaseModel):
    """
    Error event.
    """
    model_config = ConfigDict(populate_by_name=True)


    type: Annotated[Literal['error'], Field(title='Type')] = 'error'
    message: Annotated[str, Field(title='Message')]
    """
    Error message
    """
    code: Annotated[str | None, Field(title='Code')] = None
    """
    Error code
    """
    details: Annotated[Mapping[str, Any] | None, Field(title='Details')] = None
    """
    Additional error details
    """


class Suggestionchunk(BaseModel):
    """
    Suggestion or recommendation event.
    """
    model_config = ConfigDict(populate_by_name=True)


    type: Annotated[Literal['suggestion'], Field(title='Type')] = 'suggestion'
    suggestions: Annotated[Sequence[str], Field(title='Suggestions')]
    """
    List of suggestions
    """
    context: Annotated[str | None, Field(title='Context')] = None
    """
    Context for the suggestions
    """


class StreamEvent(
    RootModel[
        Messagechunk | Thinkingchunk | Toolcallchunk | Errorchunk | Suggestionchunk
    ]
):
    root: Annotated[
        Messagechunk | Thinkingchunk | Toolcallchunk | Errorchunk | Suggestionchunk,
        Field(discriminator='type', title='StreamEvent'),
    ]
    """
    Union type for all stream event chunks
    """
