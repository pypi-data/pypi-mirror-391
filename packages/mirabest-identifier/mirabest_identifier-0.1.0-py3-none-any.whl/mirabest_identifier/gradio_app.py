"""Gradio user interface for the MiraBest identifier tutorial.

This module keeps the GUI assembly separate from the Typer commands so the CLI
can stay short and focused.  The functions are heavily annotated so the
rendered documentation highlights input and output types.
"""

from __future__ import annotations

from pathlib import Path

import gradio as gr
from PIL import Image

from .inference import (
    CLASSES,
    ModelPrediction,
    predict_with_weights,
    resolve_device,
    resolve_weight_paths,
)


def _format_rows(prediction: ModelPrediction) -> list[list[float | str]]:
    """Convert a prediction into rows ready for display.

    Args:
        prediction: Prediction generated by predict_with_weights.

    Returns:
        list[list[float | str]]: Rows containing class labels and probabilities.
    """

    return [[label, round(score, 3)] for label, score in prediction.top_classes]


def build_interface(
    weight_paths: list[Path] | None,
    device_option: str,
    default_top_k: int,
) -> gr.Interface:
    """Create the Gradio interface used by the CLI command.

    Args:
        weight_paths: Optional explicit list of weight files to expose.
        device_option: Device specifier forwarded to torch.device.
        default_top_k: Default number of classes to display.

    Returns:
        gr.Interface: Configured interface ready to launch.

    Raises:
        InferenceError: If weight resolution or device configuration fails.
    """

    resolved_weights = resolve_weight_paths(weight_paths)
    device = resolve_device(device_option)
    choice_map = {path.name: path for path in resolved_weights}
    default_choice = next(iter(choice_map.keys()))
    slider_max = max(1, len(CLASSES))
    slider_default = max(1, min(default_top_k, slider_max))

    def _predict(
        image: Image.Image | None,
        weight_name: str,
        requested_top_k: float,
    ) -> list[list[float | str]]:
        """Run inference for the uploaded image and return table rows."""

        if image is None:
            return []
        selected = choice_map.get(weight_name) or choice_map[default_choice]
        adjusted_top_k = int(max(1, min(requested_top_k, slider_max)))
        grayscale = image.convert("L")
        prediction = predict_with_weights(grayscale, selected, device, adjusted_top_k)
        return _format_rows(prediction)

    description = "Upload a radio galaxy image to classify it as FRI or FRII."

    dropdown = gr.Dropdown(
        choices=list(choice_map.keys()),
        value=default_choice,
        label="Weight file",
    )
    slider = gr.Slider(
        minimum=1,
        maximum=slider_max,
        value=slider_default,
        step=1,
        label="Top-k predictions",
    )
    dataframe = gr.Dataframe(
        headers=["Class", "Probability"],
        datatype=["str", "number"],
        label="Predictions",
        interactive=False,
    )

    return gr.Interface(
        fn=_predict,
        inputs=[gr.Image(type="pil", label="Radio galaxy image"), dropdown, slider],
        outputs=dataframe,
        title="MiraBest Identifier",
        description=description,
        allow_flagging="never",
    )


def launch_gradio(
    weight_paths: list[Path] | None = None,
    device_option: str = "auto",
    default_top_k: int = 2,
    share: bool = False,
    server_name: str | None = None,
    server_port: int | None = None,
) -> None:
    """Launch the Gradio interface.

    Args:
        weight_paths: Optional explicit list of weight files to expose.
        device_option: Device specifier forwarded to torch.device.
        default_top_k: Default number of classes to display.
        share: Whether to create a public Gradio share link.
        server_name: Optional hostname for the Gradio server.
        server_port: Optional port for the Gradio server.

    Raises:
        InferenceError: If the interface cannot be constructed.
    """

    interface = build_interface(weight_paths, device_option, default_top_k)
    interface.launch(
        share=share,
        server_name=server_name,
        server_port=server_port,
        inline=False,
        inbrowser=True,
    )
