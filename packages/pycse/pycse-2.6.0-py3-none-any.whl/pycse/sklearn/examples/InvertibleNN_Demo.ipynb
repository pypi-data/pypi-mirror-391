{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invertible Neural Networks (Normalizing Flows)\n",
    "\n",
    "This notebook demonstrates two complementary uses of invertible neural networks:\n",
    "\n",
    "1. **Part 1: Regression with Uncertainty** (ConditionalInvertibleNN)\n",
    "   - **Problem**: Predict outputs Y from inputs X with uncertainty estimates\n",
    "   - **Solution**: Learn p(Y|X) - the conditional distribution of outputs given inputs\n",
    "   - **Use cases**: Predictions with confidence intervals, heteroscedastic uncertainty\n",
    "\n",
    "2. **Part 2: Density Estimation & Generative Modeling** (InvertibleNN)\n",
    "   - **Problem**: Learn the probability distribution of data X\n",
    "   - **Solution**: Learn p(X) - transform data to/from a simple Gaussian distribution\n",
    "   - **Use cases**: Anomaly detection, synthetic data generation, likelihood computation\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "Both models use **normalizing flows** - invertible transformations with tractable Jacobians:\n",
    "\n",
    "$$\\log p(x) = \\log p(z) + \\log \\left|\\det \\frac{\\partial f}{\\partial x}\\right|$$\n",
    "\n",
    "where $z = f(x)$ and $p(z)$ is a simple base distribution (Gaussian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ConditionalInvertibleNN (Regression) imported!\n",
      "✓ InvertibleNN (Density Estimation) imported!\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from pycse.sklearn.cinn import ConditionalInvertibleNN\n",
    "from pycse.sklearn.inn import InvertibleNN\n",
    "\n",
    "# Enable 64-bit precision\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "print(\"✓ ConditionalInvertibleNN (Regression) imported!\")\n",
    "print(\"✓ InvertibleNN (Density Estimation) imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Regression with Uncertainty (ConditionalInvertibleNN)\n",
    "\n",
    "## Problem: Predicting Outputs with Uncertainty\n",
    "\n",
    "**Traditional regression** (linear regression, neural networks) gives point predictions:\n",
    "- Input X → Output Y\n",
    "- No uncertainty estimates\n",
    "- Assumes constant noise\n",
    "\n",
    "**ConditionalInvertibleNN** learns the full conditional distribution p(Y|X):\n",
    "- Input X → Distribution over Y\n",
    "- Provides mean predictions AND uncertainty\n",
    "- Handles heteroscedastic noise (input-dependent uncertainty)\n",
    "- Can sample multiple plausible predictions\n",
    "\n",
    "**When to use this:**\n",
    "- Need confidence intervals on predictions\n",
    "- Uncertainty varies across input space (heteroscedastic)\n",
    "- Want to quantify prediction reliability\n",
    "- Need full predictive distribution, not just point estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Regression with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: X=(200, 1), y=(200, 1)\n",
      "Task: Learn Y = f(X) with uncertainty\n"
     ]
    }
   ],
   "source": [
    "# Generate simple regression data\n",
    "key = jax.random.PRNGKey(42)\n",
    "X = np.linspace(-3, 3, 200)[:, None]\n",
    "y_true = 2 * X + 1\n",
    "y = y_true + 0.3 * jax.random.normal(key, X.shape)\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Task: Learn Y = f(X) with uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>======================================================================\n",
       "Conditional Invertible NN [✗ not fitted]\n",
       "======================================================================\n",
       "\n",
       "Regression Model: X → Y with uncertainty\n",
       "\n",
       "Architecture:\n",
       "  Input (X)         : 1D\n",
       "  ↓\n",
       "  Conditional Flow  : 8 coupling layers\n",
       "                      Hidden: [128, 128]\n",
       "  ↓\n",
       "  Output (Y)        : 1D\n",
       "\n",
       "Capabilities:\n",
       "  • predict(X)              : Mean prediction\n",
       "  • predict(X, return_std)  : Mean + uncertainty\n",
       "  • sample(X, n_samples)    : Sample from p(Y|X)\n",
       "  • score(X, y)             : Log-likelihood\n",
       "======================================================================</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ConditionalInvertibleNN</div></div><div><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_features_in',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_features_in&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_features_out',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_features_out&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_layers',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_layers&nbsp;</td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('hidden_dims',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">hidden_dims&nbsp;</td>\n",
       "            <td class=\"value\">[128, 128]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('seed',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">seed&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "╔════════════════════════════════════════════════════════════════════╗\n",
       "║               Conditional InvertibleNN - Regression                ║\n",
       "╠════════════════════════════════════════════════════════════════════╣\n",
       "║ Architecture:                                                      ║\n",
       "║   Input (X):  1D                                                    ║\n",
       "║   │                                                                ║\n",
       "║   ├─[Conditional Layer  1] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  2] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  3] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  4] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  5] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  6] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  7] (hidden: [128, 128])                    ║\n",
       "║   │  ↓ (conditioned on X)                                          ║\n",
       "║   ├─[Conditional Layer  8] (hidden: [128, 128])                    ║\n",
       "║   │                                                                ║\n",
       "║   Output (Y): 1D                                                    ║\n",
       "╠════════════════════════════════════════════════════════════════════╣\n",
       "║ Status: ✗ not fitted                                               ║\n",
       "╚════════════════════════════════════════════════════════════════════╝"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create conditional flow for regression\n",
    "cinn = ConditionalInvertibleNN(\n",
    "    n_features_in=1,   # 1D input (X)\n",
    "    n_features_out=1,  # 1D output (Y)\n",
    "    n_layers=8,  # More layers for better modeling\n",
    "    hidden_dims=[128, 128],  # Larger network\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regression model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training regression model...\")\n",
    "cinn.fit(X, y, maxiter=2000)  # More training\n",
    "\n",
    "# Print report\n",
    "cinn.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with uncertainty - use many samples for smooth estimates\n",
    "y_pred, y_std = cinn.predict(X, return_std=True, n_samples=2000)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.3, s=10, label='Training data', c='gray')\n",
    "plt.plot(X, y_pred, 'r-', label='Mean prediction', linewidth=2)\n",
    "plt.fill_between(\n",
    "    X.ravel(),\n",
    "    (y_pred - 2*y_std).ravel(),\n",
    "    (y_pred + 2*y_std).ravel(),\n",
    "    alpha=0.3,\n",
    "    color='red',\n",
    "    label='95% confidence interval'\n",
    ")\n",
    "plt.plot(X, y_true, 'k--', label='True function', linewidth=1)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Regression with Uncertainty Quantification')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"✓ Model provides mean prediction AND uncertainty estimates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Heteroscedastic Regression (Varying Noise)\n",
    "\n",
    "**Real-world challenge**: Uncertainty often varies across the input space!\n",
    "\n",
    "- Near x=0: Low noise, high confidence\n",
    "- Far from x=0: High noise, low confidence\n",
    "\n",
    "ConditionalInvertibleNN **automatically learns** this input-dependent uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with varying noise levels\n",
    "key = jax.random.PRNGKey(99)\n",
    "X_het = np.linspace(-3, 3, 250)[:, None]\n",
    "y_true_het = X_het**2\n",
    "\n",
    "# Noise increases with |X|\n",
    "noise_std = 0.1 + 0.3 * np.abs(X_het)\n",
    "noise = noise_std * jax.random.normal(key, X_het.shape)\n",
    "y_het = y_true_het + noise\n",
    "\n",
    "print(\"Generated heteroscedastic data:\")\n",
    "print(f\"  Noise at X=0: ~{noise_std[len(X_het)//2, 0]:.2f}\")\n",
    "print(f\"  Noise at X=±3: ~{noise_std[-1, 0]:.2f}\")\n",
    "print(\"  → Noise level depends on X!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train conditional flow with better hyperparameters\n",
    "cinn_het = ConditionalInvertibleNN(\n",
    "    n_features_in=1,\n",
    "    n_features_out=1,\n",
    "    n_layers=10,  # More layers to capture input-dependent uncertainty\n",
    "    hidden_dims=[128, 128, 128],  # Deeper network\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Training on heteroscedastic data...\")\n",
    "cinn_het.fit(X_het, y_het, maxiter=2500)  # More iterations\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with learned uncertainty - use many samples for smooth estimate\n",
    "y_pred_het, y_std_het = cinn_het.predict(X_het, return_std=True, n_samples=5000)\n",
    "\n",
    "# Apply smoothing to uncertainty for cleaner visualization\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "y_std_het_smooth = gaussian_filter1d(y_std_het.ravel(), sigma=5)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left: Predictions with confidence bands\n",
    "ax = axes[0]\n",
    "ax.scatter(X_het, y_het, alpha=0.3, s=10, label='Training data', c='gray')\n",
    "ax.plot(X_het, y_pred_het, 'r-', label='Mean prediction', linewidth=2)\n",
    "ax.fill_between(\n",
    "    X_het.ravel(),\n",
    "    (y_pred_het.ravel() - 2*y_std_het_smooth),\n",
    "    (y_pred_het.ravel() + 2*y_std_het_smooth),\n",
    "    alpha=0.3,\n",
    "    color='red',\n",
    "    label='95% confidence'\n",
    ")\n",
    "ax.plot(X_het, y_true_het, 'k--', label='True function', linewidth=1)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Heteroscedastic Regression')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Learned vs True uncertainty\n",
    "ax = axes[1]\n",
    "ax.plot(X_het, noise_std * 2, 'k--', label='True noise (2σ)', linewidth=2)\n",
    "ax.plot(X_het, y_std_het_smooth * 2, 'r-', label='Learned uncertainty (2σ, smoothed)', linewidth=2, alpha=0.8)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Uncertainty (2σ)')\n",
    "ax.set_title('Model Learns Input-Dependent Uncertainty!')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\n✓ Uncertainty bands widen where data is noisier!\")\n",
    "print(\"✓ This is heteroscedastic uncertainty - traditional regression can't do this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Sampling from the Predictive Distribution\n",
    "\n",
    "Unlike traditional regression (single prediction), ConditionalInvertibleNN learns the **full distribution** p(Y|X).\n",
    "\n",
    "We can sample multiple plausible predictions for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nonlinear data\n",
    "key = jax.random.PRNGKey(123)\n",
    "X_nl = np.linspace(-2*np.pi, 2*np.pi, 300)[:, None]\n",
    "y_true_nl = np.sin(X_nl)\n",
    "y_nl = y_true_nl + 0.15 * jax.random.normal(key, X_nl.shape)\n",
    "\n",
    "# Train model with better hyperparameters\n",
    "cinn_nl = ConditionalInvertibleNN(\n",
    "    n_features_in=1,\n",
    "    n_features_out=1,\n",
    "    n_layers=10,  # More layers\n",
    "    hidden_dims=[128, 128],  # Larger network\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Training on sine wave...\")\n",
    "cinn_nl.fit(X_nl, y_nl, maxiter=2000)  # More training\n",
    "\n",
    "# Get predictions with samples\n",
    "y_pred_nl, y_samples = cinn_nl.predict(X_nl, return_samples=True, n_samples=500)\n",
    "\n",
    "print(f\"Generated {y_samples.shape[0]} plausible predictions for each input!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from predictive distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left: Mean and confidence\n",
    "ax = axes[0]\n",
    "y_std_nl = np.std(y_samples, axis=0)\n",
    "ax.scatter(X_nl, y_nl, alpha=0.3, s=10, label='Training data', c='gray')\n",
    "ax.plot(X_nl, y_pred_nl, 'r-', label='Mean prediction', linewidth=2)\n",
    "ax.fill_between(\n",
    "    X_nl.ravel(),\n",
    "    (y_pred_nl - 2*y_std_nl).ravel(),\n",
    "    (y_pred_nl + 2*y_std_nl).ravel(),\n",
    "    alpha=0.3,\n",
    "    color='red',\n",
    "    label='95% confidence'\n",
    ")\n",
    "ax.plot(X_nl, y_true_nl, 'k--', label='True function', linewidth=1)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Mean Prediction with Uncertainty')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Sampled predictions\n",
    "ax = axes[1]\n",
    "for i in range(min(20, y_samples.shape[0])):\n",
    "    ax.plot(X_nl, y_samples[i], 'r-', alpha=0.1, linewidth=0.5)\n",
    "ax.scatter(X_nl[::10], y_nl[::10], alpha=0.5, s=20, label='Training data', c='gray')\n",
    "ax.plot(X_nl, y_true_nl, 'k--', label='True function', linewidth=2)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('20 Samples from p(Y|X) for Each X')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\n✓ Each red line is a plausible prediction!\")\n",
    "print(\"✓ Sampling gives us the full distribution, not just a single answer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Multi-Output Regression\n",
    "\n",
    "ConditionalInvertibleNN handles **multi-dimensional outputs** with correlated uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D output from 1D input (parametric curve)\n",
    "key = jax.random.PRNGKey(77)\n",
    "t = np.linspace(0, 2*np.pi, 200)[:, None]\n",
    "\n",
    "# Lissajous curve\n",
    "x_true = np.sin(3*t)\n",
    "y_true = np.cos(2*t)\n",
    "\n",
    "x = x_true + 0.1 * jax.random.normal(key, x_true.shape)\n",
    "y = y_true + 0.1 * jax.random.normal(key, y_true.shape)\n",
    "\n",
    "Y_multi = np.concatenate([x, y], axis=1)  # Shape: (200, 2)\n",
    "\n",
    "print(f\"Multi-output regression:\")\n",
    "print(f\"  Input: t (time) - shape {t.shape}\")\n",
    "print(f\"  Output: (x, y) coordinates - shape {Y_multi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multi-output model with better hyperparameters\n",
    "cinn_multi = ConditionalInvertibleNN(\n",
    "    n_features_in=1,   # Input: t\n",
    "    n_features_out=2,  # Output: (x, y)\n",
    "    n_layers=10,  # More layers\n",
    "    hidden_dims=[128, 128],  # Larger network\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Training multi-output model...\")\n",
    "cinn_multi.fit(t, Y_multi, maxiter=2000)  # More training\n",
    "\n",
    "# Predict with more samples for smoother uncertainty\n",
    "Y_pred, Y_std = cinn_multi.predict(t, return_std=True, n_samples=500)\n",
    "\n",
    "print(\"Multi-output predictions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-output regression\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Left: X output\n",
    "ax = axes[0]\n",
    "ax.scatter(t, x, alpha=0.3, s=10, label='Training data (x)', c='gray')\n",
    "ax.plot(t, Y_pred[:, 0], 'r-', label='Prediction (x)', linewidth=2)\n",
    "ax.fill_between(\n",
    "    t.ravel(),\n",
    "    (Y_pred[:, 0] - 2*Y_std[:, 0]).ravel(),\n",
    "    (Y_pred[:, 0] + 2*Y_std[:, 0]).ravel(),\n",
    "    alpha=0.3,\n",
    "    color='red'\n",
    ")\n",
    "ax.plot(t, x_true, 'k--', label='True x', linewidth=1)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_title('X Component with Uncertainty')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Middle: Y output\n",
    "ax = axes[1]\n",
    "ax.scatter(t, y, alpha=0.3, s=10, label='Training data (y)', c='gray')\n",
    "ax.plot(t, Y_pred[:, 1], 'r-', label='Prediction (y)', linewidth=2)\n",
    "ax.fill_between(\n",
    "    t.ravel(),\n",
    "    (Y_pred[:, 1] - 2*Y_std[:, 1]).ravel(),\n",
    "    (Y_pred[:, 1] + 2*Y_std[:, 1]).ravel(),\n",
    "    alpha=0.3,\n",
    "    color='red'\n",
    ")\n",
    "ax.plot(t, y_true, 'k--', label='True y', linewidth=1)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Y Component with Uncertainty')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Parametric curve\n",
    "ax = axes[2]\n",
    "ax.scatter(x, y, alpha=0.3, s=10, label='Training data', c='gray')\n",
    "ax.plot(Y_pred[:, 0], Y_pred[:, 1], 'r-', label='Prediction', linewidth=2)\n",
    "ax.plot(x_true, y_true, 'k--', label='True curve', linewidth=1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Parametric Curve (x, y)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\n✓ Single model predicts both x AND y with their uncertainties!\")\n",
    "print(\"✓ Captures correlations between output dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: When to Use Conditional INN for Regression\n",
    "\n",
    "✅ **Use ConditionalInvertibleNN when you need:**\n",
    "- Predictions with confidence intervals\n",
    "- Heteroscedastic uncertainty (varies with input)\n",
    "- Full predictive distribution p(Y|X)\n",
    "- Multi-output regression with correlations\n",
    "- To quantify prediction reliability\n",
    "\n",
    "⚠️ **Not ideal for:**\n",
    "- Simple tasks where point estimates suffice\n",
    "- When uncertainty doesn't matter\n",
    "- Very small datasets (<100 samples)\n",
    "\n",
    "**Comparison to alternatives:**\n",
    "- vs **Standard NN**: CINN provides uncertainty, not just point predictions\n",
    "- vs **Bayesian NN**: CINN is faster, easier to train, exact likelihoods\n",
    "- vs **Gaussian Process**: CINN scales better to high dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Density Estimation & Generative Modeling (InvertibleNN)\n",
    "\n",
    "## Problem: Learning Data Distributions\n",
    "\n",
    "**Goal**: Learn the probability distribution p(X) of data X itself (not predicting Y from X).\n",
    "\n",
    "**Why this matters:**\n",
    "- **Anomaly Detection**: Assign low probability to outliers\n",
    "- **Generative Modeling**: Sample new, realistic data points\n",
    "- **Exact Likelihoods**: Know exactly how probable any point is\n",
    "- **Density Estimation**: Understand the shape of your data distribution\n",
    "\n",
    "**InvertibleNN approach:**\n",
    "- Learn transformation: Complex data X ↔ Simple Gaussian Z\n",
    "- Forward: Map data to Gaussian latent space\n",
    "- Inverse: Generate new data from Gaussian samples\n",
    "- Exact likelihood via change of variables formula\n",
    "\n",
    "**When to use this:**\n",
    "- No input-output pairs, just data X\n",
    "- Need to detect anomalies\n",
    "- Want to generate new synthetic data\n",
    "- Need exact probability densities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Basic Density Estimation - Learning the Moons Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D moons dataset (NO input-output pairs, just data points!)\n",
    "X_moons, _ = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
    "X_moons = np.array(X_moons)\n",
    "\n",
    "print(f\"Training data shape: {X_moons.shape}\")\n",
    "print(f\"Task: Learn p(X) - the probability distribution of the moon shape\")\n",
    "print(f\"\\nNote: No Y here! We're learning the distribution of X itself.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create invertible NN for density estimation with better hyperparameters\n",
    "inn = InvertibleNN(\n",
    "    n_features=2,        # 2D data\n",
    "    n_layers=10,         # More coupling layers\n",
    "    hidden_dims=[128, 128],  # Larger network\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Training density estimation model...\")\n",
    "inn.fit(X_moons, normalize=True, maxiter=2000, tol=1e-5)  # More training\n",
    "\n",
    "# Print report\n",
    "inn.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned distribution\n",
    "fig = inn.plot(X_moons, n_samples=1000)\n",
    "plt.suptitle('Density Estimation on Moons Dataset', fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Left: Original data (complex moon shape)\")\n",
    "print(\"✓ Middle: Latent space (should be ~Gaussian blob)\")\n",
    "print(\"✓ Right: Generated samples (new moon-shaped data!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Anomaly Detection with Likelihoods\n",
    "\n",
    "**Use case**: Detect outliers by computing their probability under learned distribution.\n",
    "\n",
    "**Intuition**: \n",
    "- Normal points → High probability\n",
    "- Anomalies → Low probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on \"normal\" data (centered Gaussian blob)\n",
    "X_normal, _ = make_blobs(n_samples=500, centers=[[0, 0]], \n",
    "                         cluster_std=0.5, random_state=42)\n",
    "X_normal = np.array(X_normal)\n",
    "\n",
    "# Train anomaly detector with better hyperparameters\n",
    "inn_anomaly = InvertibleNN(n_features=2, n_layers=8, hidden_dims=[128, 128], seed=42)\n",
    "print(\"Training anomaly detector on normal data...\")\n",
    "inn_anomaly.fit(X_normal, normalize=True, maxiter=1500)  # More training\n",
    "print(\"Training complete!\\n\")\n",
    "\n",
    "# Test points (some normal, some anomalous)\n",
    "X_test = np.array([\n",
    "    [0.0, 0.0],    # Normal (center)\n",
    "    [0.3, 0.3],    # Normal\n",
    "    [0.5, -0.5],   # Normal (edge)\n",
    "    [1.5, 1.5],    # Mild outlier\n",
    "    [3.0, 3.0],    # Moderate outlier\n",
    "    [5.0, 5.0],    # Strong outlier\n",
    "])\n",
    "\n",
    "# Compute log probabilities\n",
    "log_probs_test = inn_anomaly.log_prob(X_test)\n",
    "\n",
    "# Set threshold (5th percentile of training data)\n",
    "train_log_probs = inn_anomaly.log_prob(X_normal)\n",
    "threshold = np.percentile(train_log_probs, 5)\n",
    "\n",
    "print(\"Anomaly Detection Results:\")\n",
    "print(f\"{'Point':<20} {'Log-Prob':<15} {'Status':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for point, lp in zip(X_test, log_probs_test):\n",
    "    status = \"🚨 ANOMALY\" if lp < threshold else \"✓ NORMAL\"\n",
    "    print(f\"{str(point):<20} {lp:<15.3f} {status:<10}\")\n",
    "\n",
    "print(f\"\\nThreshold (5th percentile): {threshold:.3f}\")\n",
    "print(\"\\n✓ Points far from training data have low probability!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize likelihood landscape\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Create grid\n",
    "x1_range = np.linspace(-3, 6, 100)\n",
    "x2_range = np.linspace(-3, 6, 100)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "log_probs_grid = inn_anomaly.log_prob(X_grid)\n",
    "probs_grid = np.exp(log_probs_grid).reshape(X1.shape)\n",
    "\n",
    "# Left: Probability density\n",
    "ax = axes[0]\n",
    "contour = ax.contourf(X1, X2, probs_grid, levels=20, cmap='YlOrRd')\n",
    "ax.scatter(X_normal[:, 0], X_normal[:, 1], alpha=0.3, s=10, c='blue', label='Training')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], s=200, c='black', marker='X', \n",
    "           edgecolors='white', linewidths=2, label='Test', zorder=5)\n",
    "plt.colorbar(contour, ax=ax, label='Probability Density')\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title('Probability Density Landscape')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Decision boundary\n",
    "ax = axes[1]\n",
    "log_probs_reshaped = log_probs_grid.reshape(X1.shape)\n",
    "contour2 = ax.contourf(X1, X2, log_probs_reshaped, levels=20, cmap='RdYlGn')\n",
    "ax.contour(X1, X2, log_probs_reshaped, levels=[threshold], \n",
    "           colors='black', linewidths=3, linestyles='--')\n",
    "\n",
    "normal_mask = log_probs_test >= threshold\n",
    "anomaly_mask = log_probs_test < threshold\n",
    "\n",
    "if np.any(normal_mask):\n",
    "    ax.scatter(X_test[normal_mask, 0], X_test[normal_mask, 1], \n",
    "               s=200, c='green', marker='o', edgecolors='white', \n",
    "               linewidths=2, label='Normal', zorder=5)\n",
    "if np.any(anomaly_mask):\n",
    "    ax.scatter(X_test[anomaly_mask, 0], X_test[anomaly_mask, 1], \n",
    "               s=200, c='red', marker='X', edgecolors='white', \n",
    "               linewidths=2, label='Anomaly', zorder=5)\n",
    "\n",
    "plt.colorbar(contour2, ax=ax, label='Log-Probability')\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title('Anomaly Detection Boundary')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Forward and Inverse Transformations\n",
    "\n",
    "**Key feature**: Perfect invertibility!\n",
    "- Forward: Complex data X → Simple Gaussian Z\n",
    "- Inverse: Gaussian Z → Realistic data X\n",
    "- No information loss (reconstruction error ≈ 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward: data → latent\n",
    "Z, log_det = inn.forward(X_moons[:100])\n",
    "\n",
    "print(\"Forward Transformation (X → Z):\")\n",
    "print(f\"  Original data: {X_moons[:100].shape}\")\n",
    "print(f\"  Latent space: {Z.shape}\")\n",
    "print(f\"\\nLatent statistics (should be ~ N(0, 1)):\")\n",
    "print(f\"  Mean: [{np.mean(Z[:, 0]):.3f}, {np.mean(Z[:, 1]):.3f}]\")\n",
    "print(f\"  Std:  [{np.std(Z[:, 0]):.3f}, {np.std(Z[:, 1]):.3f}]\")\n",
    "\n",
    "# Inverse: latent → data\n",
    "X_reconstructed = inn.inverse(Z)\n",
    "reconstruction_error = np.max(np.abs(X_moons[:100] - X_reconstructed))\n",
    "\n",
    "print(f\"\\nInverse Transformation (Z → X):\")\n",
    "print(f\"  Reconstructed: {X_reconstructed.shape}\")\n",
    "print(f\"  Max error: {reconstruction_error:.2e}\")\n",
    "print(f\"  Perfect invertibility: {reconstruction_error < 1e-6} ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transformation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors = np.arange(100)\n",
    "\n",
    "# Original\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(X_moons[:100, 0], X_moons[:100, 1], \n",
    "                     c=colors, cmap='viridis', s=50, alpha=0.7)\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title('Original Data (X)\\nComplex Moon Shape')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Latent\n",
    "ax = axes[1]\n",
    "ax.scatter(Z[:, 0], Z[:, 1], c=colors, cmap='viridis', s=50, alpha=0.7)\n",
    "# Reference circles\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "for r in [1, 2, 3]:\n",
    "    ax.plot(r*np.cos(theta), r*np.sin(theta), 'r--', alpha=0.3, linewidth=1)\n",
    "ax.set_xlabel('z₁')\n",
    "ax.set_ylabel('z₂')\n",
    "ax.set_title('Latent Space (Z)\\nSimple Gaussian')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Reconstructed\n",
    "ax = axes[2]\n",
    "ax.scatter(X_reconstructed[:, 0], X_reconstructed[:, 1], \n",
    "           c=colors, cmap='viridis', s=50, alpha=0.7)\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title(f'Reconstructed (f⁻¹(Z))\\nError: {reconstruction_error:.2e}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Colors show point correspondence\")\n",
    "print(\"✓ Complex moon maps to simple Gaussian and back perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Testing on Different Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diverse datasets\n",
    "datasets = {}\n",
    "\n",
    "X_moons_test, _ = make_moons(n_samples=800, noise=0.05, random_state=42)\n",
    "datasets['Moons'] = np.array(X_moons_test)\n",
    "\n",
    "X_circles, _ = make_circles(n_samples=800, noise=0.05, factor=0.5, random_state=42)\n",
    "datasets['Circles'] = np.array(X_circles)\n",
    "\n",
    "X_blobs, _ = make_blobs(n_samples=800, centers=4, cluster_std=0.3, random_state=42)\n",
    "datasets['Blobs'] = np.array(X_blobs)\n",
    "\n",
    "n_spiral = 800\n",
    "theta = np.linspace(0, 4*np.pi, n_spiral)\n",
    "r = theta / (4*np.pi) * 3\n",
    "X_spiral = np.stack([r*np.cos(theta), r*np.sin(theta)], axis=1)\n",
    "noise = jax.random.normal(jax.random.PRNGKey(42), X_spiral.shape) * 0.1\n",
    "datasets['Spiral'] = X_spiral + noise\n",
    "\n",
    "print(\"Testing INN on 4 different distributions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on each with better hyperparameters\n",
    "trained_models = {}\n",
    "\n",
    "for name, X in datasets.items():\n",
    "    print(f\"Training on {name}...\")\n",
    "    model = InvertibleNN(\n",
    "        n_features=2, \n",
    "        n_layers=12,  # More layers for complex distributions\n",
    "        hidden_dims=[128, 128],  # Larger network\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X, normalize=True, maxiter=2000)  # More training\n",
    "    \n",
    "    trained_models[name] = {\n",
    "        'model': model,\n",
    "        'score': model.score(X),\n",
    "        'samples': model.sample(500, key=jax.random.PRNGKey(42)),\n",
    "        'data': X\n",
    "    }\n",
    "    print(f\"  Score: {trained_models[name]['score']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, name in enumerate(datasets.keys()):\n",
    "    X = trained_models[name]['data']\n",
    "    samples = trained_models[name]['samples']\n",
    "    score = trained_models[name]['score']\n",
    "    \n",
    "    # Top: original\n",
    "    ax = axes[0, idx]\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.5, s=10, c='blue')\n",
    "    ax.set_title(f'{name}\\nOriginal', fontsize=10, fontweight='bold')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom: generated\n",
    "    ax = axes[1, idx]\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.2, s=5, c='gray', label='Original')\n",
    "    ax.scatter(samples[:, 0], samples[:, 1], alpha=0.6, s=10, c='red', label='Generated')\n",
    "    ax.set_title(f'Score: {score:.2f}', fontsize=10)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "plt.suptitle('INN Performance on Different Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ INN works well on diverse distribution types!\")\n",
    "print(\"✓ Circles are challenging due to topology - may need more layers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: When to Use INN for Density Estimation\n",
    "\n",
    "✅ **Use InvertibleNN when you need to:**\n",
    "- Detect anomalies with calibrated probabilities\n",
    "- Generate new realistic synthetic data\n",
    "- Compute exact likelihoods p(X)\n",
    "- Understand data distribution structure\n",
    "- No input-output pairs, just samples from distribution\n",
    "\n",
    "⚠️ **Not ideal for:**\n",
    "- Supervised learning (use ConditionalINN instead)\n",
    "- Discrete data (INNs are for continuous distributions)\n",
    "- Very high dimensions (>100) with limited data\n",
    "\n",
    "**Comparison to alternatives:**\n",
    "- vs **VAE**: INN has exact likelihood, no reconstruction error, harder to train\n",
    "- vs **GAN**: INN is more stable, provides likelihoods, less mode collapse\n",
    "- vs **KDE**: INN scales better to high dimensions, learns complex distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Final Comparison: Conditional vs Unconditional\n",
    "\n",
    "| Aspect | ConditionalInvertibleNN | InvertibleNN |\n",
    "|--------|------------------------|-------------|\n",
    "| **Learns** | p(Y\\|X) - outputs given inputs | p(X) - data distribution |\n",
    "| **Task** | Regression with uncertainty | Density estimation |\n",
    "| **Input** | fit(X, y) - paired data | fit(X) - just data points |\n",
    "| **Output** | Predictions + uncertainty | Likelihoods + samples |\n",
    "| **Use cases** | • Regression<br>• Uncertainty quantification<br>• Heteroscedastic noise | • Anomaly detection<br>• Generative modeling<br>• Density estimation |\n",
    "| **Example** | \"Predict house price from features with confidence\" | \"Detect fraudulent transactions\" |\n",
    "\n",
    "## Recommended Configurations\n",
    "\n",
    "### For Regression (ConditionalINN):\n",
    "```python\n",
    "cinn = ConditionalInvertibleNN(\n",
    "    n_features_in=X.shape[1],\n",
    "    n_features_out=y.shape[1],\n",
    "    n_layers=8-10,          # 8-10 layers for good capacity\n",
    "    hidden_dims=[128, 128],  # Larger networks work better\n",
    "    seed=42\n",
    ")\n",
    "cinn.fit(X, y, maxiter=2000)  # 2000+ iterations recommended\n",
    "\n",
    "# Predict with many samples for smooth uncertainty\n",
    "y_pred, y_std = cinn.predict(X_test, return_std=True, n_samples=2000)\n",
    "```\n",
    "\n",
    "**Tips for ConditionalINN:**\n",
    "- Use 8-10 layers for complex relationships\n",
    "- Larger networks (128+ hidden units) capture distributions better\n",
    "- Train longer (2000+ iterations) for convergence\n",
    "- Use 2000-5000 samples for smooth uncertainty estimates\n",
    "- For heteroscedastic data: use 10+ layers with deep networks [128, 128, 128]\n",
    "\n",
    "### For Density Estimation (INN):\n",
    "```python\n",
    "inn = InvertibleNN(\n",
    "    n_features=X.shape[1],\n",
    "    n_layers=10-12,          # 10-12 layers for complex distributions\n",
    "    hidden_dims=[128, 128],  # Larger capacity\n",
    "    seed=42\n",
    ")\n",
    "inn.fit(X, normalize=True, maxiter=2000)  # Always normalize!\n",
    "\n",
    "# For anomaly detection\n",
    "log_probs = inn.log_prob(X_test)\n",
    "threshold = np.percentile(train_log_probs, 5)\n",
    "anomalies = log_probs < threshold\n",
    "\n",
    "# For generation\n",
    "samples = inn.sample(n_samples=100)\n",
    "```\n",
    "\n",
    "**Tips for INN:**\n",
    "- **Always use normalization** for stability\n",
    "- 10-12 layers for complex distributions (moons, spirals)\n",
    "- Train longer (2000+ iterations) for convergence\n",
    "- Circles/toroidal shapes are challenging - may need 15+ layers\n",
    "\n",
    "### When to Use More Resources\n",
    "\n",
    "**Complex problems need:**\n",
    "- **More layers** (12-15): Spirals, multi-modal distributions, heteroscedastic regression\n",
    "- **Deeper networks** [128, 128, 128]: Input-dependent uncertainty, high-dimensional data\n",
    "- **More iterations** (3000-5000): Slow convergence, complex distributions\n",
    "- **More samples** (5000+): Smooth uncertainty visualization, precise confidence intervals\n",
    "\n",
    "**Simple problems can use:**\n",
    "- **Fewer layers** (6-8): Linear/simple nonlinear regression, Gaussian blobs\n",
    "- **Smaller networks** [64, 64]: Low-dimensional data, simple distributions\n",
    "- **Fewer iterations** (1000-1500): Fast convergence\n",
    "- **Fewer samples** (500-1000): Quick predictions\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- Dinh et al., \"Density estimation using Real NVP\", ICLR 2017\n",
    "- Winkler et al., \"Learning Likelihoods with Conditional Normalizing Flows\", 2019\n",
    "- Ardizzone et al., \"Analyzing Inverse Problems with Invertible Neural Networks\", ICLR 2019\n",
    "- Papamakarios et al., \"Normalizing Flows for Probabilistic Modeling\", JMLR 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
