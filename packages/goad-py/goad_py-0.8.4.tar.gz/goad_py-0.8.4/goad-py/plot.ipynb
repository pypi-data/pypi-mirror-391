{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6486e091",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b66b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from matplotlib import cm\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8f03c",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data path\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "data_path = os.path.join(home_dir, \"Documents/work/data/bevel-columns/output\")\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Error: Path {data_path} does not exist.\")\n",
    "    \n",
    "# Find all directories in the path\n",
    "subdirs = [d for d in os.listdir(data_path) \n",
    "           if os.path.isdir(os.path.join(data_path, d))]\n",
    "\n",
    "print(f\"Found {len(subdirs)} directories in {data_path}\")\n",
    "\n",
    "# Function to load mueller_scatgrid files\n",
    "def load_mueller_data(file_path):\n",
    "    \"\"\"\n",
    "    Load mueller_scatgrid data file containing 18 columns:\n",
    "    - columns 0-1: theta and phi\n",
    "    - columns 2-17: Mueller matrix elements\n",
    "    \n",
    "    Returns: numpy array with the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = np.loadtxt(file_path)\n",
    "        # Check if the file has the expected number of columns (18)\n",
    "        if data.shape[1] != 18:\n",
    "            print(f\"Warning: {file_path} has {data.shape[1]} columns, expected 18\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to store mueller data for each directory\n",
    "mueller_data = {}\n",
    "\n",
    "# Iterate through subdirectories and load the data\n",
    "for subdir in subdirs:\n",
    "    full_path = os.path.join(data_path, subdir)\n",
    "    mueller_file = os.path.join(full_path, \"mueller_scatgrid\")\n",
    "    \n",
    "    if os.path.exists(mueller_file):\n",
    "        data = load_mueller_data(mueller_file)\n",
    "        if data is not None:\n",
    "            mueller_data[subdir] = data\n",
    "            print(f\"Loaded data from {subdir}, shape: {data.shape}\")\n",
    "    else:\n",
    "        print(f\"File not found: {mueller_file}\")\n",
    "\n",
    "print(f\"\\nLoaded data from {len(mueller_data)} directories\")\n",
    "\n",
    "# Display a summary of the first file if any were loaded\n",
    "if mueller_data:\n",
    "    first_key = list(mueller_data.keys())[0]\n",
    "    first_data = mueller_data[first_key]\n",
    "    \n",
    "    print(f\"\\nSample data from {first_key}:\")\n",
    "    print(\"First few rows:\")\n",
    "    print(first_data[:3, :])\n",
    "    \n",
    "    print(\"\\nData columns meaning:\")\n",
    "    print(\"Columns 0-1: theta and phi\")\n",
    "    print(\"Columns 2-17: Mueller matrix elements M11, M12, ..., M44\")\n",
    "    \n",
    "    # Calculate some basic statistics for the first dataset\n",
    "    print(f\"\\nTheta range: {first_data[:,0].min()} to {first_data[:,0].max()} degrees\")\n",
    "    print(f\"Phi range: {first_data[:,1].min()} to {first_data[:,1].max()} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e58c4",
   "metadata": {},
   "source": [
    "## Load 1D Mueller File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load 1D mueller_scatgrid_1d files\n",
    "def load_mueller_1d_data(file_path):\n",
    "    \"\"\"\n",
    "    Load mueller_scatgrid_1d data file containing 17 columns:\n",
    "    - column 0: theta (phi has been integrated out)\n",
    "    - columns 1-16: Mueller matrix elements\n",
    "    \n",
    "    Returns: numpy array with the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = np.loadtxt(file_path)\n",
    "        # Check if the file has the expected number of columns (17)\n",
    "        if data.shape[1] != 17:\n",
    "            print(f\"Warning: {file_path} has {data.shape[1]} columns, expected 17\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to store 1D mueller data for each directory\n",
    "mueller_1d_data = {}\n",
    "\n",
    "# Iterate through subdirectories and load the 1D data\n",
    "for subdir in subdirs:\n",
    "    full_path = os.path.join(data_path, subdir)\n",
    "    mueller_1d_file = os.path.join(full_path, \"mueller_scatgrid_1d\")\n",
    "    \n",
    "    if os.path.exists(mueller_1d_file):\n",
    "        data = load_mueller_1d_data(mueller_1d_file)\n",
    "        if data is not None:\n",
    "            mueller_1d_data[subdir] = data\n",
    "            print(f\"Loaded 1D data from {subdir}, shape: {data.shape}\")\n",
    "    else:\n",
    "        print(f\"1D file not found: {mueller_1d_file}\")\n",
    "\n",
    "print(f\"\\nLoaded 1D data from {len(mueller_1d_data)} directories\")\n",
    "\n",
    "# Display a summary of the first 1D file if any were loaded\n",
    "if mueller_1d_data:\n",
    "    first_key = list(mueller_1d_data.keys())[0]\n",
    "    first_1d_data = mueller_1d_data[first_key]\n",
    "    \n",
    "    print(f\"\\nSample 1D data from {first_key}:\")\n",
    "    print(\"First few rows:\")\n",
    "    print(first_1d_data[:3, :])\n",
    "    \n",
    "    print(\"\\nData columns meaning:\")\n",
    "    print(\"Column 0: theta (phi integrated out)\")\n",
    "    print(\"Columns 1-16: Mueller matrix elements M11, M12, ..., M44\")\n",
    "    \n",
    "    # Calculate some basic statistics for the first 1D dataset\n",
    "    print(f\"\\nTheta range: {first_1d_data[:,0].min()} to {first_1d_data[:,0].max()} degrees\")\n",
    "    \n",
    "    # Check if the first row is consistent with forward scattering (should be at theta=0)\n",
    "    if abs(first_1d_data[0,0]) < 1e-6:\n",
    "        print(\"\\nFirst row corresponds to forward scattering (theta \u2248 0\u00b0)\")\n",
    "    \n",
    "    # Check if the last row is consistent with backward scattering (should be at theta=180)\n",
    "    if abs(first_1d_data[-1,0] - 180) < 1e-6:\n",
    "        print(\"Last row corresponds to backward scattering (theta \u2248 180\u00b0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbdd2fd",
   "metadata": {},
   "source": [
    "## Load Results File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c400372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse results.dat files\n",
    "def parse_results_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse a results.dat file and extract key scattering parameters:\n",
    "    - Scattering Cross Section\n",
    "    - Extinction Cross Section\n",
    "    - Single Scattering Albedo\n",
    "    - Asymmetry Parameter\n",
    "    \n",
    "    Returns: Dictionary with parameter names and values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract key parameters using regular expressions\n",
    "        scat_cs_match = re.search(r'Scattering Cross Section:\\s+([0-9.]+)', content)\n",
    "        ext_cs_match = re.search(r'Extinction Cross Section:\\s+([0-9.]+)', content)\n",
    "        ssa_match = re.search(r'Single Scattering Albedo:\\s+([0-9.]+)', content)\n",
    "        asym_match = re.search(r'Asymmetry Parameter:\\s+([0-9.]+)', content)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        if scat_cs_match:\n",
    "            results['scattering_cs'] = float(scat_cs_match.group(1))\n",
    "        \n",
    "        if ext_cs_match:\n",
    "            results['extinction_cs'] = float(ext_cs_match.group(1))\n",
    "        \n",
    "        if ssa_match:\n",
    "            results['ssa'] = float(ssa_match.group(1))\n",
    "        \n",
    "        if asym_match:\n",
    "            results['asymmetry'] = float(asym_match.group(1))\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing results file {file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Dictionary to store scattering parameter data for each directory\n",
    "scattering_params = {}\n",
    "\n",
    "# Iterate through subdirectories and load the results.dat data\n",
    "for subdir in subdirs:\n",
    "    full_path = os.path.join(data_path, subdir)\n",
    "    results_file = os.path.join(full_path, \"results.dat\")\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        params = parse_results_file(results_file)\n",
    "        if params:\n",
    "            scattering_params[subdir] = params\n",
    "            print(f\"Loaded scattering parameters from {subdir}\")\n",
    "    else:\n",
    "        print(f\"Results file not found: {results_file}\")\n",
    "\n",
    "print(f\"\\nLoaded scattering parameters from {len(scattering_params)} directories\")\n",
    "\n",
    "# Display a summary of the scattering parameters\n",
    "if scattering_params:\n",
    "    print(\"\\nScattering parameter summary:\")\n",
    "    print(\"{:<15} {:<20} {:<20} {:<20} {:<20}\".format(\n",
    "        \"Directory\", \"Scattering CS\", \"Extinction CS\", \"SSA\", \"Asymmetry\"))\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    for subdir, params in scattering_params.items():\n",
    "        print(\"{:<15} {:<20.6f} {:<20.6f} {:<20.6f} {:<20.6f}\".format(\n",
    "            subdir[:14],\n",
    "            params.get('scattering_cs', float('nan')),\n",
    "            params.get('extinction_cs', float('nan')),\n",
    "            params.get('ssa', float('nan')),\n",
    "            params.get('asymmetry', float('nan'))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01611734",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1e6fc5",
   "metadata": {},
   "source": [
    "## Automatic Filename Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00394340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse command executed files with improved handling for specific parameters\n",
    "def parse_command_file_improved(file_path):\n",
    "    \"\"\"\n",
    "    Parse a command_executed.txt file and extract the command line parameters.\n",
    "    Ignores --dir parameter and extracts only basename from --geo parameter.\n",
    "    \n",
    "    Returns: Dictionary with parameter names and values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            command = f.read().strip()\n",
    "        \n",
    "        # Find the part after \"goad\" in the command\n",
    "        match = re.search(r'goad\\s+(.*)', command)\n",
    "        if not match:\n",
    "            print(f\"Could not find 'goad' in command: {command}\")\n",
    "            return {}\n",
    "        \n",
    "        params_str = match.group(1)\n",
    "        \n",
    "        # Parse parameters\n",
    "        params = {}\n",
    "        i = 0\n",
    "        skip_next = False\n",
    "        \n",
    "        while i < len(params_str):\n",
    "            # Match parameter names (starting with - or --)\n",
    "            param_match = re.search(r'(-{1,2}[a-zA-Z0-9]+)(?:\\s+([^-][^\\s]*)|)', params_str[i:])\n",
    "            if not param_match:\n",
    "                break\n",
    "            \n",
    "            param_name = param_match.group(1)\n",
    "            param_value = param_match.group(2) if param_match.group(2) else True\n",
    "            \n",
    "            # Skip --dir parameter\n",
    "            if param_name == \"--dir\":\n",
    "                i += param_match.end()\n",
    "                \n",
    "                # Also skip the directory value that follows\n",
    "                if not skip_next:\n",
    "                    dir_match = re.search(r'\\s+([^\\s]+)', params_str[i:])\n",
    "                    if dir_match:\n",
    "                        i += dir_match.end()\n",
    "                continue\n",
    "            \n",
    "            # Extract only basename from --geo parameter and remove file extension\n",
    "            if param_name == \"--geo\" and isinstance(param_value, str):\n",
    "                param_value = os.path.splitext(os.path.basename(param_value))[0]\n",
    "            \n",
    "            # Convert numeric values from strings\n",
    "            if isinstance(param_value, str):\n",
    "                try:\n",
    "                    if '.' in param_value:\n",
    "                        param_value = float(param_value)\n",
    "                    else:\n",
    "                        param_value = int(param_value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            params[param_name] = param_value\n",
    "            i += param_match.end()\n",
    "        \n",
    "        return params\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing command file {file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Dictionary to store parsed command parameters for each directory\n",
    "command_params_improved = {}\n",
    "\n",
    "# Iterate through subdirectories to load command files with the improved parser\n",
    "for subdir in subdirs:\n",
    "    full_path = os.path.join(data_path, subdir)\n",
    "    command_file = os.path.join(full_path, \"command_executed.txt\")\n",
    "    \n",
    "    if os.path.exists(command_file):\n",
    "        params = parse_command_file_improved(command_file)\n",
    "        if params:\n",
    "            command_params_improved[subdir] = params\n",
    "            print(f\"Parsed command from {subdir}, found {len(params)} parameters\")\n",
    "    else:\n",
    "        print(f\"Command file not found: {command_file}\")\n",
    "\n",
    "print(f\"\\nParsed commands from {len(command_params_improved)} directories\")\n",
    "\n",
    "# Find which parameters vary between runs and which are constant\n",
    "if len(command_params_improved) > 1:\n",
    "    # Collect all parameter names\n",
    "    all_params = set()\n",
    "    for params in command_params_improved.values():\n",
    "        all_params.update(params.keys())\n",
    "    \n",
    "    # Check which parameters vary\n",
    "    varying_params = {}\n",
    "    constant_params = {}\n",
    "    \n",
    "    for param in all_params:\n",
    "        values = [params.get(param) for params in command_params_improved.values() \n",
    "                  if param in params]\n",
    "        \n",
    "        if len(set(values)) > 1:\n",
    "            varying_params[param] = values\n",
    "        else:\n",
    "            if values:  # Make sure there's at least one value\n",
    "                constant_params[param] = values[0]\n",
    "    \n",
    "    print(\"\\nVarying parameters between datasets:\")\n",
    "    for param, values in varying_params.items():\n",
    "        unique_values = sorted(set(values))\n",
    "        print(f\"{param}: {unique_values}\")\n",
    "    \n",
    "    print(\"\\nConstant parameters across all datasets:\")\n",
    "    for param, value in constant_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    \n",
    "    # Create better labels for the datasets based on varying parameters\n",
    "    dataset_labels = {}\n",
    "    for subdir in command_params_improved.keys():\n",
    "        label_parts = []\n",
    "        for param in sorted(varying_params.keys()):\n",
    "            if param in command_params_improved[subdir]:\n",
    "                value = command_params_improved[subdir][param]\n",
    "                # Format the parameter name without dashes\n",
    "                param_name = param.lstrip('-')\n",
    "                label_parts.append(f\"{param_name}={value}\")\n",
    "        \n",
    "        if label_parts:\n",
    "            dataset_labels[subdir] = \", \".join(label_parts)\n",
    "        else:\n",
    "            dataset_labels[subdir] = subdir\n",
    "    \n",
    "    print(\"\\nDataset labels based on varying parameters:\")\n",
    "    for subdir, label in dataset_labels.items():\n",
    "        print(f\"{subdir}: {label}\")\n",
    "else:\n",
    "    print(\"Need more than one dataset to compare parameter variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of multiple Mueller matrix elements from the 1D data\n",
    "# Use LaTeX font\n",
    "plt.rcParams.update({'text.usetex': True})\n",
    "\n",
    "# Figure font config\n",
    "label_font = {'fontfamily': 'Arial Black', 'fontsize': 12}\n",
    "title_font = {'fontfamily': 'Arial Black', 'fontsize': 16}\n",
    "subfig_title_font = {'fontfamily': 'Arial Black', 'fontsize': 12}\n",
    "\n",
    "# Create figure with 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(9, 8))\n",
    "axs = axs.flatten()  # Flatten to easily iterate through all axes\n",
    "\n",
    "# Create an inset axes for S11 forward scattering region (0-3 degrees)\n",
    "axins_forward = inset_axes(axs[0], width=\"30%\", height=\"30%\", loc=\"upper left\",\n",
    "                   bbox_to_anchor=(0.1, -0.1, 1, 1), bbox_transform=axs[0].transAxes)\n",
    "\n",
    "# Create an inset axes for S11 backscattering region (175-180 degrees)\n",
    "axins_backward = inset_axes(axs[0], width=\"30%\", height=\"30%\", loc=\"upper right\",\n",
    "                   bbox_to_anchor=(-0.05, -0.1, 1, 1), bbox_transform=axs[0].transAxes)\n",
    "\n",
    "# Plot colors and styles\n",
    "colors = cm.Set2.colors\n",
    "line_styles = ['-', '--', '-.', ':', '-', '--', '-.']\n",
    "\n",
    "# Element names and column indices (0-based)\n",
    "elements = {\n",
    "    'S11': 1,           # Element is in column 1 (2nd column)\n",
    "    'S12/S11': 2,       # S12 is in column 2 (3rd column)\n",
    "    'S22/S11': 6,       # S22 is in column 6 (7th column)\n",
    "    'S33/S11': 11,      # S33 is in column 11 (12th column)\n",
    "    'S34/S11': 12,      # S34 is in column 12 (13th column)\n",
    "    'S44/S11': 16       # S44 is in column 16 (17th column)\n",
    "}\n",
    "\n",
    "# Get parameter that varies for title\n",
    "if len(varying_params) > 0:\n",
    "    varying_param_name = next(iter(sorted(varying_params.keys()))).lstrip('-')\n",
    "else:\n",
    "    varying_param_name = \"Dataset\"\n",
    "\n",
    "# Create overall figure title from constant parameters\n",
    "if 'constant_params' in locals() and constant_params:\n",
    "    # Get wavelength if available\n",
    "    wavelength = constant_params.get('-w', constant_params.get('--w', None))\n",
    "    wavelength_str = f\"$\\\\lambda = {wavelength}$ $\\\\mu$m, \" if wavelength else \"\"\n",
    "    \n",
    "    # Get geometry file if available\n",
    "    geo_file = constant_params.get('--geo', None)\n",
    "    geo_str = f\"{geo_file}, \" if geo_file else \"\"\n",
    "    \n",
    "    fig_title = f\"Mueller Matrix Elements for {geo_str}{wavelength_str}Varying {varying_param_name}\"\n",
    "else:\n",
    "    fig_title = \"Mueller Matrix Comparison\"\n",
    "\n",
    "# Dictionary to store min and max values for each element ratio\n",
    "ratio_bounds = {element: {'min': float('inf'), 'max': float('-inf')} for element in elements.keys() if element != 'S11'}\n",
    "\n",
    "# First pass to determine actual data ranges for improved y-axis limits\n",
    "for element_name, col_idx in elements.items():\n",
    "    if element_name != 'S11':  # Skip S11, we'll use log scale\n",
    "        for subdir, data in mueller_1d_data.items():\n",
    "            theta = data[:, 0]\n",
    "            element = data[:, col_idx]\n",
    "            s11 = data[:, elements['S11']]\n",
    "            ratio = element / s11\n",
    "            \n",
    "            ratio_bounds[element_name]['min'] = min(ratio_bounds[element_name]['min'], np.nanmin(ratio))\n",
    "            ratio_bounds[element_name]['max'] = max(ratio_bounds[element_name]['max'], np.nanmax(ratio))\n",
    "\n",
    "# Add overall title to the figure with reduced space (using smaller y value)\n",
    "fig.suptitle(fig_title, fontdict=title_font, y=0.95)\n",
    "\n",
    "# Store the legend handles and labels for later\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "# Plot each element\n",
    "for i, (element_name, col_idx) in enumerate(elements.items()):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    # Plot data for each dataset\n",
    "    for j, (subdir, data) in enumerate(mueller_1d_data.items()):\n",
    "        if j >= len(colors):\n",
    "            color_idx = j % len(colors)\n",
    "        else:\n",
    "            color_idx = j\n",
    "            \n",
    "        if j >= len(line_styles):\n",
    "            ls_idx = j % len(line_styles)\n",
    "        else:\n",
    "            ls_idx = j\n",
    "        \n",
    "        # Extract theta and the requested element\n",
    "        theta = data[:, 0]\n",
    "        element = data[:, col_idx]\n",
    "        \n",
    "        # Use dataset label if available, otherwise use directory name\n",
    "        if 'dataset_labels' in locals() and subdir in dataset_labels:\n",
    "            label = dataset_labels[subdir]\n",
    "        else:\n",
    "            label = subdir\n",
    "        \n",
    "        # For S11, plot on log scale\n",
    "        if element_name == 'S11':\n",
    "            # Main plot\n",
    "            line, = ax.semilogy(theta, element, \n",
    "                      color=colors[color_idx], \n",
    "                      linestyle=line_styles[ls_idx], \n",
    "                      linewidth=1.5,\n",
    "                      label=label)\n",
    "            \n",
    "            # Store handles and labels from the first element for the legend\n",
    "            if i == 0:\n",
    "                legend_handles.append(line)\n",
    "                legend_labels.append(label)\n",
    "            \n",
    "            # Forward scattering inset plot (0-3 degrees)\n",
    "            forward_mask = (theta >= 0) & (theta <= 3)\n",
    "            if np.any(forward_mask):\n",
    "                axins_forward.semilogy(theta[forward_mask], element[forward_mask],\n",
    "                             color=colors[color_idx],\n",
    "                             linestyle=line_styles[ls_idx],\n",
    "                             linewidth=1)\n",
    "                \n",
    "            # Backward scattering inset plot (175-180 degrees)\n",
    "            backward_mask = (theta >= 175) & (theta <= 180)\n",
    "            if np.any(backward_mask):\n",
    "                axins_backward.semilogy(theta[backward_mask], element[backward_mask],\n",
    "                              color=colors[color_idx],\n",
    "                              linestyle=line_styles[ls_idx],\n",
    "                              linewidth=1)\n",
    "        else:\n",
    "            # For other elements, plot the ratio to S11\n",
    "            s11 = data[:, elements['S11']]  \n",
    "            ratio = element / s11  # Calculate ratio to S11\n",
    "            \n",
    "            ax.plot(theta, ratio, \n",
    "                   color=colors[color_idx], \n",
    "                   linestyle=line_styles[ls_idx], \n",
    "                   linewidth=1.5)\n",
    "    \n",
    "    # Set x-axis label only for bottom row\n",
    "    if i >= 4:\n",
    "        ax.set_xlabel(r'Scattering Angle $\\theta$ (degrees)', fontdict=label_font)\n",
    "    \n",
    "    # Set y-axis label\n",
    "    if element_name == 'S11':\n",
    "        ax.set_ylabel(r'$S_{11}$', fontdict=label_font)\n",
    "    else:\n",
    "        ax.set_ylabel(f'${element_name}$', fontdict=label_font)\n",
    "    \n",
    "    # Configure ticks and axis limits\n",
    "    ax.set_xlim(0, 180)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(45))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(15))\n",
    "    \n",
    "    # For S11, use log scale\n",
    "    if element_name == 'S11':\n",
    "        ax.yaxis.set_major_locator(ticker.LogLocator(base=10.0, numticks=6))\n",
    "        \n",
    "        # Configure forward scattering inset axes\n",
    "        axins_forward.set_xlim(0, 3)\n",
    "        axins_forward.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        axins_forward.xaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "        axins_forward.grid(True, alpha=0.2)\n",
    "        axins_forward.tick_params(axis='both', which='major', labelsize=8)\n",
    "        axins_forward.set_title(\"Forward scattering\", fontsize=8)\n",
    "        \n",
    "        # Configure backward scattering inset axes\n",
    "        axins_backward.set_xlim(175, 180)\n",
    "        axins_backward.xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "        axins_backward.xaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "        axins_backward.grid(True, alpha=0.2)\n",
    "        axins_backward.tick_params(axis='both', which='major', labelsize=8)\n",
    "        axins_backward.set_title(\"Backscattering\", fontsize=8)\n",
    "        \n",
    "    else:\n",
    "        # Set improved y-axis limits for ratio plots\n",
    "        if element_name == 'S12/S11':\n",
    "            # For S12/S11, use symmetric limits based on max absolute value\n",
    "            abs_max = max(abs(ratio_bounds[element_name]['min']), abs(ratio_bounds[element_name]['max']))\n",
    "            # Round up to 1 decimal place\n",
    "            y_limit = math.ceil(abs_max * 10) / 10\n",
    "            ax.set_ylim(-y_limit, y_limit)\n",
    "        else:\n",
    "            # For other ratios, round min down and max up to nearest decimal\n",
    "            y_min = math.floor(ratio_bounds[element_name]['min'] * 10) / 10\n",
    "            y_max = math.ceil(ratio_bounds[element_name]['max'] * 10) / 10\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Set appropriate tick spacing based on the range\n",
    "        y_range = ax.get_ylim()[1] - ax.get_ylim()[0]\n",
    "        if y_range <= 0.5:\n",
    "            major_spacing = 0.1\n",
    "        elif y_range <= 1.0:\n",
    "            major_spacing = 0.2\n",
    "        else:\n",
    "            major_spacing = 0.5\n",
    "            \n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(major_spacing))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(major_spacing/5))\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(axis='both', color='black', alpha=0.1)\n",
    "    ax.grid(which='minor', alpha=0.05)\n",
    "\n",
    "# Add the legend to S22/S11 plot (element index 2) in the lower left corner\n",
    "axs[2].legend(legend_handles, legend_labels, loc='lower left', frameon=True, framealpha=0.8, fontsize=7)\n",
    "\n",
    "# Adjust spacing between subplots - reduced top margin to bring subplots closer to title\n",
    "plt.subplots_adjust(hspace=0.2, wspace=0.3, top=0.9)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('mueller_matrix_elements.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23db7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the integrated scattering parameters\n",
    "\n",
    "\n",
    "# Use LaTeX font\n",
    "plt.rcParams.update({'text.usetex': True})\n",
    "\n",
    "# Figure font config\n",
    "label_font = {'fontfamily': 'Arial Black', 'fontsize': 14}\n",
    "title_font = {'fontfamily': 'Arial Black', 'fontsize': 16}\n",
    "text_font = {'family': 'Palatino Linotype', 'size': 12}\n",
    "\n",
    "# Define parameters to plot\n",
    "parameters = ['asymmetry', 'ssa', 'extinction_cs', 'scattering_cs']\n",
    "parameter_labels = {\n",
    "    'asymmetry': 'Asymmetry Parameter ($g$)',\n",
    "    'ssa': 'Single Scattering Albedo',\n",
    "    'extinction_cs': 'Extinction Cross Section ($\\\\mu$m$^2$)',\n",
    "    'scattering_cs': 'Scattering Cross Section ($\\\\mu$m$^2$)'\n",
    "}\n",
    "\n",
    "# Function to extract a numeric value from dataset name for sorting\n",
    "def extract_numeric_value(dataset_name):\n",
    "    # Try to extract the last numeric part, including decimal points (e.g., \"myvalue0.5.txt\" -> returns 0.5)\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)(?!.*\\d)', dataset_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 0  # Default value if no number found\n",
    "\n",
    "# Create a figure with subplots for each parameter\n",
    "fig, axs = plt.subplots(len(parameters) , 1, figsize=(5, 12))\n",
    "\n",
    "# Process each parameter\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    # Get datasets that have this parameter\n",
    "    datasets = []\n",
    "    for subdir, params in scattering_params.items():\n",
    "        if param in params:\n",
    "            # Use the dataset label if available, otherwise use the directory name\n",
    "            if 'dataset_labels' in locals() and subdir in dataset_labels:\n",
    "                label = dataset_labels[subdir]\n",
    "            else:\n",
    "                label = subdir\n",
    "                \n",
    "            datasets.append((label, params[param], subdir))\n",
    "    \n",
    "    # Sort datasets by numeric value extracted from the label\n",
    "    datasets.sort(key=lambda x: extract_numeric_value(x[0]))\n",
    "    \n",
    "    # Extract sorted data\n",
    "    labels = [d[0] for d in datasets]\n",
    "    values = [d[1] for d in datasets]\n",
    "    subdirs = [d[2] for d in datasets]\n",
    "    \n",
    "    # # Create x positions (evenly spaced)\n",
    "    # x_pos = list(range(len(datasets)))\n",
    "    # Create x positions based on the extracted numeric value from the label\n",
    "    x_pos = [extract_numeric_value(label) for label in labels]\n",
    "    \n",
    "    # Plot each dataset point with crosses\n",
    "    for j, (x, y, label, subdir) in enumerate(zip(x_pos, values, labels, subdirs)):\n",
    "        color_idx = j % len(cm.Set2.colors)\n",
    "        \n",
    "        # Plot the point\n",
    "        ax.scatter(\n",
    "            x, y, \n",
    "            color=cm.Set2(color_idx), \n",
    "            marker='x', \n",
    "            s=50,\n",
    "            label=label,\n",
    "            zorder=3  # Ensure points are above grid lines\n",
    "        )\n",
    "        \n",
    "        # # Add label text - alternate left and right for better readability\n",
    "        # ax.text(\n",
    "        #     x, y, \n",
    "        #     extract_numeric_value(label), \n",
    "        #     fontdict=text_font, \n",
    "        #     color=cm.Set2(color_idx), \n",
    "        #     verticalalignment='bottom', \n",
    "        #     horizontalalignment='center'\n",
    "        # )\n",
    "    \n",
    "    # Set axis labels and title\n",
    "    ax.set_ylabel(parameter_labels[param], fontdict=label_font)\n",
    "    ax.set_title(f'{parameter_labels[param]}', fontdict=title_font)\n",
    "    \n",
    "    # Hide x ticks since they're just indices\n",
    "    # ax.set_xticks([])\n",
    "    # Set x-tick labels to be the numeric value extracted from the label\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([extract_numeric_value(label) for label in labels], rotation=0, ha='center', fontdict=text_font)\n",
    "    \n",
    "    # Set appropriate y-axis limits\n",
    "    if values:\n",
    "        y_range = max(values) - min(values)\n",
    "        ax.set_ylim(min(values) - y_range*0.1, max(values) + y_range*0.1)\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(axis='y', color='black', alpha=0.1, zorder=0)\n",
    "    \n",
    "    # Add horizontal grid lines for better readability\n",
    "    ax.yaxis.grid(True, linestyle='-', alpha=0.2)\n",
    "\n",
    "# Only the bottom subplot needs an x label\n",
    "axs[-1].set_xlabel('Dataset Label', fontdict=label_font)\n",
    "\n",
    "# Adjust layout to make room for the text labels\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.15, right=0.85, hspace=0.3)\n",
    "\n",
    "# Set figure title\n",
    "if 'constant_params' in locals() and constant_params:\n",
    "    # Get wavelength if available\n",
    "    wavelength = constant_params.get('-w', constant_params.get('--w', None))\n",
    "    wavelength_str = f\"$\\\\lambda = {wavelength}$ $\\\\mu$m, \" if wavelength else \"\"\n",
    "    \n",
    "    # Get geometry file if available\n",
    "    geo_file = constant_params.get('--geo', None)\n",
    "    geo_str = f\"{geo_file}, \" if geo_file else \"\"\n",
    "    \n",
    "    # fig.suptitle(f\"Scattering Parameters for {geo_str}{wavelength_str}\", \n",
    "                #  fontdict=title_font, y=0.98)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('scattering_parameters_comparison.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the 2D S11 scattering pattern for each dataset, splitting into forward and backward scattering\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Use LaTeX font\n",
    "plt.rcParams.update({'text.usetex': True})\n",
    "\n",
    "# Figure font config\n",
    "label_font = {'fontfamily': 'Arial Black', 'fontsize': 12}\n",
    "title_font = {'fontfamily': 'Arial Black', 'fontsize': 14}\n",
    "subplot_title_font = {'fontfamily': 'Arial Black', 'fontsize': 10}\n",
    "\n",
    "# S11 is in the third column (index 2) of the mueller matrix data\n",
    "S11_col = 2\n",
    "\n",
    "# Determine the grid size based on the number of datasets\n",
    "num_datasets = len(mueller_data)\n",
    "if num_datasets <= 2:\n",
    "    rows, cols = 1, num_datasets * 2  # Each dataset gets 2 plots (forward + backward)\n",
    "elif num_datasets <= 4:\n",
    "    rows, cols = 2, num_datasets  # Each row has forward+backward for one dataset\n",
    "else:\n",
    "    rows = (num_datasets + 1) // 2\n",
    "    cols = 4  # Each row has forward+backward for two datasets\n",
    "\n",
    "# Create the figure with reduced horizontal padding\n",
    "fig = plt.figure(figsize=(3.5*cols, 3.5*rows))\n",
    "\n",
    "# Get parameter that varies for title\n",
    "if len(varying_params) > 0:\n",
    "    varying_param_name = next(iter(sorted(varying_params.keys()))).lstrip('-')\n",
    "else:\n",
    "    varying_param_name = \"Dataset\"\n",
    "\n",
    "# Create overall figure title from constant parameters\n",
    "if 'constant_params' in locals() and constant_params:\n",
    "    # Get wavelength if available\n",
    "    wavelength = constant_params.get('-w', constant_params.get('--w', None))\n",
    "    wavelength_str = f\"$\\\\lambda = {wavelength}$ $\\\\mu$m, \" if wavelength else \"\"\n",
    "    \n",
    "    # Get geometry file if available\n",
    "    geo_file = constant_params.get('--geo', None)\n",
    "    geo_str = f\"{geo_file}, \" if geo_file else \"\"\n",
    "    \n",
    "    fig_title = f\"S11 Scattering Pattern for {geo_str}{wavelength_str}Varying {varying_param_name}\"\n",
    "else:\n",
    "    fig_title = \"S11 Scattering Pattern Comparison\"\n",
    "\n",
    "# Add the overall title\n",
    "fig.suptitle(fig_title, fontdict=title_font, y=0.98)\n",
    "\n",
    "# First pass to determine the intensity range across all datasets\n",
    "min_intensity = float('inf')\n",
    "max_intensity = float('-inf')\n",
    "\n",
    "for subdir, data in mueller_data.items():\n",
    "    s11 = data[:, S11_col]\n",
    "    # Handle zero or negative values\n",
    "    s11[s11 <= 0] = 1e-10\n",
    "    min_intensity = min(min_intensity, np.min(s11))\n",
    "    max_intensity = max(max_intensity, np.max(s11))\n",
    "\n",
    "# Adjust colormap limits to focus on lower intensities\n",
    "# Set the vmin to the minimum value and vmax to a fraction of the maximum value \n",
    "vmin = min_intensity\n",
    "vmax = max_intensity * 0.05  # Use only 5% of the maximum to enhance lower intensities\n",
    "\n",
    "# Process each dataset\n",
    "for i, (subdir, data) in enumerate(mueller_data.items()):\n",
    "    # Extract theta, phi, and S11 values\n",
    "    theta = data[:, 0]\n",
    "    phi = data[:, 1]\n",
    "    s11 = data[:, S11_col]\n",
    "    \n",
    "    # Handle zero or negative values (set to a small positive number for log scale)\n",
    "    s11[s11 <= 0] = 1e-10\n",
    "    \n",
    "    # Create a grid of unique theta and phi values for plotting\n",
    "    theta_unique = np.unique(theta)\n",
    "    phi_unique = np.unique(phi)\n",
    "    \n",
    "    # Verify the data forms a complete grid (important for reshaping)\n",
    "    if len(theta_unique) * len(phi_unique) != len(theta):\n",
    "        print(f\"Warning: Data for {subdir} does not form a complete grid. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Create the meshgrid\n",
    "    theta_grid, phi_grid = np.meshgrid(theta_unique, phi_unique, indexing='ij')\n",
    "    \n",
    "    # Reshape the S11 data to fit the grid\n",
    "    s11_grid = s11.reshape((len(theta_unique), len(phi_unique)))\n",
    "    \n",
    "    # Convert phi from degrees to radians for polar plotting\n",
    "    phi_grid_rad = np.radians(phi_grid)\n",
    "    \n",
    "    # Use dataset label if available, otherwise use directory name\n",
    "    if 'dataset_labels' in locals() and subdir in dataset_labels:\n",
    "        label = dataset_labels[subdir]\n",
    "    else:\n",
    "        label = subdir\n",
    "    \n",
    "    # Create forward scattering subplot (0-90 degrees)\n",
    "    ax_forward = fig.add_subplot(rows, cols, i*2+1, projection='polar')\n",
    "    \n",
    "    # Filter for forward scattering (0-90 degrees)\n",
    "    forward_mask = theta_grid <= 90\n",
    "    \n",
    "    # Plot forward scattering using RdYlBu_r colormap with adjusted limits\n",
    "    mesh_forward = ax_forward.pcolormesh(phi_grid_rad, theta_grid, np.where(forward_mask, s11_grid, np.nan),\n",
    "                                         shading='auto', \n",
    "                                         cmap=cm.RdYlBu_r,\n",
    "                                         norm=mcolors.LogNorm(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "    # Set forward plot title\n",
    "    ax_forward.set_title(f\"{label} - Forward\", fontdict=subplot_title_font)\n",
    "    \n",
    "    # Configure the forward polar plot\n",
    "    ax_forward.grid(True, alpha=0.3)\n",
    "    ax_forward.set_thetagrids(np.arange(0, 360, 45), fontsize=8)\n",
    "    ax_forward.set_rlabel_position(22.5)  # Move radial labels to make room\n",
    "    ax_forward.set_rgrids(np.arange(0, 90+1, 30), labels=[f\"{x}\u00b0\" for x in np.arange(0, 90+1, 30)], fontsize=8)\n",
    "    ax_forward.set_rlim(0, 90)\n",
    "    \n",
    "    # Create backward scattering subplot (90-180 degrees)\n",
    "    ax_backward = fig.add_subplot(rows, cols, i*2+2, projection='polar')\n",
    "    \n",
    "    # Filter for backward scattering (90-180 degrees)\n",
    "    backward_mask = theta_grid >= 90\n",
    "    \n",
    "    # For backward scattering, we need to transform the theta values\n",
    "    # 180\u00b0 becomes 0\u00b0 (center), 90\u00b0 becomes 90\u00b0 (edge)\n",
    "    transformed_theta = 180 - theta_grid\n",
    "    \n",
    "    # Plot backward scattering with transformed coordinates using RdYlBu_r colormap\n",
    "    mesh_backward = ax_backward.pcolormesh(phi_grid_rad, transformed_theta, np.where(backward_mask, s11_grid, np.nan), \n",
    "                                           shading='auto', \n",
    "                                           cmap=cm.RdYlBu_r,\n",
    "                                           norm=mcolors.LogNorm(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "    # Set backward plot title\n",
    "    ax_backward.set_title(f\"{label} - Backward\", fontdict=subplot_title_font)\n",
    "    \n",
    "    # Configure the backward polar plot\n",
    "    ax_backward.grid(True, alpha=0.3)\n",
    "    ax_backward.set_thetagrids(np.arange(0, 360, 45), fontsize=8)\n",
    "    ax_backward.set_rlabel_position(22.5)  # Move radial labels to make room\n",
    "    \n",
    "    # Set custom r-labels that show the actual scattering angles (90-180)\n",
    "    ax_backward.set_rgrids(np.arange(0, 90+1, 30), \n",
    "                           labels=[f\"{180-x}\u00b0\" for x in np.arange(0, 90+1, 30)],\n",
    "                           fontsize=8)\n",
    "    ax_backward.set_rlim(0, 90)\n",
    "\n",
    "# Add a colorbar at the bottom of the figure\n",
    "cbar_ax = fig.add_axes([0.15, 0.05, 0.7, 0.02])  # [x, y, width, height]\n",
    "cbar = fig.colorbar(mesh_forward, cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label('$S_{11}$ Intensity (log scale)', fontdict=label_font)\n",
    "\n",
    "# Reduce horizontal padding between subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.1, top=0.9, wspace=-0.3)  # Reduced wspace for tighter horizontal spacing\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('mueller_2d_patterns_split.jpg', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}